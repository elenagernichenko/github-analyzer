{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DistilBERT multilingual — дообучение для классификации ролей участников PR\n",
        "\n",
        "## Цель\n",
        "Обучить модель классификации паттернов активности участников open-source проектов на основе данных PR.\n",
        "\n",
        "## Используемые алгоритмы\n",
        "- **Модель**: DistilBERT-base-multilingual-cased (134M параметров, поддержка 104 языков)\n",
        "- **Архитектура**: Transformer encoder + линейный классификатор (head)\n",
        "- **Оптимизатор**: AdamW с weight decay\n",
        "- **Loss**: CrossEntropyLoss для многоклассовой классификации\n",
        "\n",
        "## Метрики оценки\n",
        "- **Accuracy**: доля правильных предсказаний\n",
        "- **Precision/Recall/F1 per class**: качество по каждому паттерну\n",
        "- **Macro F1**: среднее F1 по всем классам (важно при дисбалансе)\n",
        "- **Weighted F1**: F1 с весами по размеру класса\n",
        "- **Confusion Matrix**: матрица ошибок для анализа\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Устанавливаем зависимости и рабочую директорию (Colab-friendly)\n",
        "import sys, subprocess, pkg_resources, os\n",
        "from pathlib import Path\n",
        "try:\n",
        "    pkg_resources.get_distribution(\"accelerate>=0.26.0\")\n",
        "except pkg_resources.DistributionNotFound:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"accelerate>=0.26.0\"])\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    !git clone https://github.com/elenagernichenko/mcp-analyzer.git\n",
        "    %cd /content/mcp-analyzer\n",
        "\n",
        "PROJECT_ROOT = Path(\".\").resolve()\n",
        "PR_SAMPLES = PROJECT_ROOT / \"data\" / \"pr_samples_vscode.json\"  # 1000 PR из microsoft/vscode\n",
        "print(\"DATA PATH:\", PR_SAMPLES) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/spectreofoblivion/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Optional: !pip install transformers datasets scikit-learn pandas\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path(\".\").resolve()\n",
        "sys.path.append(str(PROJECT_ROOT / \"analysis\"))\n",
        "from role_classifier import classify_participant\n",
        "\n",
        "device = \"cuda\" if (os.getenv(\"CUDA_VISIBLE_DEVICES\") not in [None, \"\"] and os.environ.get(\"CUDA_VISIBLE_DEVICES\") != \"-1\") else \"cpu\"\n",
        "print(\"device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samples: 10\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>User jeroen authored 1 PRs, reviewed 0 PRs in ...</td>\n",
              "      <td>Периферийного участия</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>User andrey-khropov authored 0 PRs, reviewed 5...</td>\n",
              "      <td>Кураторства и управления</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>User topepo authored 0 PRs, reviewed 1 PRs in ...</td>\n",
              "      <td>Периферийного участия</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>User isaigordeev authored 1 PRs, reviewed 0 PR...</td>\n",
              "      <td>Периферийного участия</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>User Shersula authored 1 PRs, reviewed 0 PRs i...</td>\n",
              "      <td>Периферийного участия</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                     label\n",
              "0  User jeroen authored 1 PRs, reviewed 0 PRs in ...     Периферийного участия\n",
              "1  User andrey-khropov authored 0 PRs, reviewed 5...  Кураторства и управления\n",
              "2  User topepo authored 0 PRs, reviewed 1 PRs in ...     Периферийного участия\n",
              "3  User isaigordeev authored 1 PRs, reviewed 0 PR...     Периферийного участия\n",
              "4  User Shersula authored 1 PRs, reviewed 0 PRs i...     Периферийного участия"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загружаем выборку PR и собираем датасет участник → паттерн\n",
        "with open(PR_SAMPLES, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "prs = data.get(\"prs\", [])\n",
        "\n",
        "participants = {}\n",
        "for pr in prs:\n",
        "    author = pr.get(\"author\")\n",
        "    if author:\n",
        "        participants.setdefault(author, {\"authored\": 0, \"reviewed\": 0, \"comments\": 0})\n",
        "        participants[author][\"authored\"] += 1\n",
        "    for user in pr.get(\"participants\", []) or []:\n",
        "        if user and user != author:\n",
        "            participants.setdefault(user, {\"authored\": 0, \"reviewed\": 0, \"comments\": 0})\n",
        "            participants[user][\"reviewed\"] += 1\n",
        "\n",
        "total_prs = len(prs)\n",
        "rows = []\n",
        "for user, stats in participants.items():\n",
        "    label = classify_participant(\n",
        "        username=user,\n",
        "        prs_authored=stats[\"authored\"],\n",
        "        prs_reviewed=stats[\"reviewed\"],\n",
        "        comments_count=stats[\"comments\"],\n",
        "        total_prs=total_prs,\n",
        "    )\n",
        "    participation_rate = (stats[\"authored\"] + stats[\"reviewed\"]) / max(total_prs, 1)\n",
        "    text = (\n",
        "        f\"{user}: authored {stats['authored']} PRs, reviewed {stats['reviewed']} PRs, \"\n",
        "        f\"participation_rate {participation_rate:.2f}\"\n",
        "    )\n",
        "    rows.append({\"text\": text, \"label\": label})\n",
        "\n",
        "print(\"PRs:\", total_prs, \"participants:\", len(rows))\n",
        "pd.DataFrame(rows).head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 7/7 [00:00<00:00, 707.20 examples/s]\n",
            "Map: 100%|██████████| 3/3 [00:00<00:00, 848.53 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Подготавливаем HF Dataset + маппинг меток (stratified split)\n",
        "unique_labels = sorted(set(r[\"label\"] for r in rows))\n",
        "label2id = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
        "id2label = {i: lbl for lbl, i in label2id.items()}\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Распределение классов (для анализа дисбаланса)\n",
        "print(\"=\" * 50)\n",
        "print(\"РАСПРЕДЕЛЕНИЕ ПАТТЕРНОВ В ДАННЫХ\")\n",
        "print(\"=\" * 50)\n",
        "counts = df[\"label\"].value_counts()\n",
        "for label, count in counts.items():\n",
        "    print(f\"  {label}: {count} ({count/len(df)*100:.1f}%)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "min_count = counts.min()\n",
        "if min_count < 2 or len(counts) < 2:\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
        "    print(\"Stratify disabled: min_count=\", min_count, \"classes=\", len(counts))\n",
        "else:\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
        "    print(\"Stratified split: train/test сохраняют пропорции классов\")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "test_ds = Dataset.from_pandas(test_df)\n",
        "\n",
        "model_name = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess(batch):\n",
        "    enc = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "    enc[\"labels\"] = [label2id[lbl] for lbl in batch[\"label\"]]\n",
        "    return enc\n",
        "\n",
        "train_ds = train_ds.map(preprocess, batched=True, remove_columns=[\"text\", \"label\"])\n",
        "test_ds = test_ds.map(preprocess, batched=True, remove_columns=[\"text\", \"label\"])\n",
        "\n",
        "datasets = DatasetDict({\"train\": train_ds, \"test\": test_ds})\n",
        "print(f\"\\nГотово: train={len(train_ds)}, test={len(test_ds)}, classes={len(unique_labels)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipykernel_22448/1337417747.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/home/spectreofoblivion/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.635900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Обучение DistilBERT для классификации паттернов\n",
        "# Алгоритм: fine-tuning предобученного DistilBERT с новым classification head\n",
        "# Оптимизатор: AdamW (lr=3e-5, weight_decay=0.01)\n",
        "# Scheduler: linear warmup + decay (по умолчанию в Trainer)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(unique_labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# Гиперпараметры для полноценного обучения\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./roles-checkpoints\",\n",
        "    num_train_epochs=5,  # больше эпох для лучшей сходимости\n",
        "    per_device_train_batch_size=16,  # увеличенный batch для стабильности градиентов\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-5,  # стандартный LR для fine-tuning BERT\n",
        "    weight_decay=0.01,  # L2 регуляризация\n",
        "    warmup_ratio=0.1,  # 10% шагов на warmup\n",
        "    logging_steps=50,\n",
        "    remove_unused_columns=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=datasets[\"train\"],\n",
        "    eval_dataset=datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(f\"Training on {len(datasets['train'])} samples, evaluating on {len(datasets['test'])} samples\")\n",
        "print(f\"Classes: {len(unique_labels)}, Epochs: {args.num_train_epochs}, Batch: {args.per_device_train_batch_size}\")\n",
        "trainer.train();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/spectreofoblivion/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test size: 3\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "Активного соисполнительства       0.00      0.00      0.00         1\n",
            "   Кураторства и управления       0.00      0.00      0.00         0\n",
            "      Периферийного участия       0.67      1.00      0.80         2\n",
            "\n",
            "                   accuracy                           0.67         3\n",
            "                  macro avg       0.22      0.33      0.27         3\n",
            "               weighted avg       0.44      0.67      0.53         3\n",
            "\n",
            "Confusion matrix:\n",
            " [[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 2]]\n"
          ]
        },
        {
          "ename": "SafetensorError",
          "evalue": "Error while serializing: I/O error: No space left on device (os error 28)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(true_labels, pred_labels, labels\u001b[38;5;241m=\u001b[39mlabels_list, target_names\u001b[38;5;241m=\u001b[39mtarget_names, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, confusion_matrix(true_labels, pred_labels, labels\u001b[38;5;241m=\u001b[39mlabels_list))\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistilbert-finetune-roles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-finetune-roles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:4173\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   4168\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m   4170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   4171\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   4172\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 4173\u001b[0m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4175\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/safetensors/torch.py:307\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    277\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    278\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    279\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m ):\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: I/O error: No space left on device (os error 28)"
          ]
        }
      ],
      "source": [
        "# Оценка модели по ключевым метрикам\n",
        "# - Accuracy: общая доля правильных предсказаний\n",
        "# - Precision: точность (TP / (TP + FP)) — сколько предсказанных верны\n",
        "# - Recall: полнота (TP / (TP + FN)) — сколько реальных найдено\n",
        "# - F1-score: гармоническое среднее precision и recall\n",
        "# - Macro F1: среднее F1 по всем классам (важно при дисбалансе)\n",
        "# - Weighted F1: F1 с весами по размеру класса\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "preds = trainer.predict(datasets[\"test\"])\n",
        "logits = preds.predictions\n",
        "pred_labels = np.argmax(logits, axis=1)\n",
        "true_labels = preds.label_ids\n",
        "\n",
        "labels_list = sorted(id2label)\n",
        "target_names = [id2label[i] for i in labels_list]\n",
        "\n",
        "# Основные метрики\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "macro_f1 = f1_score(true_labels, pred_labels, average=\"macro\", zero_division=0)\n",
        "weighted_f1 = f1_score(true_labels, pred_labels, average=\"weighted\", zero_division=0)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"РЕЗУЛЬТАТЫ ДООБУЧЕНИЯ DistilBERT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Test size: {len(true_labels)} samples\")\n",
        "print(f\"Classes: {len(unique_labels)}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Accuracy:    {accuracy:.2%}\")\n",
        "print(f\"Macro F1:    {macro_f1:.2%}\")\n",
        "print(f\"Weighted F1: {weighted_f1:.2%}\")\n",
        "print(\"-\" * 60)\n",
        "print(\"\\nПодробный отчет по классам:\")\n",
        "print(classification_report(true_labels, pred_labels, labels=labels_list, target_names=target_names, zero_division=0))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, pred_labels, labels=labels_list))\n",
        "\n",
        "# Сохранение модели\n",
        "model.save_pretrained(\"distilbert-finetune-roles\")\n",
        "tokenizer.save_pretrained(\"distilbert-finetune-roles\")\n",
        "print(\"\\nМодель сохранена в distilbert-finetune-roles/\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
