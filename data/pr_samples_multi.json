{
  "repos": [
    "microsoft/vscode",
    "chaoss/augur"
  ],
  "prs": [
    {
      "repo": "microsoft/vscode",
      "number": 283512,
      "author": "roblourens",
      "created_at": "2025-12-15T05:13:34Z",
      "comments": [
        {
          "user": "roblourens",
          "body": "Should validate the location"
        },
        {
          "user": "roblourens",
          "body": "delete this AI slop"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 283256,
      "author": "dmitrivMS",
      "created_at": "2025-12-13T03:59:09Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@dmitrivMS I really like the idea of just having a min height for the chat input, pragmatic, not 100% precise in all cases but probably good enough.\r\n\r\nI have a competing proposal in https://github.com/microsoft/vscode/pull/283263 that is a much simplified change compared to this which I felt suffice. Can you check if there is a case missing? I felt we do not really have to bother about the link, esp. since I think the link is going away soon when we just show all sessions always in the chat view."
        },
        {
          "user": "dmitrivMS",
          "body": "> @dmitrivMS I really like the idea of just having a min height for the chat input, pragmatic, not 100% precise in all cases but probably good enough.\r\n> \r\n> I have a competing proposal in #283263 that is a much simplified change compared to this which I felt suffice. Can you check if there is a case missing? I felt we do not really have to bother about the link, esp. since I think the link is going away soon when we just show all sessions always in the chat view.\r\n\r\nLet me test the same scenarios with your change!"
        },
        {
          "user": "dmitrivMS",
          "body": "@bpasero Tested your change and left feedback in the other PR. Feel free to close this PR if you decide to go with the other one."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 283263,
      "author": "bpasero",
      "created_at": "2025-12-13T06:24:49Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "Here's what I found in testing:\r\n\r\n1) It is a bit strange is that you can see session list with \"Show All Sessions\" but no items or scroll bar:\r\n<img width=\"456\" height=\"217\" alt=\"image\" src=\"https://github.com/user-attachments/assets/fed596b0-73bf-4298-a5ff-0140b6191dae\" />\r\n\r\n2) The input control is getting squished at extremely small heights when you start typing and session list is visible (see the shadows below lines):\r\n<img width=\"412\" height=\"229\" alt=\"image\" src=\"https://github.com/user-attachments/assets/c8be9d63-7bb8-400c-ad9c-887b3df73410\" />\r\n\r\nI'll leave it up to you if you'd like to keep it as is."
        },
        {
          "user": "dmitrivMS",
          "body": "FWIW, I tried increasing the min height constant to mitigate second issue, but that didn't help."
        },
        {
          "user": "bpasero",
          "body": "Thanks, I feel these cases are not very important going forward because I plan to remove the link entirely via https://github.com/microsoft/vscode/issues/281961 so probably not worth the efford."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 283223,
      "author": "dmitrivMS",
      "created_at": "2025-12-12T23:24:52Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "> Not sure I fully understand the suggested fix, but the issue is about hiding the border only when there is a scroll shadow, not always ü§î\r\n\r\nHmm... I must have misunderstood, let me test this a little more."
        },
        {
          "user": "bpasero",
          "body": "@dmitrivMS no worries, this one is a tricky one because I was not able to figure out that a tree would show scroll shadow, at least not with CSS tricks, but I was also not looking very deep.\r\n\r\nThanks for jumping onto my issues that I labeled üôè"
        },
        {
          "user": "dmitrivMS",
          "body": "@bpasero Please consider this updated version:\r\n- When sessions view is stacked, border is present (as well as shadow, when scrollbar shows up)\r\n- When sessions view is SxS, border is hidden and chat panel appearance is consistent with that of sessions view (i.e. shadow shows up on scroll)"
        },
        {
          "user": "bpasero",
          "body": "@dmitrivMS this is almost there, we still want the border to show when there is no scroll shadow here though right?\r\n\r\n<img width=\"760\" height=\"184\" alt=\"image\" src=\"https://github.com/user-attachments/assets/84908f3c-2032-4916-9f42-484af004fd31\" />\r\n\r\nEssentially the expected outcome is to hide the border of the chat view title if the chat widget is scrolled down and thus shows a scroll shadow. Essentially, have the border only removed when this shows:\r\n\r\n<img width=\"772\" height=\"167\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4cf728be-64d1-4de6-a7b3-3939735b27b4\" />\r\n\r\nBecause that is almost like a border aready."
        },
        {
          "user": "dmitrivMS",
          "body": "@bpasero Let me try to update it. Keep in mind though that sessions view has no border, so there will be cases where sessions view has a shadow (only) and chat has a border (only) - is that also expected? Or do we want shadow on the chat even when it's not scrolled but sessions view is scrolled?"
        },
        {
          "user": "bpasero",
          "body": "@dmitrivMS you bring up a good point and maybe I actually misunderstood BenS original ask. Now reading it again, his ask is to remove the title border entirely, so your original PR makes more sense now. I am willing to give that a try, given that we typically do not show a border below a title for example for the editors control either:\r\n\r\n<img width=\"930\" height=\"131\" alt=\"image\" src=\"https://github.com/user-attachments/assets/7bf2ecb4-aec8-4b0c-86cc-7faac5d6d266\" />\r\n\r\nPlease feel free to go back to the solution to just remove the title border."
        },
        {
          "user": "dmitrivMS",
          "body": "@bpasero Done."
        },
        {
          "user": "dmitrivMS",
          "body": "> Thanks! Let's see how this flies next week in insiders in the team.\r\n\r\nI personally like it - it's consistent with other views we have."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 283138,
      "author": "connor4312",
      "created_at": "2025-12-12T20:34:00Z",
      "comments": [
        {
          "user": "cwalther",
          "body": "Are you sure this works? I would say this is always false now, we always land in the `else`. `details` is the same object as `this.stoppedDetails` and you just set its `length` to zero. See my original concerns about these lines in #282777.\r\n\r\nI would suggest replacing line 1333 by `const details = this.stoppedDetails.slice();` or `const details = [...this.stoppedDetails];`."
        },
        {
          "user": "connor4312",
          "body": "Indeed ü§¶"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282969,
      "author": "dmitrivMS",
      "created_at": "2025-12-12T07:54:58Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "It is actually meant to replace only one occurence."
        },
        {
          "user": "mjbvz",
          "body": "Most of our js language features are scoped to the current workspace. Maybe we should do the same here instead of walking outside of the workspace"
        },
        {
          "user": "mjbvz",
          "body": "If the tests need to use the file system, can we mock it out instead? I've found using the real FS is a very common source of flaky tests and slowness"
        },
        {
          "user": "mjbvz",
          "body": "Could this use `require.resolve` or an external npm dependency that does this for us? It's quite a lot of code to add and maintain for a lower impact bug"
        },
        {
          "user": "dmitrivMS",
          "body": "I considered it, but my understanding is that we need to use vscode's FS and `require.resolve` would not do that."
        },
        {
          "user": "dmitrivMS",
          "body": "If we go forward with this, we should probably add a cache for JSONC parse results to avoid reparsing on every call."
        },
        {
          "user": "dmitrivMS",
          "body": "added cache"
        },
        {
          "user": "dmitrivMS",
          "body": "Mocking the FS here is quite some work since TestFS does not appear to be available in extension tests. I can do this, but would like to confirm this will be going in."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282947,
      "author": "bpasero",
      "created_at": "2025-12-12T06:14:06Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "Not sure if we have a better way, but this approach is not ideal for localizing text with numerical values (some languages will have more than two cases)."
        },
        {
          "user": "bpasero",
          "body": "@TylerLeonhardt do you have guidance?"
        },
        {
          "user": "TylerLeonhardt",
          "body": "We don't support pluralization atm https://github.com/microsoft/vscode/issues/283124"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282903,
      "author": "osortega",
      "created_at": "2025-12-12T00:26:22Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@osortega having a service method only for this purpose seems like a lot of overhead, https://github.com/microsoft/vscode/pull/282943 just adds a new method to use and thus avoids the service dependency."
        },
        {
          "user": "osortega",
          "body": "Added it"
        },
        {
          "user": "roblourens",
          "body": "This removed the `&& lastStartedWaitingAt` check around this, is this still right?"
        },
        {
          "user": "osortega",
          "body": "I added it to the else if statement, I believe it's the same logical operation just split, or did I miss something?"
        },
        {
          "user": "roblourens",
          "body": "Sorry I think I read it wrong"
        },
        {
          "user": "connor4312",
          "body": "personally I would tend to make this a free-floating function so that people don't need the whole service just to check the status. I like having a namespace so I get pseudo-methods on the enums like `ChatSessionStatus.isInProgress(state)`\n\nhttps://github.com/microsoft/vscode/blob/17cf1ce11ac873561637f74dadb80dc84a4255d2/src/vs/workbench/contrib/mcp/common/mcpTypes.ts#L576-L588"
        },
        {
          "user": "connor4312",
          "body": "I would perhaps special case this so that we also show \"Needs Input\" sessions when the user filters for \"In Progress\" sessions"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282862,
      "author": "jakebailey",
      "created_at": "2025-12-11T20:18:51Z",
      "comments": [
        {
          "user": "jakebailey",
          "body": "cc @mjbvz"
        },
        {
          "user": "mjbvz",
          "body": "Thanks!"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282861,
      "author": "meganrogge",
      "created_at": "2025-12-11T20:14:42Z",
      "comments": [
        {
          "user": "meganrogge",
          "body": "Yeah I thought about this too."
        },
        {
          "user": "meganrogge",
          "body": "this was actually invalid before - when typing `test/` within `test` folder, we shouldn't have been showing `./test/...`"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282871,
      "author": "joshspicer",
      "created_at": "2025-12-11T21:06:52Z",
      "comments": [
        {
          "user": "joshspicer",
          "body": "Thanks @connor4312  - will resolve these and the setting description changes from standup, and merge back into here."
        },
        {
          "user": "connor4312",
          "body": "we have a helper for this here\n\nhttps://github.com/microsoft/vscode/blob/2c36374fbb1e9de863d2cb6d90691e39e309f8b3/src/vs/platform/observable/common/platformObservableUtils.ts#L12"
        },
        {
          "user": "connor4312",
          "body": "```suggestion\n\t\tconst agentModeEnabled = this._isAgentModeEnabled.read(reader);\n```\n\nis valid"
        },
        {
          "user": "joshspicer",
          "body": "This is needed to properly register the tools"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282742,
      "author": "Tyriar",
      "created_at": "2025-12-11T13:48:44Z",
      "comments": [
        {
          "user": "Tyriar",
          "body": "cc @meganrogge"
        },
        {
          "user": "Tyriar",
          "body": "CI flake, will retry"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282695,
      "author": "Copilot",
      "created_at": "2025-12-11T11:03:07Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "Are any of the copilot's comments worth addressing?"
        },
        {
          "user": "sandy081",
          "body": "Yes addressed here - https://github.com/microsoft/vscode/pull/283527"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282644,
      "author": "MarcusWh-cmu",
      "created_at": "2025-12-11T07:16:09Z",
      "comments": [
        {
          "user": "MarcusWh-cmu",
          "body": "@lszomoru Hi, may I ask why you closed this PR?"
        },
        {
          "user": "lszomoru",
          "body": "We do not accept pull requests that contain changes to the package lock file."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282633,
      "author": "NriotHrreion",
      "created_at": "2025-12-11T05:55:42Z",
      "comments": [
        {
          "user": "connor4312",
          "body": "Looks like a formatting failure:\r\n\r\n```\r\n\r\n[hygiene                  ] src/vs/workbench/contrib/chat/browser/chatWidget.ts(2337,1): Bad whitespace indentation\r\n[hygiene                  ] File not formatted. Run the 'Format Document' command to fix it: src/vs/workbench/contrib/chat/browser/chatWidget.ts\r\n```"
        },
        {
          "user": "connor4312",
          "body": "Hm, looks like one still remains\r\n\r\n```\r\n[hygiene                  ] src/vs/workbench/contrib/chat/browser/chatWidget.ts(2338,1): Bad whitespace indentation\r\n[hygiene                  ] File not formatted. Run the 'Format Document' command to fix it: src/vs/workbench/contrib/chat/browser/chatWidget.ts\r\n\r\n```\r\n\r\nif you open the file in vscode you should be able to ctrl+shift+p > Format Document to apply formatting"
        },
        {
          "user": "NriotHrreion",
          "body": "It should be ok now"
        },
        {
          "user": "connor4312",
          "body": "```suggestion\n\t// Whether to store the input to history. This defaults to 'true' if the input\n\t// box's current content is being accepted, or 'false' if a specific input\n\t// is being submitted to the widget.\n\tstoreToHistory?: boolean;\n```"
        },
        {
          "user": "connor4312",
          "body": "```suggestion\n\t\tthis.input.acceptInput(options?.storeToHistory ?? isUserQuery);\n```"
        },
        {
          "user": "connor4312",
          "body": "```suggestion\n\t\twidget.acceptInput(inputBeforeClear, { storeToHistory: true });\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282609,
      "author": "jruales",
      "created_at": "2025-12-11T01:28:29Z",
      "comments": [
        {
          "user": "kycutler",
          "body": "Let's just add Esc to the keycodes we bubble up. I think we'll want other shortcuts using it too, like cancelling element selection"
        },
        {
          "user": "kycutler",
          "body": "Do we still send an event with loading:false?"
        },
        {
          "user": "kycutler",
          "body": "Can we just do this in the model? i.e. have it optimistically set itself to loading: true / false, and prevent sending the event from there. Then maybe we can remove the timeout too?"
        },
        {
          "user": "jruales",
          "body": "done"
        },
        {
          "user": "jruales",
          "body": "The `did-stop-loading` event is fired right after the `did-fail-load` event when the user stops the loading. So loading:false still happens. Do you prefer that I be more explicit by unconditionally setting `fireLoadingEvent(false);` here?"
        },
        {
          "user": "jruales",
          "body": "The reason we need to keep the timeout is that I'm trying to achieve is an experience similar to Chrome and Edge, where there's a delay between clicking on the reload button and the time when the reload button turns into the Stop Loading button. We also don't want to mess with the loading state itself because we don't want this 500ms cooldown to apply to other aspects, such as showing the loading spinner.\n\nI can however remove this no-op-enforcing code, since the most important part of the cooldown isn't to prevent double reloads, but rather to prevent accidental Stop Loading after a reload. I'll remove this now.\n\nPlease let me know if there's anything else you would suggest here."
        },
        {
          "user": "jruales",
          "body": "added an explicit loading:false just for clarity, even though not strictly necessary"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282545,
      "author": "sejal77patil77-design",
      "created_at": "2025-12-10T17:53:58Z",
      "comments": [
        {
          "user": "sejal77patil77-design",
          "body": "git init"
        },
        {
          "user": "sejal77patil77-design",
          "body": "git remote add origin https://github.com/your-username/your-repo.git"
        },
        {
          "user": "sejal77patil77-design",
          "body": "git status"
        },
        {
          "user": "sejal77patil77-design",
          "body": "git add ."
        },
        {
          "user": "sejal77patil77-design",
          "body": "git add student.demo"
        },
        {
          "user": "Crackle2K",
          "body": "Doesn't appear to add anything, did you make this pull request by mistake?"
        },
        {
          "user": "erbanku",
          "body": "Please do not waste community effort by submitting random test pull requests.\r\nWe know you're newbie and just registered yesterday, lol.\r\n> [!TIP]\r\n> Public Info \r\n```json\r\n{\r\n  \"login\": \"sejal77patil77-design\",\r\n  \"id\": 248928496,\r\n  \"node_id\": \"U_kgDODtZY8A\",\r\n  \"avatar_url\": \"https://avatars.githubusercontent.com/u/248928496?v=4\",\r\n  \"gravatar_id\": \"\",\r\n  \"url\": \"https://api.github.com/users/sejal77patil77-design\",\r\n  \"html_url\": \"https://github.com/sejal77patil77-design\",\r\n  \"followers_url\": \"https://api.github.com/users/sejal77patil77-design/followers\",\r\n  \"following_url\": \"https://api.github.com/users/sejal77patil77-design/following{/other_user}\",\r\n  \"gists_url\": \"https://api.github.com/users/sejal77patil77-design/gists{/gist_id}\",\r\n  \"starred_url\": \"https://api.github.com/users/sejal77patil77-design/starred{/owner}{/repo}\",\r\n  \"subscriptions_url\": \"https://api.github.com/users/sejal77patil77-design/subscriptions\",\r\n  \"organizations_url\": \"https://api.github.com/users/sejal77pati"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282524,
      "author": "fabio-andre-rodrigues",
      "created_at": "2025-12-10T16:29:45Z",
      "comments": [
        {
          "user": "fabio-andre-rodrigues",
          "body": "@microsoft-github-policy-service agree [company=\"OutSystems\"]"
        },
        {
          "user": "fabio-andre-rodrigues",
          "body": "@microsoft-github-policy-service agree company=\"OutSystems\""
        },
        {
          "user": "fabio-andre-rodrigues",
          "body": "The third fallback check remains because if the second find returns nothing and there are lines, all lines are success messages, so we shouldn't use the first line. The check now uses the SUCCESS_PATTERNS constant instead of duplicating the patterns."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282522,
      "author": "meganrogge",
      "created_at": "2025-12-10T16:24:28Z",
      "comments": [
        {
          "user": "anthonykim1",
          "body": "Just verified this, I think we are good just with the shell type defined in lspCompletionAddonProvider:\r\n\r\nhttps://github.com/user-attachments/assets/122c1d34-d4ac-4c1f-af5a-761e5c35621e"
        },
        {
          "user": "meganrogge",
          "body": "Yeah we should probably do this"
        },
        {
          "user": "meganrogge",
          "body": "As we discussed, I think we should hardcode `shellType` to `GeneralShellType.Python` here so that this only gets invoked for that `shellType`. It also simplifies things."
        },
        {
          "user": "meganrogge",
          "body": "So we can revert these changes"
        },
        {
          "user": "Tyriar",
          "body": "```suggestion\n\treadonly shellTypes: TerminalShellType[] = [GeneralShellType.Python];\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282528,
      "author": "rzhao271",
      "created_at": "2025-12-10T16:44:42Z",
      "comments": [
        {
          "user": "rzhao271",
          "body": "Verification build: https://dev.azure.com/monacotools/Monaco/_build/results?buildId=383769&view=results\r\n\r\nI'd also like to check how much the macOS and Linux binaries grow in size."
        },
        {
          "user": "anthonykim1",
          "body": "I think we should also update the conpty version to v1.23.251008001 that comes with the node-pty bump. \r\nhttps://github.com/microsoft/vscode/pull/282291/files \r\n\r\nI'll manually test again once build passes. \r\n\r\n/cc @Tyriar"
        },
        {
          "user": "rzhao271",
          "body": "New verification build: https://dev.azure.com/monacotools/Monaco/_build/results?buildId=383805&view=results"
        },
        {
          "user": "rzhao271",
          "body": "New verification build: https://dev.azure.com/monacotools/Monaco/_build/results?buildId=383817&view=results"
        },
        {
          "user": "deepak1556",
          "body": "@rzhao271 update the cachesalt, x64 ran with cache that has prebuilds not removed https://dev.azure.com/monacotools/Monaco/_build/results?buildId=383817&view=logs&jobId=12844632-35fb-5b51-892a-9f6fe8a80e65&j=c3c6d686-fd72-58b2-fb22-32758a96abc0&t=43669b33-f7cc-5b15-d4df-074717949166 leading to the universal step failure."
        },
        {
          "user": "rzhao271",
          "body": "New verification build: https://dev.azure.com/monacotools/Monaco/_build/results?buildId=383839&view=results"
        },
        {
          "user": "rzhao271",
          "body": "Closing now that we have https://github.com/microsoft/node-pty/pull/829"
        },
        {
          "user": "deepak1556",
          "body": "Adding here would be a noop since we haven't installed deps for this directory, remove and add it in https://github.com/microsoft/vscode/blob/f1db08ab87ec1108d0e3c2a20c7ffe5b8a55a23b/build/npm/postinstall.ts#L71 for other directories"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282431,
      "author": "ThanhNguyxn",
      "created_at": "2025-12-10T09:27:51Z",
      "comments": [
        {
          "user": "deepak1556",
          "body": "The fix needs to happen here https://github.com/microsoft/vscode/blob/55ca4093e1be31fe9b974931f9c86ce80e1aaf00/extensions/tunnel-forwarding/src/extension.ts#L26-L30"
        },
        {
          "user": "ThanhNguyxn",
          "body": "Thanks @deepak1556 for pointing out the correct location! \n\nI've updated the PR to apply the fix in `extensions/tunnel-forwarding/src/extension.ts` instead of `cli.ts`. Changed the path from `../../bin` to `../bin` to correctly resolve the tunnel command path on Windows Insiders."
        },
        {
          "user": "ThanhNguyxn",
          "body": "Updated the PR based on @deepak1556's feedback:\n\n1. **Moved fix to the correct location** (`extensions/tunnel-forwarding/src/extension.ts`)\n2. **Corrected the path**: Changed from `../../bin` to `../../../bin` for Windows Insiders\n\nThe key insight is that `vscode.env.appRoot` on Windows Insiders points to `<root>/<version>/resources/app`, so we need 3 levels up (`../../../`) to reach the root `bin` folder, not 2 levels.\n\nPath analysis:\n```\nFrom: resources/app (appRoot)\n  ../../bin     ‚Üí <version>/bin  ‚ùå (doesn't exist)\n  ../../../bin  ‚Üí root/bin       ‚úÖ (correct!)\n```"
        },
        {
          "user": "ThanhNguyxn",
          "body": "Apologies for the messy commit history earlier - I had some confusion about the correct path resolution. The PR should now be clean with just the single correct fix. Thanks for your patience! üôè"
        },
        {
          "user": "deepak1556",
          "body": "```suggestion\r\n\t\t\t: process.platform === 'win32' && vscode.env.appQuality === 'insider'\r\n\t\t\t\t? '../../../bin' // TODO: remove as part of https://github.com/microsoft/vscode/issues/282514\r\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282403,
      "author": "Joemarcos99",
      "created_at": "2025-12-10T04:49:46Z",
      "comments": [
        {
          "user": "Joemarcos99",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "bpasero",
          "body": "This is a workaround I am not accepting due to layer issues."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282311,
      "author": "MohamedEmirHajji",
      "created_at": "2025-12-09T22:24:23Z",
      "comments": [
        {
          "user": "MohamedEmirHajji",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "Tyriar",
          "body": "@meganrogge I didn't test it, but skimming it looks good."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282291,
      "author": "anthonykim1",
      "created_at": "2025-12-09T20:06:40Z",
      "comments": [
        {
          "user": "anthonykim1",
          "body": "Still seem to run fine when tested locally with oss. \r\nTesting locally on OSS should be enough, right? @Tyriar"
        },
        {
          "user": "Tyriar",
          "body": "Seems to be working now ü§∑ not sure what was happening before."
        },
        {
          "user": "anthonykim1",
          "body": "I also updated the conpty dll version defined in the setting to reflect update from node-pty"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282265,
      "author": "meganrogge",
      "created_at": "2025-12-09T17:24:18Z",
      "comments": [
        {
          "user": "Tyriar",
          "body": "Easy repro in pwsh, replace `d:\\Playground\\many_files` with an empty temp folder:\r\n\r\n```\r\n1..20000 | ForEach-Object { [System.IO.File]::Create(\"d:\\Playground\\many_files\\file$_.txt\").Dispose() }\r\n```\r\n\r\nThen type `./` and it's really laggy."
        },
        {
          "user": "Tyriar",
          "body": "@meganrogge also you should be able to repro on mac by temporarily removing these ifs and doing that on mac too:\r\n\r\nhttps://github.com/microsoft/vscode/blob/ac14caf723fb772d6afe8f8a26865a7efc649b95/extensions/terminal-suggest/src/helpers/executable.ts#L10-L13\r\n\r\nhttps://github.com/microsoft/vscode/blob/ac14caf723fb772d6afe8f8a26865a7efc649b95/extensions/terminal-suggest/src/env/pathExecutableCache.ts#L35-L43"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282201,
      "author": "joaomoreno",
      "created_at": "2025-12-09T12:50:44Z",
      "comments": [
        {
          "user": "Tyriar",
          "body": "-Command is not an execution policy?"
        },
        {
          "user": "joaomoreno",
          "body": "Thank you!"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282192,
      "author": "chaitanyamedidar",
      "created_at": "2025-12-09T11:17:55Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "This looks risky and fragile, but I want to give @mrleemurray a chance to chime in on this."
        },
        {
          "user": "chaitanyamedidar",
          "body": "# Technical Breakdown: Status Bar Vertical Alignment Fix\r\n\r\nThe Status Bar is using `display: flex` and `align-items: center`, which mathematically aligns all elements to the center. However, fonts like Segoe UI and San Francisco reserve invisible space for ascenders and descenders, causing text to appear visually lower than the center even when mathematically aligned.\r\n\r\nTo resolve this, I implemented a solution using `transform` and `line-height`.\r\n\r\n## My Solution: `transform` + `line-height`\r\n\r\n### 1. `transform: translateY(-1px)` on the Label\r\n\r\n*   **Its Purpose** It moves the text up by 1 pixel at the compositor level.\r\n*   **Safety:** It does **not** trigger a layout recalculation (reflow). It does not change the height of the status bar. It does not affect the position of neighboring items. It is purely visual.\r\n*   **Fragility:** Low. It is an integer pixel shift, which renders cleanly on all screens (no sub-pixel blurring).\r\n\r\n### 2. `transform: translateY(1px)` on the Icon "
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282152,
      "author": "anthonykim1",
      "created_at": "2025-12-09T06:59:17Z",
      "comments": [
        {
          "user": "meganrogge",
          "body": "Let's go with `alert` per feedback!"
        },
        {
          "user": "anthonykim1",
          "body": "@meganrogge Should we also add keybinding to this command? \nI'm not sure if we want something along the line with ctrl+g which was the old \"hacky\" way of folks accessing this info."
        },
        {
          "user": "anthonykim1",
          "body": "@meganrogge Do you think this would be the best/most appropriate place to register this command?\r\nOther places I've been debating are:\r\n1.  `src\\vs\\workbench\\contrib\\accessibilitySignals\\browser\\commands.ts`  \r\n2. `src\\vs\\workbench\\contrib\\accessibility\\browser\\accessibleViewActions.ts`"
        },
        {
          "user": "meganrogge",
          "body": "Wondering if `alt/option+shift+g` would be good ? @jooyoungseo and @rperez030 might know. We can ask on Friday!"
        },
        {
          "user": "meganrogge",
          "body": "This looks fine to me!"
        },
        {
          "user": "meganrogge",
          "body": "They also mentioned `ctrlCmd+shift+g`"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282079,
      "author": "kycutler",
      "created_at": "2025-12-08T22:37:22Z",
      "comments": [
        {
          "user": "kycutler",
          "body": "Here we enabled additional heap space for some scripts, but many (including ci scripts) did not use it"
        },
        {
          "user": "jruales",
          "body": "This package.json has been doing something like this for years. How come it wasn't an issue before?"
        },
        {
          "user": "kycutler",
          "body": "Not exactly sure -- we may just be using more memory during builds due to code / build changes over time."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282067,
      "author": "DonJayamanne",
      "created_at": "2025-12-08T20:57:09Z",
      "comments": [
        {
          "user": "Tyriar",
          "body": "This code flows a little strangely, `newSession` and `originalModel` are both scoped to their own {} block. The fact that it's using a `{}` block though makes me think there's some reason it's being used but I don't think there is a good reason?\n\nAlso can/should we use `newSession` instead of looking it up again below?"
        },
        {
          "user": "DonJayamanne",
          "body": "Agreed, fixed"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282054,
      "author": "Copilot",
      "created_at": "2025-12-08T19:44:45Z",
      "comments": [
        {
          "user": "meganrogge",
          "body": "@copilot now the workspace profiles don't show up in the quickpick."
        },
        {
          "user": "meganrogge",
          "body": "@copilot shouldn't we have fixed how that was handled in the backend vs inspecting again in the frontend?"
        },
        {
          "user": "meganrogge",
          "body": "That change once again caused the `workspaceProfiles` to be undefined."
        },
        {
          "user": "meganrogge",
          "body": "@copilot workspace profiles are undefined. check how `configScope` is set - seems like it's not"
        },
        {
          "user": "meganrogge",
          "body": "@copilot revert the ptyHost changes, go back to just inspecting on the renderer side"
        },
        {
          "user": "Tyriar",
          "body": "@copilot this should do the inspect in `detectAvailableProfiles` in terminalProfiles.ts and then pass that info back from the profile via `ITerminalProfile.configScope`:\n\nhttps://github.com/microsoft/vscode/blob/ff0ce2caaaf9a001d875e8907947d2383cf390f0/src/vs/platform/terminal/node/terminalProfiles.ts#L29-L67\n\nWe want a single consolidated place that the config is touched, otherwise features that depend on this scope in the future will need to reimplement, refactor, etc. It also introduces the chance of mismatches; what if a user and workspace profile have the same name for example."
        },
        {
          "user": "meganrogge",
          "body": "@Tyriar this broke things - workspace config does not exist in the pty service."
        },
        {
          "user": "meganrogge",
          "body": "@copilot filter profiles from workspace such that if they're already included in user, we don't add them again"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 282025,
      "author": "Copilot",
      "created_at": "2025-12-08T17:52:35Z",
      "comments": [
        {
          "user": "meganrogge",
          "body": "@copilot tests are failing figure out why and fix that"
        },
        {
          "user": "meganrogge",
          "body": "@copilot fix it so tests don't fail\r\n\r\n```\r\n\r\n  1) TerminalCompletionService\r\n       ~ -> $HOME\r\n         ~/| with remote SSH URI scheme should respect remote scheme:\r\n\r\n      \r\n      + expected - actual\r\n\r\n       [\r\n         {\r\n      -    \"detail\": \"\\\\home\\\\/\"\r\n      +    \"detail\": \"\\\\home\\\\\"\r\n           \"kind\": 1\r\n      -    \"label\": \"~/\"\r\n      +    \"label\": \"~\\\\\"\r\n           \"replacementRange\": [\r\n             0\r\n             2\r\n           ]\r\n         }\r\n         {\r\n      -    \"detail\": \"\\\\home\\\\vscode/\"\r\n      +    \"detail\": \"\\\\home\\\\vscode\\\\\"\r\n           \"kind\": 1\r\n      -    \"label\": \"~/vscode/\"\r\n      +    \"label\": \"~\\\\vscode\\\\\"\r\n           \"replacementRange\": [\r\n             0\r\n             2\r\n           ]\r\n      \r\n  AssertionError: [{\"label\":\"~/\",\"detail\":\"\\\\home\\\\/\",\"kind\":1,\"replacementRange\":[0,2]},{\"label\":\"~/vscode/\",\"detail\":\"\\\\home\\\\vscode/\",\"kind\":1, deepStrictEqual [{\"label\":\"~\\\\\",\"detail\":\"\\\\home\\\\\",\"kind\":1,\"replacementRange\":[0,2]},{\"label\":\"~\\\\vscode\\\\\",\"detail\":"
        },
        {
          "user": "meganrogge",
          "body": "@copilot The followings tests are failing:\r\n - TerminalCompletionService ~ -> $HOME ~/| with remote SSH URI scheme should respect remote scheme (reason: [{\"label\":\"~/\",\"detail\":\"/home/\",\"kind\":1,\"replacementRange\":[0,2]},{\"label\":\"~/vscode/\",\"detail\":\"/home/vscode/\",\"kind\":1,\"repl deepStrictEqual [{\"label\":\"~\\\\\",\"detail\":\"\\\\home\\\\\",\"kind\":1,\"replacementRange\":[0,2]},{\"label\":\"~\\\\vscode\\\\\",\"detail\":\"\\\\home\\\\vscode\\\\\",\"kind\")\r\n - TerminalCompletionService resolveResources edge cases and advanced scenarios C:/Foo/| absolute paths on Windows (reason: [{\"label\":\"C:\\\\Foo\\\\\",\"detail\":\"C:\\\\Foo\\\\\",\"kind\":1,\"replacementRange\":[0,7]}] deepStrictEqual [{\"label\":\"C:\\\\Foo\\\\\",\"detail\":\"C:\\\\Foo\\\\\",\"kind\":1,\"replacementRange\":[0,7]},{\"label\":\"C:\\\\Foo\\\\Bar\\\\\",\"detail\":\"C:\\\\Foo\\\\Bar\\\\)\r\n - TerminalCompletionService resolveResources edge cases and advanced scenarios c:/foo/| case insensitivity on Windows (reason: [{\"label\":\"c:\\\\foo\\\\\",\"detail\":\"C:\\\\foo\\\\\",\"kind\":1,\"replacementRange\":[0,7]}] deepStrictEqua"
        },
        {
          "user": "meganrogge",
          "body": "@tyriar I can reproduce on WSL, so have made a custom build to test this out."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281875,
      "author": "tuzixiangs",
      "created_at": "2025-12-08T07:54:10Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "I think to be on the safe side we should define a basic product service standalone."
        },
        {
          "user": "tuzixiangs",
          "body": "> I think to be on the safe side we should define a basic product service standalone.ÊàëËÆ§‰∏∫‰∏∫‰∫ÜÂÆâÂÖ®Ëµ∑ËßÅÔºåÊàë‰ª¨Â∫îËØ•ÂÆö‰πâ‰∏Ä‰∏™Âü∫Êú¨ÁöÑ‰∫ßÂìÅÊúçÂä°Áã¨Á´ãÁâàÊú¨„ÄÇ\r\n\r\n@bpasero Thanks for the suggestion! I've updated the PR to implement a `StandaloneProductService` as you recommended.\r\n\r\nThe changes now include:\r\n- A `StandaloneProductService` class with sensible defaults (quality: 'stable', nameShort: 'Monaco Editor', etc.)\r\n- Service registration in `standaloneServices.ts`\r\n- Simplified `clipboard.ts` that directly uses `IProductService`\r\n\r\nPlease let me know if there are any adjustments needed! üôè"
        },
        {
          "user": "tuzixiangs",
          "body": "> @tuzixiangs please read the following Contributor License Agreement(CLA). If you agree with the CLA, please reply with the following information.ËØ∑ÈòÖËØª‰ª•‰∏ãË¥°ÁåÆËÄÖËÆ∏ÂèØÂçèËÆÆÔºàCLAÔºâ„ÄÇÂ¶ÇÊûúÊÇ®ÂêåÊÑè CLAÔºåËØ∑ÂõûÂ§ç‰ª•‰∏ã‰ø°ÊÅØ„ÄÇ\r\n> \r\n> ```\r\n> @microsoft-github-policy-service agree [company=\"{your company}\"]\r\n> ```\r\n> \r\n> > Options:¬†¬†ÈÄâÈ°πÔºö\r\n> > \r\n> > * (default - no company specified) I have sole ownership of intellectual property rights to my Submissions and I am not making Submissions in the course of work for my employer.ÔºàÈªòËÆ§ - Êú™ÊåáÂÆöÂÖ¨Âè∏ÔºâÊàëÂØπÊàëÁöÑÊèê‰∫§Êã•ÊúâÂÆåÂÖ®ÁöÑÁü•ËØÜ‰∫ßÊùÉÔºåÂπ∂‰∏îÊàëÂπ∂Èùû‰ª£Ë°®Èõá‰∏ªÂú®Â∑•‰ΩúËøáÁ®ã‰∏≠ËøõË°åÊèê‰∫§„ÄÇ\r\n> > \r\n> > ```\r\n> > @microsoft-github-policy-service agree\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > \r\n> > * (when company given) I am making Submissions in the course of work for my employer (or my employer has intellectual property rights in my Submissions by contract or applicable law). I have permission from my employer to make Submissions and enter into this Agreement on behalf of my employer."
        },
        {
          "user": "hediet",
          "body": "@aiday-mar do we still need that telemetry event? I'd like to avoid defining the product service for the monaco editor."
        },
        {
          "user": "aiday-mar",
          "body": "HI @hediet I am not quite sure what telemetry event we are talking about. I don't recall adding telemetry in this field."
        },
        {
          "user": "hediet",
          "body": "@aiday-mar it's about this code: https://github.com/microsoft/vscode/blob/main/src/vs/editor/contrib/clipboard/browser/clipboard.ts#L309-L323"
        },
        {
          "user": "aiday-mar",
          "body": "I see, I am not sure if this is needed. I suppose it would be okay to delete it."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281765,
      "author": "adityaonx",
      "created_at": "2025-12-07T09:39:28Z",
      "comments": [
        {
          "user": "adityaonx",
          "body": "@bpasero @deepak1556 @hediet no updates as of now?"
        },
        {
          "user": "deepak1556",
          "body": "As mentioned before we are just trading one bug for another https://github.com/microsoft/vscode/pull/245208#issuecomment-2769622491\r\n\r\nWith regards to https://github.com/microsoft/vscode/pull/245208#issuecomment-2774544780 the `RemoveRedirectionBitmap` feature is enabled by default in our latest insiders https://code.visualstudio.com/insiders and I can repro the issue with it. Requires a followup in the runtime."
        },
        {
          "user": "adityaonx",
          "body": "@deepak1556 but this does solve the major concern of having the white flash which a much more bigger issue right now than a ultimate fix. Until we have a proper fix, this mitigation is better for temporary fix. Don't you think it will save many from white flashes everytime?"
        },
        {
          "user": "deepak1556",
          "body": "I am not suggesting one bug is reasonable than other, if you have workaround proposal that keeps the mitigation for https://github.com/microsoft/vscode/pull/245208#issuecomment-2769622491 and also address the white flash, happy to review it. Otherwise, all I am saying is there is a concrete repro for the runtime https://github.com/electron/electron/issues/35362 and would be good to spend some cycles pursuing a fix based on https://chromium-review.googlesource.com/c/chromium/src/+/6092335"
        },
        {
          "user": "adityaonx",
          "body": "@deepak1556,\r\nAlthough we have a dark window instead of white but it's way better than the white flash. That's why for now I recommend merging this workaround immediately.\r\nThe current \"flashbang\" behavior upon opening VS Code is a serious accessibility and user experience issue causing eye strain. This PR provides a major, essential temporary fix that will prevent this disruption for most users.\r\nGiven the time needed for a proper, permanent solution, merging this now offers crucial and immediate user relief. We can easily revert this when came up with the final fix.\r\n\r\nhttps://github.com/user-attachments/assets/bc6a83fb-c6b2-48a3-afff-b2dcc7afb877\r\n\r\n\r\nPlease approve this merge to secure user comfort for now because in Open-source community and forums I got user concerns and major stress with this long standing flashing issue."
        },
        {
          "user": "adityaonx",
          "body": "@deepak1556 @bpasero please review and merge this PR as early fix to mitigate this ongoing issue of the White Flash until we work for the ultimate fix. It's been a long standing issue which is making people irritated as it happens to everyone using Windows OS Full-screen in dark mode. This PR will atleast will give relief to our eyes. We are waiting for a proper fix from a long time but until that it would be nice to consider this one as of now."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281662,
      "author": "joshspicer",
      "created_at": "2025-12-06T01:13:30Z",
      "comments": [
        {
          "user": "connor4312",
          "body": "It looks like this reference is leaked"
        },
        {
          "user": "joshspicer",
          "body": "of course, thanks. fixed."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281621,
      "author": "osortega",
      "created_at": "2025-12-05T21:51:17Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@osortega if this change is still relevant, rebase it onto `release/1.107` branch and make sure to bring it to `main` as well."
        },
        {
          "user": "rebornix",
          "body": "we want to dispose `chatModelRef` at the end"
        },
        {
          "user": "rebornix",
          "body": "I'm not very sure about the command registration heuristics we had here. Is it fine that we don't register the command in core or extensions `package.json`?"
        },
        {
          "user": "roblourens",
          "body": "Who's going to dispose this?"
        },
        {
          "user": "roblourens",
          "body": "This returned a reference too, who owns it?"
        },
        {
          "user": "roblourens",
          "body": "It's preferable to call a function than do `executeCommand`. That way it's type-safe"
        },
        {
          "user": "roblourens",
          "body": "Where is the command to show the changes implemented? I assume the session needs to stay alive as long as the diff editor is open, how are those two things associated?"
        },
        {
          "user": "osortega",
          "body": "Disposing now"
        },
        {
          "user": "osortega",
          "body": "I removed the core command but still we depend on the extensions one, I think this should be part of the API in the future"
        },
        {
          "user": "osortega",
          "body": "I tracked this and looks like it gets disposed right after loading it because we re-render the action bar and this view gets disposed.\r\nIt felt a bit weird that it's kind of a side effect that if the UI does something different then this will leak so I ended up registering to an event that fires when the editing session editor pane closes"
        },
        {
          "user": "osortega",
          "body": "Changed it so that we keep a reference and dispose it accordingly.\r\nThis command is owned by the chat extension"
        },
        {
          "user": "osortega",
          "body": "Changed it to be a function"
        },
        {
          "user": "roblourens",
          "body": "This is an action view item, on the toolbar, on the list template. You have a chance that the list will dispose the template at some point when it scrolls out of view. Once that happens, this will be disposed and your listener won't work. And if it scrolls out of view, the button would be reused for a different session (I don't think this would break anything as is, it would just be weird)\n\nThe button shouldn't own the reference to the ChatModel, they are independent. Now that I see how `editingSession.show()` works, I think the editing session should acquire a reference as long as the editor is visible. Or, something else external which can watch the editor should hold it."
        },
        {
          "user": "roblourens",
          "body": "I don't know why this uses this way of opening the editor, vs `IEditorService.openEditor`. I see `IEditorService.onDidCloseEditor` and I wonder if that's a safer event to listen on? Not sure"
        },
        {
          "user": "rebornix",
          "body": "> the editing session should acquire a reference as long as the editor is visible\r\n\r\nThis is how I expect it to work properly with chat model ref counting. `chatService.getSession(resource);` should not be used to get the chat model as it can be disposed by others (who acquire chat model via `loadSessionForResource`)."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281536,
      "author": "odinGitGmail",
      "created_at": "2025-12-05T14:52:58Z",
      "comments": [
        {
          "user": "odinGitGmail",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "connor4312",
          "body": "Hm, looks like these tests fail on Windows:\r\n\r\n```\r\n\r\n  1) Debug - Link Detector\r\n       mixedStackTraceFormats:\r\n\r\n      \r\n      + expected - actual\r\n\r\n      -false\r\n      +true\r\n      \r\n  AssertionError: false == true\r\n  \tat Context.<anonymous> (http://localhost:58316/c1bccc748c2f775b6f519880fdd91232/out/vs/workbench/contrib/debug/test/browser/linkDetector.test.js:222:5)\r\n\r\n\r\n\r\n2025-12-13T00:07:57.284Z pw:browser [pid=6476] <gracefully close start>\r\n2025-12-13T00:07:57.314Z pw:browser [pid=6476] <process did exit: exitCode=0, signal=null>\r\n2025-12-13T00:07:57.314Z pw:browser [pid=6476] starting temporary directories cleanup\r\n2025-12-13T00:07:57.321Z pw:browser [pid=6476] finished temporary directories cleanup\r\n2025-12-13T00:07:57.321Z pw:browser [pid=6476] <gracefully close end>\r\nThe followings tests are failing:\r\n - Debug - Link Detector mixedStackTraceFormats (reason: false == true)\r\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281485,
      "author": "mrleemurray",
      "created_at": "2025-12-05T10:52:03Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "Goes into https://github.com/microsoft/vscode/pull/281447"
        },
        {
          "user": "mrleemurray",
          "body": "@bpasero I'll add them there"
        },
        {
          "user": "bpasero",
          "body": "@mrleemurray I did that already!"
        },
        {
          "user": "mrleemurray",
          "body": "Ha, you're too quick!"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281505,
      "author": "tamuratak",
      "created_at": "2025-12-05T12:10:49Z",
      "comments": [
        {
          "user": "roblourens",
          "body": "I can't repro the issue, and I don't see why this is necessary. Why isn't it enough to clear these parts the next time the template is reused?"
        },
        {
          "user": "tamuratak",
          "body": "I asked gpt-5.1-codex-mini to make the issue reproducible, and it proposed the following change. It adds an artificial delay inside `onDidChangeItems`. Even with this change, I can still see the issue.\r\n\r\n- https://github.com/tamuratak/vscode/tree/make_codebloack_bug_reproducible\r\n\r\nreproduce steps:\r\n\r\n1. Start a new chat.\r\n2. Type the prompt.\r\n3. Move the session to the editor area.\r\n4. Close the chat in the editor area.\r\n5. Restore the session in the chat.\r\n\r\nprompt\r\n\r\n~~~\r\noutput the following three times:\r\n\r\naaa message\r\n\r\n```text\r\na\r\n\r\n\r\na\r\n\r\n\r\n\r\na\r\n\r\n\r\n\r\n\r\na\r\n\r\n\r\n\r\na\r\n\r\n\r\n\r\naaaa\r\n\r\nbbb\r\n\r\n\r\naa\r\n```\r\n~~~\r\n\r\n--- \r\ngpt-5.1-codex-mini's explanation:\r\n\r\nThe bug where code blocks disappear when reloading a saved chat session happens because `ChatListItemRenderer` keeps reusing the template and code-block caches from the previous session. The change delays `onDidChangeItems` by `SAVED_SESSION_BUG_REPRO_DELAY_MS` when a saved session is loaded, slowing down the Tree update and progressiv"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281474,
      "author": "justschen",
      "created_at": "2025-12-05T09:37:34Z",
      "comments": [
        {
          "user": "justschen",
          "body": "we used to return early, which would lead to the wrong spinner behavior"
        },
        {
          "user": "justschen",
          "body": "we never want to show the working spinner in any thinking scenario anymore, since it shows in the header now, this check was leftover from when we used to show it"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281482,
      "author": "joaomoreno",
      "created_at": "2025-12-05T10:33:47Z",
      "comments": [
        {
          "user": "joaomoreno",
          "body": "Merging changes into https://github.com/microsoft/vscode/pull/281447"
        },
        {
          "user": "joaomoreno",
          "body": "```suggestion\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281519,
      "author": "yavanosta",
      "created_at": "2025-12-05T13:33:08Z",
      "comments": [
        {
          "user": "yavanosta",
          "body": "I think workflows need to be approved to run since I'm not from VSCode team.\r\n\r\nThanks for review!"
        },
        {
          "user": "yavanosta",
          "body": "Fixed code style error."
        },
        {
          "user": "dmitrivMS",
          "body": "CI is failing... I've reran failing jobs."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281450,
      "author": "osortega",
      "created_at": "2025-12-05T06:20:53Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@osortega just fyi, any changes going forward that are for November also need to be manually backported into the `release/1.107` branch."
        },
        {
          "user": "osortega",
          "body": "> @osortega just fyi, any changes going forward that are for November also need to be manually backported into the `release/1.107` branch.\r\n\r\nYeah I'm debating whether we want to include this or not, this seems a bit of an edge case any thoughts?"
        },
        {
          "user": "osortega",
          "body": "@copilot open a new pull request to apply changes based on [this feedback](https://github.com/microsoft/vscode/pull/281450#discussion_r2591565752)"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281447,
      "author": "bpasero",
      "created_at": "2025-12-05T05:36:58Z",
      "comments": [
        {
          "user": "joaomoreno",
          "body": "fixes #281448\r\nexploration: https://jsfiddle.net/kb2n9j86/1/\r\n\r\n\r\n\r\nhttps://github.com/user-attachments/assets/ce7039d3-0c9e-4148-8617-1c7add9f9484"
        },
        {
          "user": "OrenMe",
          "body": "Great fixes\nI also raised a few possible improvements here if this feedback helps https://github.com/microsoft/vscode/issues/281512"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281430,
      "author": "justschen",
      "created_at": "2025-12-05T03:38:06Z",
      "comments": [
        {
          "user": "justschen",
          "body": "with background sessions, we want things to continue in the background, so we never want to prematurely end any thinking parts just because of a context switch"
        },
        {
          "user": "justschen",
          "body": "update this logic so we don't return early"
        },
        {
          "user": "justschen",
          "body": "we don't want to show the working spinner REGARDLESS of the thinking style anyways"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281387,
      "author": "hawkticehurst",
      "created_at": "2025-12-04T23:11:45Z",
      "comments": [
        {
          "user": "benibenj",
          "body": "As this is for January release, I will wait until the November/December agents work is done before reviewing as code and ideas might slightly change due to that work."
        },
        {
          "user": "hawkticehurst",
          "body": "@benibenj @bpasero wasn't quite sure what to do here so for the moment I've defined local interfaces.\r\n\r\nWas specifically unsure about making some of the private properties for model resources/requests public and/or pulling them out into a separate class/interface, so again just defined an interface locally to make TS happy. Would love input from @roblourens or @justschen on if this feels icky or not."
        },
        {
          "user": "roblourens",
          "body": "I'm not an expert in this area, but I don't think there should be anything chat-specific in AbstractPaneCompositePart. Rather we should figure out how to turn it into a generic feature, which the chat view can enable/configure in some way, or, we figure out how to have a chat-specific `IPaneCompositePart` which has chat features. We might ask Steven for advice, or maybe Ben understands it well."
        },
        {
          "user": "benibenj",
          "body": "I think there are 3 approaches\r\n1. Have a contributable toolbar to the left of view pane title => I don't think this is a good idea\r\n2. When creating a view pane, the title is passed as an option. We could also have a titleAction which is passed in which uses `when` condition for toggling visibility\r\n3. Change the type of view pane `options.title` and `updateTitle()` to be `string | { action: Action; label: string }` instead of just `string`\r\n\r\nNot sure yet which is better. I'm leaning towards 2."
        },
        {
          "user": "bpasero",
          "body": "Why is this file formatted? Its impossible for me to review this."
        },
        {
          "user": "bpasero",
          "body": "I think this is already being mentioned, but we cannot add Chat knowledge in to this generic pane that is the home for many other things like the Explorer.\n\nWhat I would have expected is a menu that can be contributed to that appears to the left of the pane title, only if there is a contribution."
        },
        {
          "user": "hawkticehurst",
          "body": "I have no idea, and was actually going to ask one of you about it. \r\n\r\nIt was bugging the hell out of me, but assumed it was part of some formatting rules we have set up for VS Code ‚Äì‚Äì I guess that's not the case though?"
        },
        {
          "user": "hawkticehurst",
          "body": "Any time I `cmd+s` the file / CSS selectors would be reformatted like that."
        },
        {
          "user": "hawkticehurst",
          "body": "Yep, totally on board with this. Planning to update this PR next week / in January.\r\n\r\nJust noticed I forgot to convert this PR to a draft though. I'll update that now so the state of this PR is better reflected."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281325,
      "author": "dmitrivMS",
      "created_at": "2025-12-04T19:41:25Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "follow up from previous PR"
        },
        {
          "user": "dmitrivMS",
          "body": "We now return error on empty content"
        },
        {
          "user": "dmitrivMS",
          "body": "follow up on previous PR"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281351,
      "author": "meganrogge",
      "created_at": "2025-12-04T20:54:40Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@meganrogge can we move this to December?"
        },
        {
          "user": "bpasero",
          "body": "Thanks, I am having a very hard time to accept most of these changes, partially because the code has changed meanwhile and partially because I disagree. I will ping you on the pieces I could extract and use."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281324,
      "author": "DonJayamanne",
      "created_at": "2025-12-04T19:30:02Z",
      "comments": [
        {
          "user": "DonJayamanne",
          "body": "thats not true at all."
        },
        {
          "user": "DonJayamanne",
          "body": "Lol, the previous message was provieded by copilot review run locally.."
        },
        {
          "user": "DonJayamanne",
          "body": "fixed."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281314,
      "author": "Copilot",
      "created_at": "2025-12-04T18:53:24Z",
      "comments": [
        {
          "user": "joshspicer",
          "body": "@copilot tests are mega broken"
        },
        {
          "user": "joshspicer",
          "body": "@copilot I see this as the resource?\n\n\t\"explorerFindProviderActive\": false,\n\t\"resource\": \"multi-diff-editor:1600.07176356234441006\",\n\t\"resourceScheme\": \"multi-diff-editor\",\n\t\"resourceFilename\": \"1600.07176356234441006\",\n\t\"resourceDirname\": \".\",\n\t\"resourcePath\": \"1600.07176356234441006\",\n\t\"resourceLangId\": \"unknown\",\n\t\"resourceExtname\": \".07176356234441006\",\n\t\"resourceSet\": true,\n\t\"isFileSystemResource\": false,"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281316,
      "author": "osortega",
      "created_at": "2025-12-04T19:07:52Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "Does Copilot have a valid point?"
        },
        {
          "user": "mjbvz",
          "body": "This comment seems correct. There's a `getChatSessionType(resource)` function you can use for this"
        },
        {
          "user": "osortega",
          "body": "@copilot open a new pull request to apply changes based on [this feedback](https://github.com/microsoft/vscode/pull/281316#discussion_r2590276625)"
        },
        {
          "user": "osortega",
          "body": "might be faster if I do it lol"
        },
        {
          "user": "mjbvz",
          "body": "I know this was there before but this seems strange. @osortega during debt week can you please see why we need to manually marshal the uri here"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281312,
      "author": "joshspicer",
      "created_at": "2025-12-04T18:40:20Z",
      "comments": [
        {
          "user": "joshspicer",
          "body": "@copilot open a new pull request to apply changes based on [this feedback](https://github.com/microsoft/vscode/pull/281312#discussion_r2590198197)"
        },
        {
          "user": "roblourens",
          "body": "Do you have to do this step? I believe you should only have to call `openSession`"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281303,
      "author": "zlondrej",
      "created_at": "2025-12-04T18:13:20Z",
      "comments": [
        {
          "user": "zlondrej",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "zlondrej",
          "body": "I'm not so sure about that, it's a very simple extension of `Toggle`, which is already tested.\r\nAnd checking if action correctly finds the `UseExcludesAndIgnoreFilesToggle` is like testing the language itself. If `instanceof` breaks, we're probably not even launching tests.\r\n\r\nThe only test I would consider would be check that calling `toggle()` doesn't fire the `onChange` even twice, in case that `Toggle` changes and it starts firing `onChange` just by setting `checked = bool` ."
        },
        {
          "user": "zlondrej",
          "body": "Since when is `o` before `e` in the alphabet?"
        },
        {
          "user": "zlondrej",
          "body": "Assert is strict equal, so it shouldn't be necessary."
        },
        {
          "user": "zlondrej",
          "body": "This is optional dependency. The button will work fine without it, but it just won't display the keyboard shortcut if configured."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281268,
      "author": "mrleemurray",
      "created_at": "2025-12-04T16:17:46Z",
      "comments": [
        {
          "user": "mrleemurray",
          "body": "@bpasero I've updated the color to have different intensities / opacities in dark & light themes for better legibility."
        },
        {
          "user": "bpasero",
          "body": "@mrleemurray thanks, I will take this change into my larger PR in https://github.com/microsoft/vscode/pull/281447 since we now have to merge into release branch too."
        },
        {
          "user": "bpasero",
          "body": "Why is this needed?"
        },
        {
          "user": "mrleemurray",
          "body": "I have now found where the original background color is set & have removed this override."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281248,
      "author": "x-SUKUNA-x",
      "created_at": "2025-12-04T14:40:08Z",
      "comments": [
        {
          "user": "x-SUKUNA-x",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "connor4312",
          "body": "https://github.com/microsoft/vscode/issues/281218#issuecomment-3612737922"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281233,
      "author": "iumehara",
      "created_at": "2025-12-04T13:36:33Z",
      "comments": [
        {
          "user": "iumehara",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "iumehara",
          "body": "pushed new commit that tracks stash history"
        },
        {
          "user": "iumehara",
          "body": "I'm opting to follow the pattern in the historyProvider to maintain consistency within the file."
        },
        {
          "user": "iumehara",
          "body": "Implemented. stashes now defaults to _historyStashRefs."
        },
        {
          "user": "iumehara",
          "body": "@sequentialize was added to the method as suggested."
        },
        {
          "user": "iumehara",
          "body": "new sort function added with the suggested logic."
        },
        {
          "user": "iumehara",
          "body": "Skipping tests, as there does not seem to be an established pattern. \r\nFYI @lszomoru. Please let me know if this is problematic."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281057,
      "author": "meganrogge",
      "created_at": "2025-12-03T21:05:29Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "Valid point?"
        },
        {
          "user": "meganrogge",
          "body": "yes but change I just pushed does work ü§î \r\n\r\n<img width=\"509\" height=\"128\" alt=\"Screenshot 2025-12-03 at 3 19 27‚ÄØPM\" src=\"https://github.com/user-attachments/assets/fa2cfa8f-e5e9-4c9a-b588-948999ed790a\" />"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 281051,
      "author": "lszomoru",
      "created_at": "2025-12-03T20:33:48Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@lszomoru good start! I brought `main` back in and left some comments. On a high level I also wonder if the sessions picker could actually look a bit more like the actual session cards (i.e. 2 lines, with title and description) so that the representation is not so different?\r\n\r\nI think the changes to quick pick need review from @TylerLeonhardt"
        },
        {
          "user": "TylerLeonhardt",
          "body": "I will review after issue grooming unless you need it sooner"
        },
        {
          "user": "lszomoru",
          "body": "> @lszomoru please see my commits, by moving the action into the title, a lot of things become easier because no need to send around the HTMLElement where to show the picker.\r\n\r\nHence my original implementation :)"
        },
        {
          "user": "lszomoru",
          "body": "@TylerLeonhardt, to make things easier to review, I have updated the PR to reduce its scope. The PR now only includes the changes to enable the `anchor` option for the quick input widget and the adoption of this new option for the agent sessions picker. Please let me know if you have any questions or concerns. Thanks!"
        },
        {
          "user": "bpasero",
          "body": "This could get some JSDoc to explain what its about."
        },
        {
          "user": "bpasero",
          "body": "Same here"
        },
        {
          "user": "bpasero",
          "body": "I would suggest to move this into `agentSessionActions.ts` and let it instantiate the picker and open the session (see below)."
        },
        {
          "user": "bpasero",
          "body": "This feels a bit wrong to me: I would have expected the action to use some kind of sessions picker (that I would implement as `agentSessionsPicker.ts` into the `agentSessions` folder for reuse in other contexts, for example there should be a way to open a sessions picker anytime) which then is opened into the side as a result by using `IChatWidgetService.openSession` with the related option to open in sidebar."
        },
        {
          "user": "bpasero",
          "body": "As said I would turn this into a real `agentSessionsPicker.ts` sibling to reduce file complexity."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280952,
      "author": "Shubhz20",
      "created_at": "2025-12-03T13:16:43Z",
      "comments": [
        {
          "user": "Shubhz20",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "sandy081",
          "body": "Thanks for the PR. The reported issue is still under discussion which means the fix is not sure. Hence I am closing this."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280957,
      "author": "Raghav-Somasundaram",
      "created_at": "2025-12-03T14:03:29Z",
      "comments": [
        {
          "user": "dbaeumer",
          "body": "Closing the PR since this is the wrong place to fix it."
        },
        {
          "user": "dbaeumer",
          "body": "I mean wrong project."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280904,
      "author": "jrieken",
      "created_at": "2025-12-03T10:06:04Z",
      "comments": [
        {
          "user": "jrieken",
          "body": "@roblourens I pushed this leak on purpose because I don't know how to handle this. For this flow to work, I needed a new model but I don't really know where to put it... What is the idea for ref-counted chat models? How/where should I store them once I hand them over to the view?"
        },
        {
          "user": "roblourens",
          "body": "The view will hold its own reference to the model, you can just dispose the reference after `openSession`. I think how it should work is that `IChatWidgetService` would also support starting new sessions in the requested target with one step, and you don't get a reference. Then we can move more of our complicated \"new chat\" actions on it."
        },
        {
          "user": "roblourens",
          "body": "I opened https://github.com/microsoft/vscode/issues/280968 to give you a better way to do it but for now you should be able to just dispose the ref"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280747,
      "author": "joshspicer",
      "created_at": "2025-12-02T20:20:35Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@joshspicer did you mean `[\"preview\"]`? I see `experimental` but do we expect to run an experiment?"
        },
        {
          "user": "joshspicer",
          "body": "good point, 'preview' is more accurate https://github.com/microsoft/vscode/pull/280787"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280803,
      "author": "Copilot",
      "created_at": "2025-12-02T23:10:32Z",
      "comments": [
        {
          "user": "aeschli",
          "body": "Duplicate\r\nCandidate: https://github.com/microsoft/vscode/issues/281419\r\nPR to main: https://github.com/microsoft/vscode/pull/281451\r\nPR to release: https://github.com/microsoft/vscode/pull/281453"
        },
        {
          "user": "bryanchen-d",
          "body": "shouldn't we just check if the prompt file exists first instead?"
        },
        {
          "user": "bryanchen-d",
          "body": "is it possible to not disable the no-explicit-any rule?"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280857,
      "author": "dmitrivMS",
      "created_at": "2025-12-03T04:58:18Z",
      "comments": [
        {
          "user": "dmitrivMS",
          "body": "> This is what I get once I run on my machine, it seems like all tests fail:\r\n> \r\n> Test run\r\n> ```\r\n> \r\n> ÔøΩ[0mÔøΩ[0m\r\n> ÔøΩ[0m  VS Code Sanity TestsÔøΩ[0m\r\n> ÔøΩ[0m    CLIÔøΩ[0m\r\n> [2025-12-11T14:46:26.089Z] Fetching metadata for cli-alpine-arm64 from https://update.code.visualstudio.com/api/versions/commit:19228f26df517fecbfda96c20956f7c521e072be/cli-alpine-arm64/insider\r\n> [2025-12-11T14:46:26.283Z] Fetched metadata for cli-alpine-arm64: {\"url\":\"https://vscode.download.prss.microsoft.com/dbazure/download/insider/19228f26df517fecbfda96c20956f7c521e072be/vscode_cli_alpine_arm64_cli.tar.gz\",\"name\":\"1.107.0-insider\",\"version\":\"19228f26df517fecbfda96c20956f7c521e072be\",\"productVersion\":\"1.107.0-insider\",\"hash\":\"e465ba329ff26d2546c86cfb26be90670aaee42a\",\"timestamp\":1764616654713,\"sha256hash\":\"e3f90fb98a9df46f7624240ff2784d23acf3c1d6869c34f50ce9a77242bd4032\",\"supportsFastUpdate\":true}\r\n> [2025-12-11T14:46:26.284Z] Created temp directory: /private/var/folders/pf/mm7knd7126v0scgzgrqpyvn00000gn/T/vscod"
        },
        {
          "user": "dmitrivMS",
          "body": "nope, that's what update API uses"
        },
        {
          "user": "dmitrivMS",
          "body": "This will not be used on Linux"
        },
        {
          "user": "joaomoreno",
          "body": "Can we perhaps rely on spawning `tar` and `unzip` on the machine, instead of adding `fflate` for unzipping and `tar-stream` for untaring?"
        },
        {
          "user": "joaomoreno",
          "body": "```suggestion\nnpm run sanity-test -- --commit 19228f26df517fecbfda96c20956f7c521e072be --quality insider -g \"cli*\"\n```"
        },
        {
          "user": "joaomoreno",
          "body": "How could it work that both these tests run on the same machine? Ie, will I be able to run both `cli-linux-x64` and `cli-win32-arm64` from the same machine? I sort of expected separate test suites, each addressing a different platform. Maybe I'm missing something?"
        },
        {
          "user": "joaomoreno",
          "body": "I'm guessing this is where my errors come from. We can't assume Powershell is available everywhere. Or is this meant to be run only on Windows platforms?"
        },
        {
          "user": "joaomoreno",
          "body": "How about Insiders, Exploration etc?"
        },
        {
          "user": "joaomoreno",
          "body": "We also have the exploration quality."
        },
        {
          "user": "dmitrivMS",
          "body": "The current code follows some existing examples of dealing with archives from bisect, evaluation and automation repros, but I can definitely update the code as you requested."
        },
        {
          "user": "dmitrivMS",
          "body": "You are right, the tests are not meant to run on same machine. As we discussed, the idea is to run them in groups (using patterns in command-line args), in the pipelines at which point only tests corresponding to a given platform will be selected."
        },
        {
          "user": "dmitrivMS",
          "body": "Correct, this is only meant to run on Windows. See my other comments for multi-platform question."
        },
        {
          "user": "dmitrivMS",
          "body": "Thank you, I will add exploration as well. I wasn't sure about it since it wasn't present in other repros I was referencing, but it makes sense to support it as well."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280732,
      "author": "ramanverse",
      "created_at": "2025-12-02T20:00:33Z",
      "comments": [
        {
          "user": "ramanverse",
          "body": "Closing this PR as it was created in error. Will recreate from the correct fork."
        },
        {
          "user": "ramanverse",
          "body": "Yes, exactly! This fix ensures that Pro/ProPlus/Business/Enterprise users see a warning in the status bar when they exceed their premium chat quota, just like Free users currently see warnings when they exceed their quotas.\r\n\r\n**Current behavior:** Only Free tier users see quota warnings in the status bar\r\n**New behavior:** All entitled users (Free, Pro, ProPlus, Business, Enterprise) see appropriate quota warnings\r\n\r\nThe `premiumChat` quota is already tracked in the system and displayed in the dashboard, but the status bar warning logic was missing the check for it. This change brings the status bar in line with the existing quota tracking system."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280738,
      "author": "joshspicer",
      "created_at": "2025-12-02T20:06:51Z",
      "comments": [
        {
          "user": "joshspicer",
          "body": "@bpasero this is a dynamic action (generated from the product.json). Are you just blocking because you want the dynamic action included in more places (beyond/instead the blue button)?\r\n\r\nThe blue button is around for at least this iteration, so it seems to make sense to include the actions there, no?"
        },
        {
          "user": "bpasero",
          "body": "@joshspicer the blue button will be removed as soon as we merge \"Agents\" into \"Chat\" view. I am just saying to not invest into the blue button but focus on the ‚ûï action of the Chat view, as that is the prime target going forward.\r\n\r\nSorry if this was not clear from the beginning üôè \r\n\r\nBtw I can already predict that we may want to surface this dynamic action in other menus that we still need to implement, namely: some kind of picker in the chat input box. But I assume we can do that with a `MenuId` once we have it  introduced."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280600,
      "author": "alexr00",
      "created_at": "2025-12-02T14:03:15Z",
      "comments": [
        {
          "user": "alexr00",
          "body": "This is the actual fix: set the enablement once we create the implicit context"
        },
        {
          "user": "alexr00",
          "body": "The `&& !this._implicitContext` check and this are not part of the fix, but it seems like we should be doing them."
        },
        {
          "user": "alexr00",
          "body": "I modified this check to compare the `.kind` as just comparing by reference was resulting in `false` for restored Agent mode chats. Do we actually want to include the whole file when not in agent mode?"
        },
        {
          "user": "justschen",
          "body": "this was a big point when we changed the implicit context a few iterations ago. it's intended that in every mode except agent mode, the full fiile should be automatically added"
        },
        {
          "user": "alexr00",
          "body": "Ok, then I think my change is correct, as it seems like restored agent mode chats should count as agent mode. Though, maybe there's a separate problem that restored agent mode chats are not the same mode by reference as `ChatMode.Agent`?"
        },
        {
          "user": "alexr00",
          "body": "Oof. Good catch."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280593,
      "author": "deepak1556",
      "created_at": "2025-12-02T13:52:26Z",
      "comments": [
        {
          "user": "StefanXhunga",
          "body": "Thank you for your support"
        },
        {
          "user": "deepak1556",
          "body": "We have dropped support for Big Sur, refs https://github.com/microsoft/vscode/issues/268375"
        },
        {
          "user": "deepak1556",
          "body": "The workaround for catalina from https://github.com/microsoft/vscode/pull/160919/files is no longer needed"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280573,
      "author": "Himanshu197200",
      "created_at": "2025-12-02T12:07:41Z",
      "comments": [
        {
          "user": "Himanshu197200",
          "body": "@bpasero , please review this PR."
        },
        {
          "user": "Himanshu197200",
          "body": "@lszomoru , kindly review this PR."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280457,
      "author": "daviddossett",
      "created_at": "2025-12-01T22:31:20Z",
      "comments": [
        {
          "user": "mrleemurray",
          "body": "Looking great! @bpasero what do you think? Now that we're in endgame should we wait to merge this in the next iteration?"
        },
        {
          "user": "lszomoru",
          "body": "Just throwing this out there. I see that across many files we have standardized to use `4px` as the border radius. Could this be an opportunity to extract that in a variable (or variables in case we would want to use different values depending on the size) so that in the future we can easily update it?"
        },
        {
          "user": "bpasero",
          "body": "@mrleemurray this seems like a large enough change to postpone to next iteration to get insiders coverage.\r\n\r\nI am with Lad, would be nice if somehow all the border radius could be defined as 1 variable so that we can consistently apply it everywhere."
        },
        {
          "user": "mrleemurray",
          "body": "@lszomoru @bpasero agreed - I intend to spin back up the variable effort next iteration & can include corner radii as it is pretty scoped in terms of usage"
        },
        {
          "user": "bpasero",
          "body": "@mrleemurray as part of this PR or a new PR? Lad and me will do a code review too, as the change is quite large and also touches TS."
        },
        {
          "user": "mrleemurray",
          "body": "@bpasero a different PR - I want to tackle font sizes also"
        },
        {
          "user": "daviddossett",
          "body": "I had considered introducing a var for these. I was hoping that I could strip enough overrides that it wouldn't be quite as necessary and that the hardcoded value at the component's root stylesheet. would be fine. \r\n\r\nBut there are still a fair number of special cases (dropdown buttons, editors-as-text-inputs) that it wasn't that straightforward.\r\n\r\nWould be greta to have a general purpose radius or set of them to use everywhere though. Sounds like you're already thinking about it @mrleemurray?"
        },
        {
          "user": "mrleemurray",
          "body": "@daviddossett yes, I am planning to implement a token system for size related values - font sizes, corner radii, strokes, etc. hopefully in the next iteration - which will be exposed across the workbench, like the color tokens."
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280406,
      "author": "Srishtyshree",
      "created_at": "2025-12-01T19:17:19Z",
      "comments": [
        {
          "user": "Srishtyshree",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "Srishtyshree",
          "body": "@rwoll Please review the changes and suggest improvements if any!"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280426,
      "author": "pwang347",
      "created_at": "2025-12-01T20:05:53Z",
      "comments": [
        {
          "user": "aeschli",
          "body": "This needs to be below the activateByEvent await"
        },
        {
          "user": "aeschli",
          "body": "There should be no special handling in computeAutomaticInstructions. The provider instructions are not any special. If we want to to be always included they should define `applyTo: **`"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280362,
      "author": "Himanshu197200",
      "created_at": "2025-12-01T16:48:46Z",
      "comments": [
        {
          "user": "Himanshu197200",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "Himanshu197200",
          "body": "@sandy081 , Please review this PR."
        },
        {
          "user": "Himanshu197200",
          "body": "@lszomoru , please review this PR."
        },
        {
          "user": "sandy081",
          "body": "> Tested locally and verified the queries are happening concurrently now.\r\n\r\nThis is good, but is the issue that https://github.com/microsoft/vscode/issues/280336 is seeing? If fetching remote extension hangs then it will block even if you do parallelly right?"
        },
        {
          "user": "Himanshu197200",
          "body": "Hi @sandy081,\r\n\r\nThanks for testing!\r\n\r\nYou're right to question this. The root cause of #280336 is `queryLocal()` awaiting servers **sequentially**. If WSL/remote hung, it blocked everything ‚Üí frozen UI.\r\n\r\n**My fix:**\r\n1. Parallelized queries - even if remote hangs, local extensions load and UI stays responsive\r\n2. \"Install Local Extensions\" now only queries local server, avoiding the hung remote server\r\n\r\nThis won't prevent individual hangs, but stops them from cascading and freezing the entire extension system. Based on #280336's symptoms (empty list, stuck UI), sequential blocking was the culprit.\r\n\r\nHappy to add timeout handling later if needed, but this should resolve the reported issue.\r\nWould you be open to merging this?"
        },
        {
          "user": "sandy081",
          "body": "> The root cause of https://github.com/microsoft/vscode/issues/280336 is queryLocal() awaiting servers sequentially. If WSL/remote hung, it blocked everything ‚Üí frozen UI.\r\n\r\nHave you tried this? Because UI asks extensions per server which means there will be only single request"
        },
        {
          "user": "Himanshu197200",
          "body": "@sandy081 \r\n\r\nYou're right to challenge this. If the UI makes separate `queryLocal()` calls per server (one for local, one for remote, etc.), then parallelizing within a single call wouldn't help.\r\n\r\nCould you point me to where the UI requests extensions? I want to verify whether my fix addresses the actual flow or if I need to look elsewhere.\r\n\r\nThanks for the guidance!"
        },
        {
          "user": "sandy081",
          "body": "Here - \r\nhttps://github.com/microsoft/vscode/blob/9913515e4720b3d52b34ca83708ade1228c97e64/src/vs/workbench/contrib/extensions/browser/extensionsViews.ts#L336"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280263,
      "author": "DrSergei",
      "created_at": "2025-12-01T08:53:56Z",
      "comments": [
        {
          "user": "DrSergei",
          "body": "–°–° @connor4312"
        },
        {
          "user": "connor4312",
          "body": "This is allowed for the `+` operator"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280236,
      "author": "dileepyavan",
      "created_at": "2025-12-01T05:08:24Z",
      "comments": [
        {
          "user": "dileepyavan",
          "body": "> I would like to learn more what a `sandboxSettingsResource` is and what the new dependency is `@anthropic-ai/sandbox-runtime`\r\n> \r\n> Are we really pushing this in on the last day of the iteration?\r\n\r\n Sure I can setup a call if needed. Daniel is OOF and I dont think it will go this week."
        },
        {
          "user": "connor4312",
          "body": "This only works if `srt` happens to already be on the user's path, which is not guaranteed."
        },
        {
          "user": "connor4312",
          "body": "I'm not clear why these are needed -- it doesn't seem like we actually used them?"
        },
        {
          "user": "connor4312",
          "body": "This won't work for remotes where the user's profile is on a different machine than the workspace.\n\nI suggest we PR in support for setting the sandbox config via an environment variable for the SRT library (if we want to commit to using that.) There are some other issues with the file handling here, but switching to an environment variable would make them moot."
        },
        {
          "user": "connor4312",
          "body": "This just resends the last request and turns sandboxing off in the terminal commands it makes. The terminal command could have been the 20th turn step in a long agentic request, and users would find restarting the whole last request to be frustrating.\r\n\r\nWe should instead re-run that individual command and proceed from there. I think this may need API changes to support unless we stall after the request fails and before returning to the model (which is also not good, some command failures are normal and expected). A cheap interim solution would be to generate a request saying something like `Rerun the terminal command 'X' and proceed from there`"
        },
        {
          "user": "dileepyavan",
          "body": "This is part of a npm package that is added as a dependency"
        },
        {
          "user": "dileepyavan",
          "body": "These slipped from previous changes where the entire process is sandboxed."
        },
        {
          "user": "connor4312",
          "body": "That is not available on the user path when VS Code is installed."
        },
        {
          "user": "dileepyavan",
          "body": "Correct, this needs to be available. My testing was working as there was a global install on my machine."
        },
        {
          "user": "Tyriar",
          "body": "What's all these launch.json changes about?"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280207,
      "author": "mjbvz",
      "created_at": "2025-12-01T01:44:23Z",
      "comments": [
        {
          "user": "mjbvz",
          "body": "Needed to ensure the command shows up properly. Previously some items in this list weren't disposed"
        },
        {
          "user": "mjbvz",
          "body": "Yes this is intentionally a command from the external extension"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280217,
      "author": "Josbleuet",
      "created_at": "2025-12-01T03:19:14Z",
      "comments": [
        {
          "user": "TylerLeonhardt",
          "body": "Actually, why are we fixing this here instead of lower down in the stack. Wouldn't it make sense that we do this replacement generically for all logger names?\n\nThis fixes this instance, but if someone does this again, they won't know unless they're in this discussion.\n\nCc @sandy081"
        },
        {
          "user": "Josbleuet",
          "body": "@microsoft-github-policy-service agree\r\n\r\n\r\nOn Mon, Dec 1, 2025 at 7:58‚ÄØAM microsoft-github-policy-service[bot] <\r\n***@***.***> wrote:\r\n\r\n> *microsoft-github-policy-service[bot]* left a comment\r\n> (microsoft/vscode#280217)\r\n> <https://github.com/microsoft/vscode/pull/280217#issuecomment-3596425390>\r\n>\r\n> @Josbleuet <https://github.com/Josbleuet> please read the following\r\n> Contributor License Agreement(CLA). If you agree with the CLA, please reply\r\n> with the following information.\r\n>\r\n> @microsoft-github-policy-service agree [company=\"{your company}\"]\r\n>\r\n> Options:\r\n>\r\n>    - (default - no company specified) I have sole ownership of\r\n>    intellectual property rights to my Submissions and I am not making\r\n>    Submissions in the course of work for my employer.\r\n>\r\n> @microsoft-github-policy-service agree\r\n>\r\n>\r\n>    - (when company given) I am making Submissions in the course of work\r\n>    for my employer (or my employer has intellectual property rights in my\r\n>    Submissions by co"
        },
        {
          "user": "sandy081",
          "body": "That's right and it also fixes - https://github.com/microsoft/vscode/issues/269810"
        },
        {
          "user": "Josbleuet",
          "body": "I've updated the PR with your suggested approach - using an inline replace instead of a separate sanitization function."
        },
        {
          "user": "TylerLeonhardt",
          "body": "Maybe instead just url encode it?"
        },
        {
          "user": "Josbleuet",
          "body": "# Response to Reviewer\r\n\r\nGood question about URL encoding. I looked into the VS Code codebase to see how this kind of thing is typically handled.\r\n\r\n## What I found\r\n\r\nI searched through the existing logger creation patterns and filename sanitization in the codebase. A few things stood out:\r\n\r\n**How logger IDs become filenames:**\r\n\r\nIn `src/vs/platform/log/common/log.ts` (lines 653-655), when you pass a string ID, it goes straight into `joinPath()`:\r\n\r\n```typescript\r\nprotected toResource(idOrResource: string | URI): URI {\r\n    return isString(idOrResource) ? joinPath(this.logsHome, `${idOrResource}.log`) : idOrResource;\r\n}\r\n```\r\n\r\nThere's no sanitization or encoding happening there. That's why we hit the Windows path error with characters like `:`, `/`, `?`.\r\n\r\n**Existing patterns:**\r\n\r\nLooking at 50+ logger creation calls across the codebase, they all use simple IDs like `'network'`, `'terminal'`, `'remoteagent'`. I couldn't find any examples of URLs or complex strings being used as "
        },
        {
          "user": "sandy081",
          "body": "```suggestion\n\treturn isString(idOrResource) ? joinPath(this.logsHome, `${idOrResource.replace(/[\\\\/:\\*\\?\"<>\\|]/g, '')}.log`) : idOrResource;\n```"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280222,
      "author": "roblourens",
      "created_at": "2025-12-01T04:11:04Z",
      "comments": [
        {
          "user": "bpasero",
          "body": "@roblourens as this PR got automatically merged without my feedback considered, I have opened https://github.com/microsoft/vscode/pull/280249 to continue there."
        },
        {
          "user": "roblourens",
          "body": "Thanks for the followup PR"
        },
        {
          "user": "bpasero",
          "body": "This is maybe up for debate, but I was adding the `revealIfOpened: true` here actually intentionally because I am assuming that a user (such as Kai) will have setup a careful editor layout where chats are all in one group and files are in other groups for review and then it would be frustrating if a chat editor moves around only because another group is active. But I can be convinced to drop this intent and see from real user feedback."
        },
        {
          "user": "bpasero",
          "body": "Do we need to check if the editor was closed after all? Isn't it possible that this still brings up a dialog asking for accepting or discarding edits from the session? I am not sure how Connors change is timed for this dialog to disappear?"
        },
        {
          "user": "bpasero",
          "body": "`revealIfOpened` is actually an editor option, which is now here used in a non-editor context (sidebar). I would still prefer that we just respect the `target` that is passed in to determine if we need to reveal an existing chat in the sidebar or not. Because otherwise this will not work: pass in an editor group and `revealIfOpened: true`, will sometimes go to the sidebar and sometimes not, which is yet again undeterministic."
        },
        {
          "user": "roblourens",
          "body": "That dialog is removed (not in Insiders but in main)"
        }
      ]
    },
    {
      "repo": "microsoft/vscode",
      "number": 280125,
      "author": "aman-ak-r",
      "created_at": "2025-11-30T08:03:23Z",
      "comments": [
        {
          "user": "aman-ak-r",
          "body": "@microsoft-github-policy-service agree"
        },
        {
          "user": "aman-ak-r",
          "body": "@ulugbekna can you please review and tell any changes required ?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3464,
      "author": "paras-chinchalkar",
      "created_at": "2025-12-12T15:01:36Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Thanks for your contribution! In order to properly prioritize and review this, please make sure you are submitting your contributions with descriptive titles that explain what the fix is. While you can mention the issue that you are fixing in the title, a better way would be to include text like \"fixes#<number>\" in the body of your PR message so that github can link the issue being solved automatically.\r\n\r\nIt would also be helpful to learn a little more about why you believe these changes are a good solution to the problem, or what led you to these solutions in the first place. It's okay to summarize your code changes in the PR description, but without context, its hard for other maintainers to see why this solution is better than other options that may be available."
        },
        {
          "user": "MoralCode",
          "body": "I also notice that this PR also contains the changes from https://github.com/chaoss/augur/pull/3463. If multiple sets of changes are included in a pull request, it makes the code a lot harder to review as the maintainers need to distinguish between which code is related to what changes and are less able to consider each change independently."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3449,
      "author": "shlokgilda",
      "created_at": "2025-12-09T19:24:21Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "converting to draft because of \r\n> This PR should be merged after https://github.com/chaoss/augur/pull/3439 as it builds on that branch"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode  : I really appreciate the safety move of switching this to draft so somebody (me) doesn't merge these in the wrong order. :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3453,
      "author": "paras-chinchalkar",
      "created_at": "2025-12-10T05:45:38Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Can you make the title of your pull request more descriptive of what is actually being fixed? Raw issue numbers by themselves arent very easy to read/understand at a glance"
        },
        {
          "user": "paras-chinchalkar",
          "body": "> Can you make the title of your pull request more descriptive of what is actually being fixed? Raw issue numbers by themselves arent very easy to read/understand at a glance\r\n\r\nfix: correct regex parsing of PostgreSQL connection string\r\nwhat I tried to do:-\r\nThis update improves the parse_database_string function so it correctly pulls out the username, password, host, port, and database from a PostgreSQL connection string. If the input doesn‚Äôt match the expected format, the function now raises a clear ValueError instead of silently failing. The changes are kept focused only on the parsing logic, without any unrelated reformatting, to make the review straightforward."
        },
        {
          "user": "MoralCode",
          "body": "This PR contains a lot of reformatting fixes that dont contribute to the core issue being solved. Please keep PRs focused on one issue at a time so they are easier to review, especialy if they touch core detabase functionality"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3467,
      "author": "shlokgilda",
      "created_at": "2025-12-15T06:25:51Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "Validating every single timestamp for commits seems like a very resource intensive solution to a problem that does not crop up very often.\n\nIn another part of the code, we use a binary reduction algorithm to isolate records with invalid timestamps, and then we trim off the time zone data portion and insert it as UTC. Is something of that nature feasible to do here? \n\nIf not, perhaps this should lead into a discussion of not relying on native datetime types in PostgreSQL. I think that it would be preferable that we preserve whatever lives on the git log, as opposed to attempting to fix it."
        },
        {
          "user": "shlokgilda",
          "body": "@Ulincsys Fair point! This was definitely a defensive approach. I thought we should validate every timestamp, but I see the performance implication.\r\n\r\nI dug into why the existing binary reduction in `lib.py` didn't catch this. The fix logic actually looks correct - it should replace \"-13068837\" with \"+0000\" and retry. Year 2106 is valid for PostgreSQL 64-bit. The stack trace shows multiple chained exceptions, so something else might be failing - possibly other corrupted fields in the same record, or multiple bad records with different issues.\r\n\r\n**Option 1:** Improve the existing error recovery in `lib.py:facade_bulk_insert_commits()`. When we've isolated a single bad record, use `datetime.strptime` to validate the entire timestamp instead of just checking timezone against a magic number set (`postgres_valid_timezones`). This catches any malformed timestamp in one go and keeps zero overhead for valid records. \r\n\r\n**Option 2:** Or a completely different discussion point, as you suggest"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3448,
      "author": "paras-chinchalkar",
      "created_at": "2025-12-08T19:38:38Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@MoralCode : I added a \"discussion\" label here because I'm not certain ... BUT, I think we have other open PR's that address the python versioning issues."
        },
        {
          "user": "MoralCode",
          "body": "> I think we have other open PR's that address the python versioning issues.\r\n\r\nmost likely - thats why i added the redundant tag"
        },
        {
          "user": "MoralCode",
          "body": "> Title / Commit: docs: update supported Python versions and add onboarding steps (#3441) ‚Äî committed to the repo.\r\n\r\nPlease make the titles of your Pull requests more descriptive of the actual issue being solved"
        },
        {
          "user": "paras-chinchalkar",
          "body": "> > Title / Commit: docs: update supported Python versions and add onboarding steps (#3441) ‚Äî committed to the repo.\r\n> \r\n> Please make the titles of your Pull requests more descriptive of the actual issue being solved\r\n\r\n\r\n\r\nProblem 1: Outdated Python version documentation\r\nIssue: Hard-coded \"Python3.7 through Python3.11\" becomes outdated, and OSX-only examples don't help Windows/Linux users.\r\nSolution: Replaced with flexible language about supporting current Python versions (centered on 3.11) and added cross-platform virtual environment examples for Windows (PowerShell) and macOS/Linux.\r\nImpact: Documentation stays current longer and helps contributors on all platforms.\r\nProblem 2: Missing onboarding guidance\r\nIssue: New contributors lacked a clear starting point; onboarding info was scattered.\r\nSolution: Added an \"Onboarding for New Contributors\" section in README.md with steps: join Slack, read CONTRIBUTING.md, run Augur locally, find starter issues (first-timers-only or good first"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3443,
      "author": "cnaples79",
      "created_at": "2025-12-04T22:47:49Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "I think we should just mention the official policy that Augur aims to work with all supported python versions, although we are dependent on support from our dependencies so new versions may not be fully supported right out of the gate"
        },
        {
          "user": "MoralCode",
          "body": "this isnt necessary with uv, it handles creating and activating an env for you\n\nim not sure what should go here. `uv run augur` would make some sense, but i have yet to test if that actually works. the Docker quick start in the readthedocs is the recommended way to set augur up currently"
        },
        {
          "user": "sgoggins",
          "body": "`uv run augur backend start` does work on bare metal in the `release` branch. Some of the db update scripts are causing it to fail in `main`, which isn't directly related to this PR but worth mentioning in the context of testing."
        },
        {
          "user": "MoralCode",
          "body": "Can you open a new issue for the issues you describe with bringing the migrations up on main?\r\n\r\nThe scope of this PR is just updating docs essentially. IMO i think the docker based workflow by default makes the most sense for most people, at least until there are updated scripts or other similarly easy ways newcomers can do a manual setup."
        },
        {
          "user": "sgoggins",
          "body": "I agree that the docker based setup should be primary now."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3446,
      "author": "iGufrankhan",
      "created_at": "2025-12-07T06:55:27Z",
      "comments": [
        {
          "user": "iGufrankhan",
          "body": "@MoralCode \r\n<img width=\"1898\" height=\"850\" alt=\"image\" src=\"https://github.com/user-attachments/assets/2e85817a-9a60-4df6-8aa9-576d0475e86b\" />\r\n\r\n\r\nif we want to maintain name in one place so i recommned to remove the contributiors.md \r\nbeacauseThe index.rst page already documents this well, and it‚Äôs an important part of the documentation structure‚Äîas shown in the screenshot above\r\n\r\nand for image can i make a file docs/static store the image there \r\nthis would ensure the images stay in the repository and avoid broken links in the future.\r\nwhat do you think about this \r\nand I‚Äôve also revised the CONTRIBUTING.md to be clearer, more aligned with the existing style, and better integrated with the current guidance"
        },
        {
          "user": "iGufrankhan",
          "body": "@MoralCode \r\n<img width=\"968\" height=\"388\" alt=\"image\" src=\"https://github.com/user-attachments/assets/dab36c39-516e-4c36-80ff-7b117874b7e7\" />\r\n\r\nis this good update the contributing.md in index.rst\r\nfor the images I used ‚Äî can I just upload them in this issue and reference the URLs? I think creating a new folder only for images isn‚Äôt necessary. What do you think?"
        },
        {
          "user": "MoralCode",
          "body": "I think, rather than maintaining a list of maintainers (heh) in two places, one of them (IMO this one) should be updated to be more of a pointer (i.e. say something along the lines of \"You can find our list of maintainers and previous GSoC contributors here <link to the list in the repo>\""
        },
        {
          "user": "MoralCode",
          "body": "the / should not be part of the backticks here.\n```suggestion\nThen filter by label to see only the `good first issue`/`first-timer-only` items:\n```"
        },
        {
          "user": "MoralCode",
          "body": "if we are going to include images, they should be uploaded to the repo so they dont disappear in future"
        },
        {
          "user": "MoralCode",
          "body": "Overall this change mostly adds lines to the CONTRIBUTING file. I think it may be worth a more thorough review to see where we can utilize words and organization that already exist in this file.\n\nI strongly suspect this is the kind of task that is going to require some human attention to get right, rather than just having an LLM do it. After all, we dont want one of the first documents that a newcomer sees to sound AI generated or low-effort since it leaves an uncomfortable first impression of the project"
        },
        {
          "user": "sgoggins",
          "body": "This gets at one of the core challenges within CHAOSS, which is that most members of the community do not write code for our large and complex software projects. The \"non coder friendly\" nature of CHAOSS is mostly a plus. However, when it comes to onboarding, we do an excellent job with non code onboarding, and historically do a not very good job with onboarding code contributors. \n\nI think @MoralCode is providing the kind of onboarding thoughtfulness that is resulting in more contributions (some credit, also, to AI) to Augur. \n\nAll that is to say that I think our onboarding process is different than the non-software parts of CHAOSS (which is why we created a software core group at the outset and a metrics core group --> to ensure representation on the board)... we have almost never had a code contributor arrive through other CHAOSS working groups. \n\nThank you for the contribution @iGufrankhan !!! Our comments are largely around how we want to work with newcomers and do the onboarding,"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3438,
      "author": "MoralCode",
      "created_at": "2025-12-03T19:04:32Z",
      "comments": [
        {
          "user": "shlokgilda",
          "body": "I created a dedicated test file to validate the null string handling fix. Since this test is very specific to this PR and adds\r\ntest infrastructure dependencies (unique test IDs, platform setup, etc.), I'm not committing it to the repository. Instead, I'm documenting the test methodology and results here.\r\n\r\n### Test File\r\nCreated `tests/test_tasks/test_github_tasks/test_pr_review_null_handling.py`:\r\n\r\n```python\r\n\"\"\"\r\nThis test validates that the collect_pull_request_reviews function properly\r\nhandles null, None, and edge-case values in pr_review_body fields by using\r\nthe string_fields parameter in insert_data().\r\n\"\"\"\r\nfrom augur.tasks.github.pull_requests.tasks import collect_pull_request_reviews\r\nfrom augur.application.db.models import PullRequestReview\r\n\r\nclass TestPRReviewNullHandling:\r\n    \"\"\"Test suite for PR review null string handling (PR #3438)\"\"\"\r\n\r\n    def test_pr_review_insert_uses_string_fields_parameter(self):\r\n        \"\"\"\r\n        Test that the collect_pull_request_revie"
        },
        {
          "user": "MoralCode",
          "body": "Actually, fixing the test infrastructure is something I plan to do very soon. Thats one of the reasons i want to move towards using the Sqlalchemy Models as the source of truth (by syncing them with the migrations), then we can do `Base.metadata.create_all()` when bringing up a testing DB and can hopefully get a bunch of other db-dependent tests working too.\r\n\r\nOverall i think having a testcase like this in the codebase is actually helpful, especially if you think about it as preventing regressions in insert_data with regards to the string fields parameter"
        },
        {
          "user": "MoralCode",
          "body": "as a bonus, if you throw this in the tests directory somewhere relatively sensible, the fact that the tests are currently largely broken means itll probably be an easy merge (youd effectively be adding code thats not gonna actually run without the DB test fixtures backing it) and it'll be my job to make those work when i get around to finishing fixing those DB test fixtures"
        },
        {
          "user": "shlokgilda",
          "body": "I have uploaded the test file in a branch of my fork. You can see the file below. I can open a new PR if that helps? \r\nLink to my branch: https://github.com/chaoss/augur/compare/main...shlokgilda:augur:test-pr-3438-validation"
        },
        {
          "user": "MoralCode",
          "body": "> I can open a new PR if that helps?\r\n\r\nyep, go for it!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3436,
      "author": "MoralCode",
      "created_at": "2025-12-03T14:33:16Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "IMO since these files are entirely comments, Im going to consider this change to be tested"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I am rerunning the podman end to end test. Not sure why its failing here."
        },
        {
          "user": "MoralCode",
          "body": "Seems like it passed second time around"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3444,
      "author": "PredictiveManish",
      "created_at": "2025-12-06T17:32:17Z",
      "comments": [
        {
          "user": "shlokgilda",
          "body": "I just have non-blocking code quality suggestion: use a named constant like `MESSAGE_BATCH_SIZE = 500` instead of a magic number"
        },
        {
          "user": "MoralCode",
          "body": "> I just have non-blocking code quality suggestion: use a named constant like `MESSAGE_BATCH_SIZE = 500` instead of a magic number\r\n\r\nYep, agreed"
        },
        {
          "user": "PredictiveManish",
          "body": "> I just have non-blocking code quality suggestion: use a named constant like `MESSAGE_BATCH_SIZE = 500` instead of a magic number\r\n\r\nWhat to give the size 500 or 200? as @MoralCode suggested for 200"
        },
        {
          "user": "sgoggins",
          "body": "> > I just have non-blocking code quality suggestion: use a named constant like `MESSAGE_BATCH_SIZE = 500` instead of a magic number\r\n> \r\n> What to give the size 500 or 200? as @MoralCode suggested for 200\r\n\r\n200"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode / @PredictiveManish : I'm rerunning the failed end to end test. Sometimes GitHub gets overwhelmed and they just timeout."
        },
        {
          "user": "MoralCode",
          "body": "> May we assume you ran this locally and collected data?\r\n\r\nLets not assume - would rather accidentally over-test than not test at all."
        },
        {
          "user": "sgoggins",
          "body": "Changing this all the way to 1,000 is going to potentially generate more contention and locking; but not if teh full table scans are tamped down independently of this change."
        },
        {
          "user": "MoralCode",
          "body": "if we are going to bump this, and it was set this low to begin with, id say raising it to 200 would be a good first step. thats 10x more records, so 10x less batch overhead without risking the batches getting too big"
        },
        {
          "user": "PredictiveManish",
          "body": "updated it for 200."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode / @shlokgilda : I think this amounts to all the requested changes I see."
        },
        {
          "user": "shlokgilda",
          "body": "Sounds about right!"
        },
        {
          "user": "MoralCode",
          "body": "Above you rely on some functions for these mappings, Is this code just a duplicate of the code in those functions? If those functions are useful elsewhere and not tied in anywhere maybe they can be useful utility functions that can be imported here too?\n\nOverall id recommend splitting this PR so that the changes to events.py can be merged without being held up by the larger question of refactoring ( ref #3345) that this file brings up"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3432,
      "author": "xiaoha-cloud",
      "created_at": "2025-11-26T18:12:50Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Is this essentially #3214 but rebased and without the schemas that were already merged?"
        },
        {
          "user": "xiaoha-cloud",
          "body": "Actually, this is the worker/core part of #3254, rebased onto the latest main and without the schema changes that were already merged. I intentionally split the original big PR into smaller.My plan is to follow up with additional small PRs for the remaining pieces, so they can be reviewed and discussed step by step."
        },
        {
          "user": "sgoggins",
          "body": "Does this really not require database connection? I question that. @MoralCode ?"
        },
        {
          "user": "MoralCode",
          "body": "DatabaseSession is not the only place in our code that can access the database, however it is the one that (IMO) everything should be using if at all possible.\r\n\r\nI havent looked through this code, but removing this import from api.py does make me think something has gone wrong too."
        },
        {
          "user": "xiaoha-cloud",
          "body": "In main, `DatabaseSession` is also imported but unused: the routes never call with `DatabaseSession(...)`, and `add_existing_org_to_group` isn‚Äôt invoked. All DB access still flows through the `current_user.*` and `UserGroup/UserRepo` helpers, so removing the unused import was just a lint clean-up and doesn‚Äôt change behavior."
        },
        {
          "user": "xiaoha-cloud",
          "body": "If we need to follow the ‚Äúexplicit outer session‚Äù convention, we can re-import from `augur.application.db.session import DatabaseSession` and wrap the relevant routes in `with DatabaseSession(logger, engine=app.engine) as db`: and pass that session into the calls. As of now, behavior matches `main`, just without the unused-import warning."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3435,
      "author": "MoralCode",
      "created_at": "2025-12-02T20:31:02Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "OK so it seems like the smoke tests revealed an interesting bug\r\n\r\n<details>\r\n<summary>Stack Trace</summary>\r\n```\r\naugur-1         | Traceback (most recent call last):\r\naugur-1         |   File \"/augur/.venv/bin/augur\", line 10, in <module>\r\naugur-1         |     sys.exit(run())\r\naugur-1         |              ^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1462, in __call__\r\naugur-1         |     return self.main(*args, **kwargs)\r\naugur-1         |            ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1383, in main\r\naugur-1         |     rv = self.invoke(ctx)\r\naugur-1         |          ^^^^^^^^^^^^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1850, in invoke\r\naugur-1         |     return _process_result(sub_ctx.command.invoke(sub_ctx))\r\naugur-1         |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nau"
        },
        {
          "user": "shlokgilda",
          "body": "Hey @MoralCode, thanks for tackling this schema drift cleanup. Found one issue that will likely cause problems:\r\n\r\n1. The `Sequence()` calls are missing `schema='augur_data'`. Per [SQLAlchemy docs](https://docs.sqlalchemy.org/en/20/core/defaults.html#defining-sequences):\r\n\r\n> When using tables with explicit schema names, the configured schema of the Table is **not** automatically shared by an embedded Sequence, instead, specify `Sequence.schema`\r\n\r\nThe old `server_default=text(\"nextval('augur_data.xxx_seq'::regclass)\")` worked because it referenced the schema explicitly. The new `Sequence('xxx_seq', start=N)` will look in `public` schema (or whatever `search_path` resolves to) instead of `augur_data`.\r\n\r\n**Fix**: Add `schema='augur_data'` to each Sequence:\r\n```python\r\n# Instead of:\r\nSequence('chaoss_metric_status_cms_id_seq', start=1)\r\n\r\n# Use:\r\nSequence('chaoss_metric_status_cms_id_seq', start=1, schema='augur_data')\r\n```\r\nThis affects all sequence definitions in the PR.\r\n\r\n2. Also, m"
        },
        {
          "user": "MoralCode",
          "body": "we currently require an email to sign up, we should (ideally) be validating that the person signing up owns that email address"
        },
        {
          "user": "MoralCode",
          "body": "added this back to the models"
        },
        {
          "user": "sgoggins",
          "body": "OK ... so is this still in draft mode then?"
        },
        {
          "user": "MoralCode",
          "body": "yes, Im extracting some ancillary fixes that I made as part of this branch into separate PRs (#3436, #3450 ) then ill rebase this on top of main.\r\n\r\nThat said, this is a pretty consequential change since it touches one of the most core aspects of the system. I want to make 1000% sure that all changes to models and migrations are agreed on by everyone. I put this up as early as possible as a draft so everyone had as much time as possible to review it\r\n\r\nthat said, this is a blocker for basically all other database schema changes right now, so we shouldn't let it languish forever"
        },
        {
          "user": "shlokgilda",
          "body": "This needs `schema='augur_data'` - sequences don't inherit the table's schema automatically. Same applies to all other Sequence definitions in this file. See: https://docs.sqlalchemy.org/en/20/core/defaults.html#defining-sequences\n\n```python\n  Sequence('chaoss_metric_status_cms_id_seq', start=1, schema='augur_data')\n```"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3447,
      "author": "paras-chinchalkar",
      "created_at": "2025-12-08T19:26:18Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@paras-chinchalkar : I am unfamiliar with the `onboarding.md` file's origin story. I know there are an ever growing number of \"standard\" files being dropped into repositories, but I could use a little history and context to evaluate whether this file fits how we operate. Also interested in what @MoralCode thinks. \n\nTHANK YOU for the contribution. This comment is simply to make you aware that we need a minute. :)"
        },
        {
          "user": "MoralCode",
          "body": "I have already given this feedback to another contributor who is solving this same issue, but IMO this list of guideposts (from the issue) should be in CONTRIBUTING.md. Im not aware of ONBOARDING.md being a widely used practice"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3439,
      "author": "shlokgilda",
      "created_at": "2025-12-04T00:16:36Z",
      "comments": [
        {
          "user": "shlokgilda",
          "body": "Testing update: Did not encounter any errors. Table values correctly updated. Tested with `https://github.com/tensorflow/tensorflow` (large repo; ~75K PRs)."
        },
        {
          "user": "sgoggins",
          "body": "@shlokgilda : I merged a PR that fixed a seperate issue on PR reviews from @MoralCode just now ... which created a conflict with your code. I think it looks pretty straightforward as both changes add safety. While I am nearly certain I know how to resolve the conflict while incorporating both changes, I would like @shlokgilda to change it in their fork/branch and update the PR ... So I don't mess something up editing online."
        },
        {
          "user": "shlokgilda",
          "body": "@sgoggins Fixed and pushed."
        },
        {
          "user": "MoralCode",
          "body": "why was this removed?"
        },
        {
          "user": "MoralCode",
          "body": "This is probably going to need adjusting or merge-deconflicting to account for the fix in #3438 depending on which merges first"
        },
        {
          "user": "shlokgilda",
          "body": "This was a duplicate call. repo_id is being reset on line 397 later."
        },
        {
          "user": "shlokgilda",
          "body": "Yeah, I agree."
        },
        {
          "user": "shlokgilda",
          "body": "If we know the order of PRs in which they will be processed, I can rebase older PRs on this."
        },
        {
          "user": "MoralCode",
          "body": "i suspect the other one is more *likely* to get in first, just because its smaller/more focused.\r\n\r\nif youre able to replicate the underlying issue (i think the github.com/ClassclockAPI repo was the one that triggered that other issue, but theoretically anything with null characters in a PR review should do it) and help test the fix that would be super though!"
        },
        {
          "user": "shlokgilda",
          "body": "Okay! I can try to mock up a quick test for the other PR I guess."
        },
        {
          "user": "sgoggins",
          "body": "I think that would be very helpful @shlokgilda"
        },
        {
          "user": "MoralCode",
          "body": "Does this move to procesing contributors within a batch, rather than globally, affect how contributors are processed?\n\ni.e. if its resolving or deduplicating contributors only within a batch, would that mean its possible that something gets mis-resolved or a duplicate gets missed if the values are in separate batches?"
        },
        {
          "user": "shlokgilda",
          "body": "No, this won't cause any issues with contributors being missed across batches. The `remove_duplicate_dicts()` call is just an optimization to avoid sending redundant INSERT statements within a single batch. The actual cross-batch deduplication happens at the database level - `insert_data()` uses PostgreSQL's `ON CONFLICT DO UPDATE` (upsert) with `cntrb_id` as the natural key:\r\n\r\n```python\r\naugur_db.insert_data(unique_contributors, Contributor, [\"cntrb_id\"])\r\n```\r\nSo if contributor \"alice\" shows up in batch 1, she gets inserted. If she appears again in batch 3, the `ON CONFLICT` clause updates the existing row instead of creating a duplicate. The batch-local dedup just saves us from sending multiple identical INSERTs in the same DB call."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3422,
      "author": "MoralCode",
      "created_at": "2025-11-19T21:57:52Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@JohnStrunk / @MoralCode : Not sure about this and whether or not it matters."
        },
        {
          "user": "MoralCode",
          "body": "@sgoggins do you know why this test is here, or if we still rely on it?"
        },
        {
          "user": "MoralCode",
          "body": "i dont think theres a direct dependency, i suspect this is just here to stop the image build from trying if the e2e test fails, which seems like it may be helpful so we dont ship something broken (but also thats what the E2E and other tests help prevent so idk)\r\n\r\nIf theres no other way to keep this and have it reference across files, then we may as well remove it"
        },
        {
          "user": "sgoggins",
          "body": "@JohnStrunk created most of these adn they have been working. AFAIK these tests are part of what is keeping augur stable and easy to deploy ... which I think you know so I think I may not understand the question :)"
        },
        {
          "user": "sgoggins",
          "body": "Why don't we want to check docs, or is this simply relocated?"
        },
        {
          "user": "sgoggins",
          "body": "Got my answer by scrolling. :)"
        },
        {
          "user": "MoralCode",
          "body": "given the definition of this test, im unsure what it is specifically testing - it seems to just install some python data processing toolkits and things. are we trying to ensure one of our dependencies can install on mac OS? it feels weird to be testing a dependency in one of our tests like this - IMO it would make more sense to make sure the unit tests run on MacOS (which I think its set up by this PR)"
        },
        {
          "user": "sgoggins",
          "body": "The \"Go\" and NLTK parts have been the most inconsistent historically. \r\n\r\n@JohnStrunk's approach, as I understand it, was to create this test in the CI and then validate that, when the test succeeds, Augur runs on OSX. Successful installation of the toolkits cannot be assumed across OSX distros, Go, and Python distros on OSX, based on our long experience."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3424,
      "author": "shlokgilda",
      "created_at": "2025-11-20T16:23:13Z",
      "comments": [
        {
          "user": "shlokgilda",
          "body": "It's a slightly longer PR, but I think important and within scope since all these issues were possible causes of OOM exceptions."
        },
        {
          "user": "MoralCode",
          "body": "@shlokgilda has been thoroughly testing this and has [confirmed](https://chaoss-workspace.slack.com/archives/C0226ELG6R4/p1764789515373849?thread_ts=1764789018.459519&cid=C0226ELG6R4) that the facade workers are flowing and secondary is not memory bottlenecked anymore.\r\n\r\nI trust this as far as testing goes and am going to mark this as ready"
        },
        {
          "user": "MoralCode",
          "body": "I think I was the one who removed that import because pylint suggested it was unused. I haven't personally tested that change so prob worth reverting just in case."
        },
        {
          "user": "MoralCode",
          "body": "rebased, fixed the merge conflict with the string fields fix (#3434) and corrected my pylint bug"
        },
        {
          "user": "MoralCode",
          "body": "is this reliant on having a raw sqlalchemy Result object? I would love to also make sure we are explicit about calling something like `.fetchall()` after the query so that we dont unnecesserily hold on to database connections as we iterate results (that we then forget to close)"
        },
        {
          "user": "MoralCode",
          "body": "should we reuse BATCH_SIZE from above? is there a reason these are two different values/is there a reason we would want the batch sizes for the two halves to be different?"
        },
        {
          "user": "MoralCode",
          "body": "holy whitespace"
        },
        {
          "user": "shlokgilda",
          "body": "The idea was to let it be configurable for later use. Maybe we see that one of those queries is faster and so we can possibly increase the batch size for that one query. \n\nBut I guess using just one is also fine."
        },
        {
          "user": "MoralCode",
          "body": "its ok, this is a bit of a nitpick - i see how it would make sense to leave this in (functionally its identical and its probably not worth merging only to separate later if needed"
        },
        {
          "user": "shlokgilda",
          "body": "I didn't realize the original list comprehension was already materializing all results, effectively closing the cursor. I've updated the code to call `.fetchall()` immediately after both queries"
        },
        {
          "user": "MoralCode",
          "body": "Did this flip the truthiness of this?\n\nIt sounds like not len would be true if len is 0, but the new version is true if missing_commits has nonzero length"
        },
        {
          "user": "MoralCode",
          "body": "i introduced this bug so ill fix it"
        },
        {
          "user": "Ulincsys",
          "body": "`BATCH_SIZE` should ideally be a configurable parameter instead of hardcoded here."
        },
        {
          "user": "shlokgilda",
          "body": "Gotcha!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3420,
      "author": "shlokgilda",
      "created_at": "2025-11-19T17:12:25Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "holy git ops batman - i didnt think there were so many places we did git subprocesses lol"
        },
        {
          "user": "MoralCode",
          "body": "> GenAI Disclosure: Used Claude Code to draft this PR.\r\nDo you mean just the PR description? or the pr diff contents itself?"
        },
        {
          "user": "shlokgilda",
          "body": "> > GenAI Disclosure: Used Claude Code to draft this PR.\r\n> > Do you mean just the PR description? or the pr diff contents itself?\r\n\r\nAah, my bad! I meant just the PR description."
        },
        {
          "user": "MoralCode",
          "body": "> Aah, my bad! I meant just the PR description.\r\n\r\nno worries, just checking! cant wait to find time to finish the policy part of #3371 so we can have a better template for people to use"
        },
        {
          "user": "sgoggins",
          "body": "Outstanding contribution! Reviewing ."
        },
        {
          "user": "MoralCode",
          "body": "@shlokgilda has been thoroughly testing this and has [confirmed](https://chaoss-workspace.slack.com/archives/C0226ELG6R4/p1764789515373849?thread_ts=1764789018.459519&cid=C0226ELG6R4) that the facade workers are flowing.\r\n\r\nI trust this as far as testing goes and am going to mark this as ready"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Re0running podman end to end, which failed."
        },
        {
          "user": "MoralCode",
          "body": "rerunning again. the test passed (all expected log lines seen in the run) but was marked failed because its shutdown took too long and it got killed"
        },
        {
          "user": "sgoggins",
          "body": "> rerunning again. the test passed (all expected log lines seen in the run) but was marked failed because its shutdown took too long and it got killed\r\n\r\nI think your prior comment and the ready tag signal its ready to merge, but since there were commits since your last review @MoralCode , I am double checking."
        },
        {
          "user": "MoralCode",
          "body": "I havent re-reviewed to mark it approved because I havent explicitly tested it personally, but i consider all my review comments to be resolved and I trust @shlokgilda's testing"
        },
        {
          "user": "MoralCode",
          "body": "It seems like we reuse this pattern a lot - could we potentially refactor it into a single function (maybe that's what we can use FacadeHelper for) to deduplicate a lot of this process running wrapper code? especially one where the option for discarding output is explicit"
        },
        {
          "user": "shlokgilda",
          "body": "Great idea. Pushed the changes. \r\n\r\nGenAI Disclosure: Used Claude Code to write the new `run_git_command` in `FacadeHelper` class. Verified the accuracy of the code by manual testing and restarting augur."
        },
        {
          "user": "MoralCode",
          "body": "Lots of these options seem duplicated - i wonder if it would be best to create a dict of the common options and then append the correct set of options depending on `capture_output` and then expand those as  kwargs in a single call to `subprocess.run`"
        },
        {
          "user": "shlokgilda",
          "body": "Addressed in latest commit @MoralCode"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\n            return result.returncode, result.stdout.strip() if capture_output else ''\n```"
        },
        {
          "user": "shlokgilda",
          "body": "In the same file, there are a few more places where we don't use ternary if else blocks. So, I skipped it here as well. Nonetheless, do you think we should use `return result.returncode, (result.stdout.strip() if capture_output else '')` with the parentheses for clarity? Or is it clear to folks that `result.returncode` will always return as the first element?"
        },
        {
          "user": "shlokgilda",
          "body": "Thoughts @MoralCode?"
        },
        {
          "user": "MoralCode",
          "body": "i think the parenthesis would help yeah"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\r\n            return result.returncode, (result.stdout.strip() if capture_output else '')\r\n```"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3426,
      "author": "sgoggins",
      "created_at": "2025-11-20T18:01:22Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@copilot open a new pull request to apply changes based on [this feedback](https://github.com/chaoss/augur/pull/3426#discussion_r2547097340)"
        },
        {
          "user": "sgoggins",
          "body": "@copilot open a new pull request to apply changes based on [this feedback](https://github.com/chaoss/augur/pull/3426#discussion_r2547097363)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3416,
      "author": "MoralCode",
      "created_at": "2025-11-18T19:53:34Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "marking ready due to aforementioned comments on decently extensive testing and relatively low impact of the changes"
        },
        {
          "user": "MoralCode",
          "body": "this doesnt matter but thanks for the reminder reviewdog"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3419,
      "author": "MoralCode",
      "created_at": "2025-11-19T16:10:05Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Out of scope"
        },
        {
          "user": "MoralCode",
          "body": "Out of scope"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3414,
      "author": "shlokgilda",
      "created_at": "2025-11-17T14:58:39Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "since this is a functional change, I suspect it would be best to move to a separate PR for more thorough review"
        },
        {
          "user": "shlokgilda",
          "body": "Fair enough. Closing this PR. Will start with a new PR for unit-tests for keyman, followed by this functional bug fix, and then docs."
        },
        {
          "user": "MoralCode",
          "body": "@shlokgilda we have unit tests (mostly a smoke test) i just learned"
        },
        {
          "user": "MoralCode",
          "body": "early versions of keyman had probabistic weighting for preferring certain keys, so this is somewhat legacy and just left this way because its not hard to change.\r\n\r\nif we want keys to be unique in the key list we should just replace it with a set anyway because sets gaurantee uniqueness"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3410,
      "author": "iGufrankhan",
      "created_at": "2025-11-15T18:11:45Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "The process names is separate. this PR updates the CLI to  use the values from the config (augur.json or DB) for concurrency values when starting aufur from CLI"
        },
        {
          "user": "sgoggins",
          "body": "> The process names is separate. this PR updates the CLI to use the values from the config (augur.json or DB) for concurrency values when starting aufur from CLI\r\n\r\nok ... with that and the redundant tag I'm unsure what to do with this one ..."
        },
        {
          "user": "MoralCode",
          "body": "> > The process names is separate. this PR updates the CLI to use the values from the config (augur.json or DB) for concurrency values when starting aufur from CLI\r\n> \r\n> ok ... with that and the redundant tag I'm unsure what to do with this one ...\r\n\r\nRedundant tag just serves as a flag to say \"hey, there are duplicates of this thing\" (i.e. if two newcomers submit PRs for the same issue). it just means we have to make sure we pick the PR with the best implementation and, once it merges, the other one gets automatically closed for being a duplicate."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3412,
      "author": "shlokgilda",
      "created_at": "2025-11-17T03:00:24Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "> * to persist BadgingDEI records\r\n> DEI endpoints (`dei_track_repo`, `dei_report`) should be manually tested (although I don't think these are even used?)\r\n\r\ni think that table is unused and i plan to drop it soon lol (just filed https://github.com/chaoss/augur/issues/3423)\r\nI suspect you are right about the routes too.\r\n\r\n> Fixed database connection leaks in DEI API endpoints and user CLI commands\r\n\r\nfunny you say that. I'm fairly sure that the DatabaseSession object itself is causing leaks, even when used with `with` based on chatting with other maintainers. Gen AI suggests that this is because the methods often returns raw `Result` objects due to db calls not using functions like `.one()` that specify what kind of results they want, meaning connections are held onto and brought outside the with scope.\r\n\r\n\r\nOverall it seems like you are trying to do several things in this PR that may be better to split into separate, more focused PRs."
        },
        {
          "user": "shlokgilda",
          "body": "Okay, yeah! The \"too many things in one PR\" sounds like me. \n\nI'll try to be more vigilant of this. \n\nRe DatabaseSession: I didn't check that. If that's the case, that should fix a whole bunch of issues."
        },
        {
          "user": "MoralCode",
          "body": "@shlokgilda are there tests to confirm that the core of this change does in fact leak fewer connections?"
        },
        {
          "user": "shlokgilda",
          "body": "Hmm, good question! I don't think so. Might have to figure out a way to calculate the number of connections before/after the fix.\n\nAny suggestions?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3391,
      "author": "MoralCode",
      "created_at": "2025-11-11T18:36:40Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@MoralCode : Your root cause analysis sounds DEAD ON, and explains why this appears not to be working in the case of automatic moving. This will fix that issue."
        },
        {
          "user": "MoralCode",
          "body": "Still waiting on testing this to 100% confirm that this will update the repo_git url"
        },
        {
          "user": "sgoggins",
          "body": "> Still waiting on testing this to 100% confirm that this will update the repo_git url\r\n\r\nWill hold off on marking it ready and merging until you green light it then."
        },
        {
          "user": "MoralCode",
          "body": "Current issues with this: seems to be a dependence on using the repo URL for querying:\r\n\r\n```\r\n[augur]        | 2025-11-18 23:04:30 cd3ac88591d1 augur_collection_monitor[276] INFO Setting github repo core status to collecting for repo: https://github.com/moralcode/classclockapi\r\n[augur]        | [2025-11-18 23:04:30,464: INFO/MainProcess] Task augur.tasks.github.detect_move.tasks.detect_github_repo_move_core[38307c62-7947-495d-ac2f-35d8bd2bb241] received\r\n[augur]        | 2025-11-18 23:04:30 cd3ac88591d1 detect_github_repo_move_core[280] INFO Starting repo_move operation with https://github.com/moralcode/classclockapi\r\n[augur]        | 2025-11-18 23:04:30 cd3ac88591d1 augur_collection_monitor[276] INFO Starting collection on 0 secondary repos\r\n[augur]        | 2025-11-18 23:04:30 cd3ac88591d1 augur_collection_monitor[276] INFO Starting collection on 0 facade repos\r\n[augur]        | 2025-11-18 23:04:30 cd3ac88591d1 detect_github_repo_move_core[280] INFO Pinging repo: https://github.com/"
        },
        {
          "user": "cdolfi",
          "body": "@MoralCode Would changing that query to be based on the repo_src_id fix the issue? Or does github require the URL to get to the repo_src_id?"
        },
        {
          "user": "MoralCode",
          "body": "Thats what I was thinking, I just have to do it. And I suspect the code for it is buried somewhere in augurs various functions."
        },
        {
          "user": "MoralCode",
          "body": "The above stack trace seems to be happening in the error handler for augur's celery tasks. The fact that it is still repo_url based is a different tech debt issue. But the fact that we are getting it comes from us throwing an exception to stop collection on repo move or delete. This is the subject of #3166. ill likely try and solve both in this PR"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : This one appears ready."
        },
        {
          "user": "MoralCode",
          "body": "> This one appears ready.\r\n\r\nIt largely is, however, I would like to also include a new database table alongside this fix so that, when the repo url gets updated, the old one gets saved in a `repo_aliases` table so that lookups can be performed using either the old url or new one (making the process of checking if a repo is already in the db when it is added easier)\r\n\r\nwe can merge this, but data will be lost until that secondary change is in as well, and because that secondary change requires a database migration, its largely blocked on some of the database sync/organizing PRs that are being reviewed currently"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3399,
      "author": "shlokgilda",
      "created_at": "2025-11-12T16:21:52Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Thanks for submitting this!\r\n\r\nI'll try and run/test these changes soon, but just out of curiosity - did you run the tests `uv tun tox` after making these changes to make sure tests that were renamed still run (most of them will likely fail and thats ok, as long as it still can find them and theres no issues caused by the rename)"
        },
        {
          "user": "shlokgilda",
          "body": "@MoralCode Ran all the tests using `uv run tox -e ALL`. Everything seems to be working as expected."
        },
        {
          "user": "shlokgilda",
          "body": "@sgoggins Yep, ran the test suite. I believe @MoralCode is planning to run the tests on his system as well."
        },
        {
          "user": "MoralCode",
          "body": "Seems like the test failure is just because this touches the unit tests and they probably havent been linted, so im inclined to let that slide and deal with that in future PRs that actually fix the tests"
        },
        {
          "user": "MoralCode",
          "body": "I think when i was poking through these tests briefly while pursuing something else, I noticed that this `Persistent` superclass didnt appear to exist in the repo, so  i just removed both of these large classes that inherit from it.\n\nIt also seems like GPT5/cursor is not able to find this import either."
        },
        {
          "user": "shlokgilda",
          "body": "Yep, I noticed that as well. I did repo wide search for \"Persistant\" and \"Persistence\", but couldn't find it. But I didn't want to change the core logic of the tests and just fix the typos for now. Otherwise that would've increased the scope of the PR."
        },
        {
          "user": "MoralCode",
          "body": "yeah i guess thats fair to not want to mix a substantive change like this with an already large PR that renames a ton of stuff"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3387,
      "author": "omkute10",
      "created_at": "2025-11-10T07:03:33Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "thanks for this PR! This is also something ive been working on (updating test fixtures to allow a test database to be spun up/set up)\r\n\r\nOne of the challenges is that we have several ways to initialize the schema and they are all different.\r\n- the .sql file you use here is pretty static/independent, likely somewhat dated, and also failed to work when i messed with it as part of my testing (the way it populates data from stdin seemed to be failing)\r\n- replaying the schema migrations (what the Augur CLI does) seems to be the main way, but it requires building augur enough to access alembic and stuff\r\n- creating the schemas from the SQLAlchemy models seem to me missing/not creating some required sequences, making it hard to inititalize things\r\n\r\nI want to get these all in sync so that this testing is less fragile in future"
        },
        {
          "user": "omkute10",
          "body": "@MoralCode Gotcha!\r\nSo are you looking forward to work on this issue or should I carry forward with the improvements?"
        },
        {
          "user": "MoralCode",
          "body": "> So are you looking forward to work on this issue or should I carry forward with the improvements?\r\n\r\nI will likely be implementing something very similar to this based on my own branch, which makes some more fundamental changes to how the database is connected to and generally used in these test fixtures. That version is most likely the one that will end up getting merged.\r\n\r\nUnless this is valuable to you personally (i.e. as a learning project/for fun), I would encourage you find other ways to help out. If working on database stuff like this is something you are interested in, you *can* take a look at the `db-testing` branch (which contains my changes) and see if you notice how I'm doing things. You could also potentially work based on that branch if you'd like to propose specific commits; however, I realize I haven't communicated my plans in these areas too thoroughly and there's a high likelihood that I'm going to be moving fairly fast on this kind of thing.\r\n\r\nThat said, Once the"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I think this one can be closed based on the last discussions."
        },
        {
          "user": "MoralCode",
          "body": "I dont want to close it because it'll help remind me that i need to get around to doing this. The database test fixture stuff is largely waiting on #3435 right now because its going to be so much easier to initialize testing dbs with sqlalchemy than by replaying all past migrations. (and will act as a proof of concept for doing this as part of the main app's DB init process in future)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3386,
      "author": "AdeebaNizam404",
      "created_at": "2025-11-09T21:38:59Z",
      "comments": [
        {
          "user": "AdeebaNizam404",
          "body": "@MoralCode \r\nKindly review this documentation update that moves contributor details to CONTRIBUTORS.md. Feedback on formatting or missing entries is welcome!"
        },
        {
          "user": "AdeebaNizam404",
          "body": "Thanks @sgoggins and @MoralCode for catching that!\r\nI‚Äôve updated the maintainer list to match the current version from the README and added @MoralCode correctly.\r\nPlease re-review when you have a moment üòä"
        },
        {
          "user": "AdeebaNizam404",
          "body": "Thanks @sgoggins and @MoralCode for the clarification!\r\nI‚Äôve moved Derek Howard to the new Founding Maintainers section as suggested.\r\nApologies for the delay in updating ‚Äî and thank you for your patience.\r\nPlease re-review when convenient üòä"
        },
        {
          "user": "AdeebaNizam404",
          "body": "Hi @MoralCode,\r\n\r\nThank you for pointing these out. I want to sincerely apologize ‚Äî I realized that I unintentionally missed some names in the Former Maintainers section while updating the file. That was my mistake, and I‚Äôm correcting it now.\r\n\r\nI‚Äôve also added a separate heading for Founding Maintainers and placed Derek under it as you suggested. Thank you for the clarification there.\r\n\r\nJust to address your concern: I did not use any Generative AI tool to create the document. I referred to another open-source project for formatting inspiration, which led to a few changes (adding emojis) that weren‚Äôt part of the original README.\r\n\r\nSpecifically, the items I introduced were:\r\n\r\n*Emojis in the headings (I‚Äôve removed them since they caused inconsistency)\r\n\r\n*Making all contributors link clickable\r\n\r\n*Minor changes to the Current Maintainers section\r\n\r\n*Adding a ‚ÄúFounding Maintainers‚Äù heading (as Suggested)\r\n\r\n*Adding GSOC 2025 contributors from the official GSOC website\r\n\r\nI appreciate y"
        },
        {
          "user": "MoralCode",
          "body": "You misattributed my username with Andrew - Despite the Andrew -> Adrian similarity, we are two separate contributors üôÇ"
        },
        {
          "user": "sgoggins",
          "body": "This current maintainer list is not right. The prior one is, and we should probably add @MoralCode ."
        },
        {
          "user": "MoralCode",
          "body": "If im not mistaken, I think Derek stepped away from maintaining Augur a little while ago.\n\nI'll work with the other maintainers to come up with an updated list for this section"
        },
        {
          "user": "MoralCode",
          "body": "ok, so this list is accurate, but I think we should move Derek to a separate \"Founding maintainers\" section just below current maintainers as he was basically the original person who wrote the repo."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I agree that moving Derek to \"Founding Maintainers\" makes sense."
        },
        {
          "user": "MoralCode",
          "body": "this list seems a lot smaller than the one in the current README: https://github.com/chaoss/augur#former-maintainers"
        },
        {
          "user": "MoralCode",
          "body": "Derek should be in a category by himself called \"Founding Maintainers\""
        },
        {
          "user": "MoralCode",
          "body": "These emojis in the heading are not present in the current README.\n\nWas this document generated with the assistance of a Generative AI tool?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3397,
      "author": "xiaoha-cloud",
      "created_at": "2025-11-12T01:28:20Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Can you make this a TimestampTZ so that we can store timezone data as well (see #1370 )"
        },
        {
          "user": "MoralCode",
          "body": "Timestamp with timezone here too"
        },
        {
          "user": "MoralCode",
          "body": "is there a reason these use the postgresql version of TIMESTAMP?\n\nlooks like its also built into Sqlalchemy: https://docs.sqlalchemy.org/en/20/core/type_basics.html#sqlalchemy.types.TIMESTAMP"
        },
        {
          "user": "xiaoha-cloud",
          "body": "Sure I change to use  Sqlalchemy version of TIMESTAMP"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3383,
      "author": "omkute10",
      "created_at": "2025-11-07T12:12:11Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Also, you dont need to re-create PRs to update them, pushing to, or even force-pushing to the branch that you created the PR with will automatically update it"
        },
        {
          "user": "omkute10",
          "body": "@MoralCode Got it!"
        },
        {
          "user": "MoralCode",
          "body": "this can probably be an inline instruction like the ones that were removed.\n\nAlso is the command accurate? i think it at least should be wrapped in a `uv run`"
        },
        {
          "user": "MoralCode",
          "body": "this should probably link to the \"running augur in production\" document that will be added soon. #3249 \n\ni know thats kinda confusing to add before its merged, so maybe this PR should be sequenced after it"
        },
        {
          "user": "omkute10",
          "body": "Yes, please sequence it for later!"
        },
        {
          "user": "omkute10",
          "body": "Please check the new commit and lmk if there are any other changes to be made!"
        },
        {
          "user": "MoralCode",
          "body": "@sgoggins do you know if this command, even with `uv run` is accurate for starting augur in a manual install?"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode / @omkute10 : What is the status of this PR?"
        },
        {
          "user": "omkute10",
          "body": "@MoralCode can you please check this once, as you mentioned earlier to sequence it later."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3384,
      "author": "PredictiveManish",
      "created_at": "2025-11-09T18:17:02Z",
      "comments": [
        {
          "user": "PredictiveManish",
          "body": "@MoralCode are you working on this now? or I can continue? as I got to know that now changes need new files and this is 35th and I will update- remove the suggestions and update accordingly."
        },
        {
          "user": "MoralCode",
          "body": "This change is going to require more than just a schema change. We discussed it briefly at the end of today's Augur call and Sean mentioned that this is likely to require a fair degree of logic changes as well, especially to make sure that various error cases get handled when converting date values (which come from various sources and may all be in different formats).\r\n\r\nAlso since this is a breaking schema change, I think its going to get through review faster if an existing maintainer can handle it.\r\n\r\nI can't stop you from working on it, but i will likely be adopting this change  and working with the maintainers to figure out the best way to handle it (along with lots of other database changes) - especially given similar/related issues like #1370"
        },
        {
          "user": "PredictiveManish",
          "body": "> This change is going to require more than just a schema change. We discussed it briefly at the end of today's Augur call and Sean mentioned that this is likely to require a fair degree of logic changes as well, especially to make sure that various error cases get handled when converting date values (which come from various sources and may all be in different formats).\r\n> \r\n> Also since this is a breaking schema change, I think its going to get through review faster if an existing maintainer can handle it.\r\n> \r\n> I can't stop you from working on it, but i will likely be adopting this change and working with the maintainers to figure out the best way to handle it (along with lots of other database changes) - especially given similar/related issues like #1370\r\n\r\nOk. got your point will work on this so that can understand database system in the augur deeply and manage to solve other issues related to database."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : We probably should discuss this one and decide how it intersects with the other db updates you've been working on."
        },
        {
          "user": "MoralCode",
          "body": "> We probably should discuss this one and decide how it intersects with the other db updates you've been working on.\r\n\r\nThis is a pretty major fix, possibly a breaking change that is very likely to require some soecial handling/special consideration for how to migrate existing data, which can be in just about any date format. I dont really know how to resolve this cleanly and its probably going to be a pretty big effort that may not be worth it for a while."
        },
        {
          "user": "MoralCode",
          "body": "This is not the correct file to update. When making schema changes, a new file should be created (i.e. create a new migration file with a higer number and use the `upgrade()` and `downgrade()` functions to apply/undo the schema change (especially being mindful to handle any data that may exist in someones DB at the time of this change)"
        },
        {
          "user": "sgoggins",
          "body": "While it is logical to convert dates to timestamps or another date type, the data is stored, in this instance, as a VARCHAR in the table. This almost surely arises from the inconsistency of package managers and how we obtain this data. I don't think this change is going to work without breaking some of the logic embedded in the source data; because the source data is heterogeneous. This change is simply likely to be incompatible, as illogical as that seems."
        },
        {
          "user": "sgoggins",
          "body": "This is a serialization and deserialization of all schema changes over time. Current instances will break or be inconsistent and broken if we add things mid-construction like this; It'll be ok on any new instances, but problematic for existing ones."
        },
        {
          "user": "PredictiveManish",
          "body": "Ok, working in that direction."
        },
        {
          "user": "MoralCode",
          "body": "@sgoggins as the operator of the largest augur instance I know of, can you do an audit of these fields to see if you can actually observe any such date inconsistencies that would be problematic? or at least grab a list of samples of the variety of date values in this column so we can understand the kind of incompatibility you suspect/are thinking about?\r\n\r\nDates are one of the more structured/precisely defined types and python has some pretty good date parsing libraries. If Augur downstreams can at least somewhat use the data in this column, i feel like we can also help take on some of that data cleaning effort to make things easier on downstream projects. And if there are serious compatibility issues, we could introduce this change by creating a new text field where we populate the values that cant be processed into a valid date."
        },
        {
          "user": "PredictiveManish",
          "body": "Removed the unnecessary changes"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : After looking more closely at the data we are saving, I think some of the existing values have timezones, and others do not. They do all appear to be \"valid\" dates. I think the challenge then becomes ensuring the proper conversion of already in place data, which will require some experimentation, I think. \r\n\r\n@PredictiveManish : \r\n\r\nI Ran this on my instance with ~150k repos and got no rows that were \"not convertable\" to a timestamped TimeZoned datatype: \r\n\r\n```sql\r\nDROP TABLE IF EXISTS _rdl_bad;\r\n\r\nCREATE TEMP TABLE _rdl_bad AS\r\nWITH s AS (\r\n  SELECT\r\n    t.ctid AS row_id,\r\n    t.current_release_date,\r\n    t.latest_release_date,\r\n\r\n    COALESCE(\r\n      CASE WHEN t.current_release_date ~* '^\\d{4}-\\d{2}-\\d{2}[ T]\\d{2}:\\d{2}(:\\d{2}(\\.\\d+)?)?(Z|[+-]\\d{2}:?\\d{2})$'\r\n           THEN t.current_release_date::timestamptz END,\r\n      CASE WHEN t.current_release_date ~* '^\\d{4}-\\d{2}-\\d{2}[ T]\\d{2}:\\d{2}(:\\d{2}(\\.\\d+)?)?$'\r\n           THEN (t.current_release_date::timestamp) AT TIME"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3376,
      "author": "omkute10",
      "created_at": "2025-11-06T05:19:37Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Thanks for this fix!\r\n\r\nI am planning to address various database and schema jank very soon, however I'm not quite there yet. These kinds of changes tend to be breaking changes as well.\r\n\r\nI will likely be folding this change into some of the other changes I want to make, but I can't promise that will happen especially quickly. Im hoping for sometime in November but we shall see.\r\n\r\nIm going to assign myself and mark this as pending changes as a reminder for me to return to this when i shift focus from the config system to the DB schema.\r\n\r\nThanks again for submitting this PR!"
        },
        {
          "user": "omkute10",
          "body": "Great!"
        },
        {
          "user": "sgoggins",
          "body": "This PR needs to pass CI. @MoralCode : Do you think this docker fail is related to the others we are seeing?"
        },
        {
          "user": "MoralCode",
          "body": "the CI is failing with this exception:\r\n\r\n```\r\n Traceback (most recent call last):\r\naugur-1         |   File \"/augur/.venv/bin/augur\", line 10, in <module>\r\naugur-1         |     sys.exit(run())\r\naugur-1         |              ^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1462, in __call__\r\naugur-1         |     return self.main(*args, **kwargs)\r\naugur-1         |            ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1383, in main\r\naugur-1         |     rv = self.invoke(ctx)\r\naugur-1         |          ^^^^^^^^^^^^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1844, in invoke\r\naugur-1         |     cmd_name, cmd, args = self.resolve_command(ctx, args)\r\naugur-1         |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\naugur-1         |   File \"/augur/.venv/lib/python3.11/site-packages/click/core.py\", line 1"
        },
        {
          "user": "sgoggins",
          "body": "As an update, I think this PR is delayed by its sheer scope."
        },
        {
          "user": "sgoggins",
          "body": "@omkute10 : Do you plan to address the failing integration tests?"
        },
        {
          "user": "MoralCode",
          "body": "yes, This PR is waiting for some other database changes to land first (notably #3435), as well as thinking through how the migration process will work for existing users (i hope postgres lets you RENAME a column, rather than creating a new one, copying data, and deleting the old one)"
        },
        {
          "user": "omkute10",
          "body": "@sgoggins Cannot comment anything on thr failing PR. Debugged it at my end but as @MoralCode mentioned, it needs the database changes. And once done, it will pass all CI and it's ready to merge."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3373,
      "author": "omkute10",
      "created_at": "2025-11-04T12:02:59Z",
      "comments": [
        {
          "user": "omkute10",
          "body": "@MoralCode Done with the changes as per requested, please do check and lmk if I am missing anything!"
        },
        {
          "user": "MoralCode",
          "body": "the CI jobs are also not passing. its not clear from the logs why, but I suspect this has to do with the missing `datetime` import."
        },
        {
          "user": "omkute10",
          "body": "@MoralCode Thank you for your feedback! I've made the following improvements to the code:\r\n\r\n1. Removed redundant TypedDict classes (ContributorData, PRLabelData, PRBaseData) that were duplicating SQLAlchemy models.\r\n2. Updated type hints to use List[Dict[str, Any]] where appropriate.\r\n3. Enhanced code quality with better null checks and safer dictionary access.\r\n4. Added comprehensive docstrings and improved code organization.\r\n5. Ensured all type annotations are consistent throughout the file.\r\n\r\nThe changes maintain the same functionality while making the code more maintainable and aligned with the SQLAlchemy ORM patterns."
        },
        {
          "user": "MoralCode",
          "body": "how is this PR different from #3367"
        },
        {
          "user": "omkute10",
          "body": "@MoralCode \r\nMy Bad! \r\n#3367 covers it all at once. So you can close this."
        },
        {
          "user": "MoralCode",
          "body": "Im not sure these type aliases help readability since it requires people to check one additional place in the code to see what the type is for the function they are trying to call"
        },
        {
          "user": "MoralCode",
          "body": "This import is new in this PR and not used"
        },
        {
          "user": "MoralCode",
          "body": "These classes seem quite long and potentially duplicated with the ORM model class objects that already exist in the data models."
        },
        {
          "user": "omkute10",
          "body": "Will resolve this!"
        },
        {
          "user": "sgoggins",
          "body": "Yeah, this is a really old library. I would not use it anywhere, tbh."
        },
        {
          "user": "MoralCode",
          "body": "dataclasses is i think a python3 builtin. https://docs.python.org/3/library/dataclasses.html\r\n\r\nits useful, just wasnt in use here"
        },
        {
          "user": "MoralCode",
          "body": "reviewdog also wants datetime to be imported for this type declaration to work"
        },
        {
          "user": "MoralCode",
          "body": "Why was this removed?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3368,
      "author": "Vatsal-Patel-09",
      "created_at": "2025-11-03T14:45:11Z",
      "comments": [
        {
          "user": "Vatsal-Patel-09",
          "body": "Thanks! for the feedback, I did the requested changes few days ago , along with proper pluralization instead of \"day(s)\""
        },
        {
          "user": "MoralCode",
          "body": "i feel like saying something like \"every <number> days\" may be a better phrasing"
        },
        {
          "user": "Vatsal-Patel-09",
          "body": "Thanks! for the feedback, I did the requested changes  along with proper pluralization instead of \"day(s)\""
        },
        {
          "user": "MoralCode",
          "body": "it might be better to make this a ternary if statement\n\n\n```suggestion\n            day_text = \"day\" if mat_views_interval == 1 else \"days\"\n```"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3366,
      "author": "TudorGR",
      "created_at": "2025-11-01T17:24:26Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "While this is a good start, I was thinking it may be better to also mention it in a more paragraph-like format closer to the top of the file so that new contributors see it as one of the first things if they decide to read this file. That way, if they get stuck, they will already be in a position to ask for help in the right place."
        },
        {
          "user": "MoralCode",
          "body": "Can you move the \"join the community\" section to be below this line about reading the docs?"
        },
        {
          "user": "TudorGR",
          "body": "Done! Moved the \"Join the Community\" section to appear after the docs introduction line as requested. üëç"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3375,
      "author": "shlokgilda",
      "created_at": "2025-11-05T03:09:41Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Another thing i would like to include in this change is unit testing - i have recently been getting things up and running again and would like to ensure that all the various cases of this functionality are covered by tests"
        },
        {
          "user": "shlokgilda",
          "body": "@MoralCode I like that. I'll add a few unit tests. That brings me to a completely different coding style issue: type hints and docstrings? I can see that some files/functions have type hints whereas some don't. Do we have some general guidelines?"
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode I like that. I'll add a few unit tests. That brings me to a completely different coding style issue: type hints and docstrings? I can see that some files/functions have type hints whereas some don't. Do we have some general guidelines?\r\n\r\n\r\nI'm hoping to work towards more thorough documentation and actual whole-repo type checking yes. if you would like to add your new files to the list in the `mypy` section of config at the end of `pyproject.toml` so that  `uv run mypy` will typecheck them, you can do that!\r\n\r\nalso happy to chat in the [CHAOSS Slack](https://chaoss.community/kb-getting-started/) (in the #wg-augur-8knot channel) if you'd like. especially if you want to be able to test out running unit tests before my branch that fixes them gets merged"
        },
        {
          "user": "shlokgilda",
          "body": "@MoralCode Added test cases and type hints. Will update `pyproject.toml` later once your PR is merged. I generated a `pytest.ini` locally to test my new test cases since I ran into issues with pytest with the pyproject.toml file.\r\n\r\n**Note:** Generated the new test cases using Claude Code. But I've tested everything and reviewed the code before committing."
        },
        {
          "user": "MoralCode",
          "body": "> Will update `pyproject.toml` later once your PR is merged. I generated a `pytest.ini` locally to test my new test cases since I ran into issues with pytest with the pyproject.toml file.\r\n\r\nThings have been merged now! feel free to rebase (dont forget to make sure all commits have a DCO signoff) and make sure the tests work"
        },
        {
          "user": "shlokgilda",
          "body": "@MoralCode All of my previous commits have been signed off. I should probably add a global config locally to do that. I keep forgetting to do that. \r\n\r\nRe tests: `uv run tox` only runs the `classes` environment by default, which only tests `tests/test_classes/`. I had to specifically run `uv run tox -e py-application`. I could update `pyproject.toml` to include application tests by default as well. I didn't do it yet since I wasn't sure about specific design choices when it comes to running the test suite."
        },
        {
          "user": "shlokgilda",
          "body": "@MoralCode Any more changes requested?"
        },
        {
          "user": "MoralCode",
          "body": "I suspect people may like to still have the progress counter (line num/line total) during the import"
        },
        {
          "user": "MoralCode",
          "body": "I see this is largely the same as `process_repo_csv` above it with only very minor differences for specifying the specific headers to look for.\n\nI think it may be better to refactor this into a single function. What do you think of doing this and allowing the column names to be passed in as a dict that maps the column name to a function that can check for values that make sense for that column.\n\ni.e. for the repo csv you could pass in `{'repo_url': lambda v: <check both parse_github_repo_url and parse_gitlab_repo_url and return true if one of them passes>, `repo_group_id`:  lambda v: str(v).isnumeric()}`\n\nis this overcomplicated do you think?"
        },
        {
          "user": "MoralCode",
          "body": "i wonder if we can use the column detection to just.... insert a header row at the beginning of the CSV data and then rerun it through the DictReader code path?\n\ni.e. \n1. open the file and initialize a dictReader\n2. check the `reader.fieldnames` property to see what the detected names are\n3. if the names detected dont match whats expected (i.e. its returning none or theres actual data in the list thats returned instead of actual values) use the data in the field names parameter (i.e. is there a url or an integer first) to create the field names list and assign it to `reader.fieldnames`\n4. iterate through the rows and process as normal. Both cases are now using the same code.\n\nWhen doing this we should also make sure that reassigning fieldnames in this way will cause the first row to be treated like data, and not ignored/overwritten."
        },
        {
          "user": "MoralCode",
          "body": "hmm, now that I see this implemented i wonder if it would be easier to just log errors and the rows that caused them to the console, especially since this mostly just lives within the CLI interface anyway."
        },
        {
          "user": "MoralCode",
          "body": "I'm curious how this file is connected to the above parsing code since its a test of Facade, not of the CLI."
        },
        {
          "user": "shlokgilda",
          "body": "Good call! Added the progress counter back in - now shows \"Inserting repo X/Y...\" for each repository."
        },
        {
          "user": "shlokgilda",
          "body": "Love this idea! Refactored into a single `process_csv()` function that takes validators as a dict. The two processing functions are just thin wrappers that pass in their specific validators."
        },
        {
          "user": "shlokgilda",
          "body": "The new implementation uses `DictReader` for both cases. When headers are missing, it detects the column order and processes all rows with the detected mapping. Both code paths are unified now."
        },
        {
          "user": "shlokgilda",
          "body": "Yeah, that's simpler. Removed the rejection file entirely - now just logs failed rows and their errors directly to the console."
        },
        {
          "user": "shlokgilda",
          "body": "Hmm, this was a good catch. This was a misunderstanding on my end about the codebase. Reverted them back to the original format."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3370,
      "author": "YashSejani",
      "created_at": "2025-11-03T17:10:23Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Also be aware that this PR, #3368, and #3370 are all solving the same issue, and only one of them can be merged."
        },
        {
          "user": "MoralCode",
          "body": "Can you move these imports to the top of the file and deduplicate them with existing imports if they are already present?"
        },
        {
          "user": "YashSejani",
          "body": "okk"
        },
        {
          "user": "MoralCode",
          "body": "This module for `datetime` (on the right side of the import) is using the same name as the package imported about 5 lines above this (just above `import traceback`). This is likely going to cause issues with calls in the code that call `datetime.datetime.something()`. \r\n\r\nId suggest adjusting your calls to `datetime` and `timedelta` to be `datetime.datetime` and `datetime.timedelta` respectively"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3364,
      "author": "omkute10",
      "created_at": "2025-11-01T12:02:49Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Thank you for the contribution, @omkute10 ! \r\n\r\nThis PR is not on the critical path for our current work, so I am closing this to help scope our test suite."
        },
        {
          "user": "omkute10",
          "body": "@sgoggins no worries!"
        },
        {
          "user": "MoralCode",
          "body": "Closing as these changes are also part of https://github.com/chaoss/augur/pull/3367"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3367,
      "author": "omkute10",
      "created_at": "2025-11-03T11:16:03Z",
      "comments": [
        {
          "user": "omkute10",
          "body": "Sure!"
        },
        {
          "user": "MoralCode",
          "body": "why was this python type `dict` replaced with one from `typing` (`Dict`)?"
        },
        {
          "user": "MoralCode",
          "body": "we probably shouldnt be adding `Any` types here"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3378,
      "author": "MoralCode",
      "created_at": "2025-11-06T16:05:28Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Im ignoring the codeql misspell CI failure because that came from the inclusion of the unit testing config, where a folder and its associated job name (which are unused here) are misspelled. Im considering this out of scope for this PR given the already large diff.\r\n\r\nI can address this in a followup if it is important"
        },
        {
          "user": "MoralCode",
          "body": "I'm also thinking instead of all the complexity surrounding the dynamic filtering of the list of config store backends, It may be easier to just separately store/designate a single config entry that is the writable one and use that. it would be less dynamic, but I think thats acceptable because realistically these config backends aren't likely to change much (other than maybe introducing a backend to interface with the \"configmanager\" service (think like keyman), once that exists."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Obviously need to fix the CII ... Do we think we need to have @JohnStrunk revisit our current Docker builds? It is unclear if we have made docker brittle or more brittle, or if there is just some brittleness related to the changes we are making."
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode : Obviously need to fix the CII ... Do we think we need to have @JohnStrunk revisit our current Docker builds? It is unclear if we have made docker brittle or more brittle, or if there is just some brittleness related to the changes we are making.\r\n\r\nI don't think we need to pull John in. I have a decent amount of container experience at this point, and I think the dynamic of two required reviews, one from someone using a manual install and one from someone on docker is good, especialy if we intend to support both. My bigger issues are more surrounding docker vs podman differences to be honest.\r\n\r\nI'll get the CI working."
        },
        {
          "user": "shlokgilda",
          "body": "There's a typo in `tests/test_applicaton`. Should be `test_application` (missing `i`.) Not sure if if's within the scope of this PR but if you're updating `tests/test_applicaton/test_config/test_config.py`, is it prudent to fix the typo? Or should I open a separate issue and PR for that?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3359,
      "author": "kabir2123",
      "created_at": "2025-10-30T21:01:46Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Was there a reason this was closed?"
        },
        {
          "user": "kabir2123",
          "body": "> Was there a reason this was closed?\r\n\r\nI didnt sign my commit off so had to close it"
        },
        {
          "user": "MoralCode",
          "body": "ah ok.\r\nyou can sign your commit with `git rebase HEAD~1 --signoff`  (replace the `1` with the number of commits in your branch you want to sign off.\r\n\r\nthis will rewrite those commits  (giving them new hashes) and include a signoff in the commit message. \r\nthen do a `git push --force` to push to your branch and tell git \"i know these are different commits than you have - but take these anyway\" (careful this can be dangerous\r\n\r\nif you prefer not to do this force push, you can also create a new branch at your rewritten commit with `git checkout -b <branch name>` and push to a new branch and create a new PR from that."
        },
        {
          "user": "kabir2123",
          "body": "Great I have done the same. Can you please merge the branch now?"
        },
        {
          "user": "MoralCode",
          "body": "> Great I have done the same. Can you please merge the branch now?\r\n\r\nThere's still some unaddressed feedback I left on this PR regarding your redirect back to the settings page when there is an error (which prevents users from seeing the flash messages).\r\n\r\nI have marked this as accepted for the purposes of hacktoberfest though in case you are participating"
        },
        {
          "user": "kabir2123",
          "body": "> > Great I have done the same. Can you please merge the branch now?\r\n> \r\n> There's still some unaddressed feedback I left on this PR regarding your redirect back to the settings page when there is an error (which prevents users from seeing the flash messages).\r\n> \r\n> I have marked this as accepted for the purposes of hacktoberfest though in case you are participating\r\n\r\nI have made the required changes. Lmk if I need to make any more ammends. I'll be happy to do so. Also I was eyeing on Google Summer of Code and not hacktober fest but Thanks!!!"
        },
        {
          "user": "MoralCode",
          "body": "Because this is a fairly narrowly targeted fix for a confirmed crashing scenario, im going to try and get this merged for this release"
        },
        {
          "user": "kabir2123",
          "body": "> Because this is a fairly narrowly targeted fix for a confirmed crashing scenario, im going to try and get this merged for this release\r\n\r\nI am contributing for the first time. Hope I was actually able to solve some problem"
        },
        {
          "user": "MoralCode",
          "body": "> I am contributing for the first time. Hope I was actually able to solve some problem\r\n\r\nWelcome! This contribution definitely is helpful - you were able to identify and fix a crash you found in the UI - kudos!\r\n\r\nIf you plan to stick around or continue using Augur, feel free to check out the [getting started](https://chaoss.community/kb-getting-started/) page and join the #wg-augur-8knot channel on slack if you'd like to chat with other users and/or the team!"
        },
        {
          "user": "MoralCode",
          "body": "If the user was just on the page listing repos in a specific group, It might be a little surprising to have them suddenly be directed to  the page they were on before that.\r\n\r\nI also suspect the flash messages are intended to show an error on the same page the user is currently on (kind of like how you might see little toast message popups in mobile apps)"
        },
        {
          "user": "MoralCode",
          "body": "Good catch! seems like we arent using the parameters of url_for properly!"
        },
        {
          "user": "MoralCode",
          "body": "Can you remove the return statements that redirect to the user settings  page from this PR?"
        },
        {
          "user": "MoralCode",
          "body": "It seems like this if statement is now no longer doing anything"
        },
        {
          "user": "MoralCode",
          "body": "we should probably also print a log message here with the actual exception so the admin of augur knows what specifically happened."
        },
        {
          "user": "kabir2123",
          "body": "added a return statement here"
        },
        {
          "user": "kabir2123",
          "body": "updated please check"
        },
        {
          "user": "MoralCode",
          "body": "looks good, thanks!"
        },
        {
          "user": "MoralCode",
          "body": "Was it your editor that reformatted a lot of these imports? I dont see anything crazy wrong just wanted to check where this came from"
        },
        {
          "user": "kabir2123",
          "body": "The pylint check was failing coz of the order of imports. So had to make some tweaks"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3354,
      "author": "MoralCode",
      "created_at": "2025-10-29T00:37:47Z",
      "comments": [
        {
          "user": "giordano",
          "body": "I did a quick smoke test and it looks like this PR fixes our problem with some commits, like https://github.com/UCL/rsd-engineeringcourse/commit/fffaf9ad163c9c6ebb4128c69f4ce9d40e465d18, not being attributed to any user, as [it's currently happening](https://github.com/chaoss/augur/issues/3317#issue-3526950995).  `SELECT c.* FROM augur_data.contributors AS c WHERE cntrb_email IS NOT NULL` is quickly filled up and doesn't decrease over time anymore.    Thank you!"
        },
        {
          "user": "MoralCode",
          "body": "Sweet! Since I made modifications since we wrote this and it impacts a critical part of the code, I'd like to get @ABrain7710's input on this before merging"
        },
        {
          "user": "samcunliffe",
          "body": "Same lines of code in two places, should this be abstracted out?"
        },
        {
          "user": "samcunliffe",
          "body": "Also, should you tag/co-authored-by @razekmh somewhere? Maybe mention in the merge commit?"
        },
        {
          "user": "MoralCode",
          "body": "> Same lines of code in two places, should this be abstracted out?\r\n\r\nif you are referring to session.py vs lib.py, then yes. In fact this fix is what sparked #3345, which I plan to fix quite soon, just maybe not in this release\r\n\r\n> Also, should you tag/co-authored-by @razekmh somewhere? Maybe mention in the merge commit?\r\n\r\nyep, I can do that! Also edited this PR description to explicitly mention it. Even though we only took a tiny piece of the original PR, the inspiration was definitely helpful"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3353,
      "author": "IsaacMilarky",
      "created_at": "2025-10-29T00:32:04Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : I think you said this was ready for review when we met the other day. Checking back because its still in \"draft mode\"."
        },
        {
          "user": "MoralCode",
          "body": "My $0.02: could we make the new option more descriptive? Like \"facade_process_commit_messages\"?\n\nOther users may not know what this is intuitively and the config is going to be most peoples main interaction with augur internals"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : I think @MoralCode makes a good suggestion."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Can you let us know if this is finished up?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3348,
      "author": "PredictiveManish",
      "created_at": "2025-10-28T12:56:31Z",
      "comments": [
        {
          "user": "PredictiveManish",
          "body": "> This seems like a good start! I'd wonder if there are ways to use existing logger objects or create them in more similar ways to how the ones that already exist are created. Right now it sorta feels like there are more new loggers to have to manage (that said though, i havent gotten deep into how augur does logging)\r\n\r\nWherever logger were absent in files I created and where already defined i used them, but in some files each methods have mentioned there own logger, I will try to reduce unnecessary loggers."
        },
        {
          "user": "PredictiveManish",
          "body": "> @PredictiveManish : Can you address @MoralCode 's suggestion?\r\n\r\nYes sir, following what he said."
        },
        {
          "user": "PredictiveManish",
          "body": "@MoralCode Sorry for this question, but if possible can you make a small explanation what it means by tech debt? I can't understand what does this means."
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode Sorry for this question, but if possible can you make a small explanation what it means by tech debt? I can't understand what does this means.\r\n\r\nI'll probably do a worse job explaining than other sources online, but Tech debt is essentially a nickname for \"technical debt\", which is essentially a software engineering/developer term for code \"mess\" that accumulates over time. For example, if part of a codebase (such as a function to insert bulk data into a database, or a logging system) is refactored/rewritten, but not everything that was using the old system got moved over, the code now has two methods for doing that thing. You could also think of technical debt as maybe \"shortcuts\" that get taken with regard to the code (often done to save time) that need to be cleaned up later. Sort of like \"hey ill just do things this way temporarily and fix it later\". Its called debt because its similar to \"taking out a loan against your future\" but for code. Just like how you may get "
        },
        {
          "user": "PredictiveManish",
          "body": "> > @MoralCode Sorry for this question, but if possible can you make a small explanation what it means by tech debt? I can't understand what does this means.\r\n> \r\n> I'll probably do a worse job explaining than other sources online, but Tech debt is essentially a nickname for \"technical debt\", which is essentially a software engineering/developer term for code \"mess\" that accumulates over time. For example, if part of a codebase (such as a function to insert bulk data into a database, or a logging system) is refactored/rewritten, but not everything that was using the old system got moved over, the code now has two methods for doing that thing. You could also think of technical debt as maybe \"shortcuts\" that get taken with regard to the code (often done to save time) that need to be cleaned up later. Sort of like \"hey ill just do things this way temporarily and fix it later\". Its called debt because its similar to \"taking out a loan against your future\" but for code. Just like how you ma"
        },
        {
          "user": "PredictiveManish",
          "body": "@MoralCode the testcase which is failing is showing that in some files `else` is used after `return` and that's where around 9-10 warnings are there which is failing `run-linting-checks/runner/pylint (pull request)` do you suggest upgrading that?"
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode the testcase which is failing is showing that in some files `else` is used after `return` and that's where around 9-10 warnings are there which is failing `run-linting-checks/runner/pylint (pull request)` do you suggest upgrading that?\r\n\r\nIf you added the `else:` in your PR, i would say yes it should be fixed. A quick skim of the diff here seems to suggest these were present before though, so I wouldn't worry about it. Code changes like that are more of a stylistic choice anyway and I think keeping the else - while not the most concise - may make the code more readable. \r\n\r\nIn other words, theres a solid chance the pylint rules could be \"wrong\". dont sweat it."
        },
        {
          "user": "PredictiveManish",
          "body": "> > @MoralCode the testcase which is failing is showing that in some files `else` is used after `return` and that's where around 9-10 warnings are there which is failing `run-linting-checks/runner/pylint (pull request)` do you suggest upgrading that?\r\n> \r\n> If you added the `else:` in your PR, i would say yes it should be fixed. A quick skim of the diff here seems to suggest these were present before though, so I wouldn't worry about it. Code changes like that are more of a stylistic choice anyway and I think keeping the else - while not the most concise - may make the code more readable.\r\n> \r\n> In other words, theres a solid chance the pylint rules could be \"wrong\". dont sweat it.\r\n\r\nYes, I didn't added them, ok thanks for clarifying that pylint errors is not an issue, i thought it'll cause trouble in merging to  main.\r\nDo you've any other suggestion for the PR, otherwise I think it's resolving the issue and replaced all print statement to `logger` command."
        },
        {
          "user": "MoralCode",
          "body": "I think this is ready but im holding off on marking it as such until we get the next release cut"
        },
        {
          "user": "PredictiveManish",
          "body": "> I think this is ready but im holding off on marking it as such until we get the next release cut\r\n\r\nOk sir."
        },
        {
          "user": "MoralCode",
          "body": "oops, i should probably test this soon"
        },
        {
          "user": "PredictiveManish",
          "body": "> What reviewdog is choking on seems pedantic. If @PredictiveManish could fix it I think we'd have it passing. I technically agree that:\r\n> \r\n> ```python\r\n> if \"joe\" == \"bob\": \r\n>     return whatever\r\n> \r\n> Do next thing\r\n> ```\r\n> \r\n> is better than:\r\n> \r\n> ```python\r\n> if \"joe\" == \"bob\": \r\n>     return whatever\r\n> else: \r\n>     Do next thing\r\n> ```\r\n> \r\n> But good golly it works either way.\r\n\r\nyeah sure, I'm fixing this. will do it in 24 hours sir as I have an exam today."
        },
        {
          "user": "MoralCode",
          "body": "Would this be better to put at the top of the file?"
        },
        {
          "user": "MoralCode",
          "body": "it would be nice to print this along with more context about what this number is (i.e. print it as part of an f-string that says its the libdays value)"
        },
        {
          "user": "PredictiveManish",
          "body": "I followed the flow of the file, as in some files modular level logger were there and in some files each methods had in this format so defined in this way \r\nlike `def get_days(): logger=logging.getLogger(get_days.__name__)`\r\n\r\nYes, I think this also needs change, and modular level logger will be great!"
        },
        {
          "user": "PredictiveManish",
          "body": "Ok sir"
        },
        {
          "user": "PredictiveManish",
          "body": "Updated!"
        },
        {
          "user": "MoralCode",
          "body": "Actually, I know I asked you to move things like this to the top of the file, but I think im realizing that this will potentially cause log messages from several places to be printed under different names.\r\n\r\n\r\nAlso The intention for the issue #3313 was to simply replace calls to `print()` with `logger.<level>()` calls so that logs are shown at the appropriate level and can be managed in a uniform way across the project.\r\n\r\nCan you update this PR so that the only changes are these print() -> logger changes?\r\n\r\napologies if my initial issue on this wasn't clear enough!"
        },
        {
          "user": "PredictiveManish",
          "body": "No issues, I will update as you said!"
        },
        {
          "user": "PredictiveManish",
          "body": "Done @MoralCode !"
        },
        {
          "user": "sgoggins",
          "body": "I don't know why reviewdog is choking on line 123. The if-then-else appears fully logical to me and was not changed as part of this PR. \n\n@MoralCode / @PredictiveManish : Have we seen this before? \nRaw Output:\naugur/tasks/util/worker_util.py:123:8: R1705: Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it (no-else-return)\n[action-pylint] Clean up reviewdog...\nError: Process completed with exit code 1."
        },
        {
          "user": "PredictiveManish",
          "body": "yes many times I have seen that reviewdog suggest a warning which doesn't looks as an error"
        },
        {
          "user": "MoralCode",
          "body": "Ive also noticed reviewdog point out these kind of lint warnings from other parts of the code that were not touched in the PR (and IMO adding them to the PR would be introducing out of scope changes into the PR)"
        },
        {
          "user": "PredictiveManish",
          "body": "I think it reviews for clean code as it has shown 10 warnings here which are fine in use but suggestions so that more adjustments to make I am working on few of them."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3344,
      "author": "MoralCode",
      "created_at": "2025-10-27T18:25:39Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "discussion result: lets do this"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : This seems ready. @Ulincsys : Can you review?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3342,
      "author": "razekmh",
      "created_at": "2025-10-26T14:04:07Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "@sgoggins \r\n\r\n> I appropriate that there are cases where data in the database need to be overwritten with Null or a full row needs to be replaced including some new Null values. \r\n\r\nAre you able to speak more to this? Do you think there are cases where this \"overwriting with null\" behavior is intended?"
        },
        {
          "user": "MoralCode",
          "body": "root cause may be related to #3217"
        },
        {
          "user": "MoralCode",
          "body": "a query to watch for the issue:\r\n\r\n```sql\r\nSELECT  (SELECT COUNT(*) FROM augur_data.contributors_aliases) AS aliases_count,\r\n  (SELECT COUNT(cntrb_email) FROM augur_data.contributors) AS cntrb_email_c,\r\n  (SELECT COUNT(cntrb_canonical) FROM augur_data.contributors) AS cntrb_canonical_c;\r\n```"
        },
        {
          "user": "sgoggins",
          "body": "Riffing of of @MoralCode , I wrote some python to save information to a file and append rows to follow trends\r\n\r\nRequirements: \r\n```\r\npsycopg2-binary\r\npandas \r\n```\r\n\r\n```python\r\nimport psycopg2\r\nimport pandas as pd\r\nimport os\r\n\r\noutput_path = \"/Users/sean/Desktop/contributor_counts.csv\"\r\n\r\nconn = psycopg2.connect(\"dbname=augur port=5434 user=augur password='xxxx' host=xxxx \")\r\n\r\nquery = \"\"\"\r\nSELECT\r\n  (SELECT COUNT(*) FROM augur_data.contributors_aliases) AS aliases_count,\r\n  (SELECT COUNT(cntrb_email) FROM augur_data.contributors) AS cntrb_email_c,\r\n  (SELECT COUNT(cntrb_canonical) FROM augur_data.contributors) AS cntrb_canonical_c;\r\n\"\"\"\r\n\r\ndf = pd.read_sql(query, conn)\r\n\r\n\r\nif os.path.exists(output_path):\r\n    df.to_csv(output_path, mode='a', index=False, header=False)\r\n    print(f\"Appended new row to {output_path}\")\r\nelse:\r\n    df.to_csv(output_path, index=False)\r\n    print(f\"Created new file at {output_path}\")\r\n```"
        },
        {
          "user": "MoralCode",
          "body": "Thank you for this PR\r\n\r\nSince this PR touches some critical components of the codebase that affect nearly every database operation, the core maintainers reviewed it and decided to create #3354 instead. This PR includes the essential part (the coalesce) from this PR, but excludes other parts, such as the iterating over `string_fields` (both for performance reasons, and, despite the name, thats not the purpose of string fields this is documetned inthe mentioned PR).\r\n\r\nThanks again for your work! Hoping to get the fix for this merged soon!\r\n\r\nI'm going to close this PR as it is superseded by the other one"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\r\n    _email = contributor.get(\"email\", None)\r\n```\r\nThis is a different syntax that should achieve the same thing. technically explicitly specifying None isnt required as i think its the default, but kept it just to make it obvious what is happening here"
        },
        {
          "user": "MoralCode",
          "body": "were you actually seeing examples of these empty and string-null values in the DB?\r\n\r\nif so, maybe checking `_email.lower() == \"null\"` would be more robust against other edge cases"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : i think that is the right question. It seems like, from Slack discussion, folks are seeing this happen."
        },
        {
          "user": "sgoggins",
          "body": "Since this is a general function we will need to do some smoke testing on this change. I'm wondering if we should setup an instance using this code. @MoralCode ? What do you think?"
        },
        {
          "user": "sgoggins",
          "body": "This section is probably even more important to smoke test."
        },
        {
          "user": "razekmh",
          "body": "No, I have only seen the usual \"NULL\" but I was trying to cast a wide net. I think some of the cases (None, \"\", \"null\", \"Null\") might not be needed but I did not test removing one at a time and checking. I was hoping that I could attached a debugger and check the data while the parsing/insertion is happening but did not manage to do this either. \r\n\r\nYes, `_email.lower() == \"null\"` would be better"
        },
        {
          "user": "sgoggins",
          "body": ".. and perhaps this change most important. All the changes read like they will work; I am suggesting the smoke test because this code is used in many collection tasks."
        },
        {
          "user": "MoralCode",
          "body": "Sounds good to me!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3336,
      "author": "MoralCode",
      "created_at": "2025-10-23T19:29:47Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "None of them should be used, period. For basically every single one of these, I ctrl-F-ed after the name, and looked to see if we were importing it anywhere throughout the entire codebase.\n\nI did also have the idea of making it an optional sub package too, but I'm not sure how that works"
        },
        {
          "user": "MoralCode",
          "body": "some of these are for sure still being used by the ml workers\r\n\r\n\"scikit-image==0.19.1\",\r\n    \"scikit-learn==1.5.0\",\r\n    sklearn-crfsuite\r\n    \r\n    h5py is  imported by keras (transitive) so can prob be left out"
        },
        {
          "user": "MoralCode",
          "body": "needs rebase"
        },
        {
          "user": "sgoggins",
          "body": "Rerunning failed end to end test."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3346,
      "author": "mohsinm-dev",
      "created_at": "2025-10-28T01:59:59Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "@mohsinm-dev Since this is fairly high priority for us, are you likely to have time to work on this PR, or would you be okay if one of the core maintainers takes it over and makes the fixes to make recollection intervals configurable?"
        },
        {
          "user": "MoralCode",
          "body": "@mohsinm-dev looks good! I added a couple small changes (one to rename the variables to include the word `days` so its clearer what the values should be, and another one to add a brief mention of these changes to the ReadTheDocs). I also rebased these changes on top of the current main branch.\r\n\r\n\r\n@sgoggins Can you set DCO to passing on this one?"
        },
        {
          "user": "MoralCode",
          "body": "This change (and several others in this diff are not related to the issue being fixed here - is there a reason you made this change?"
        },
        {
          "user": "MoralCode",
          "body": "I disagree with doing things this way - i would rather keep the parameter in each function (while fixing the `CollectionRequest` instantiation to actually use it) and then read in the config values at the time each of these functions is called."
        },
        {
          "user": "MoralCode",
          "body": "Doing it this way just means the function has more side-effects/prerequisites/things it expects that aren't clearly documented/visible in the function signature - it makes the functions less able to be refactored/reorganized as the codebase evolves without also moving around other things as well."
        },
        {
          "user": "MoralCode",
          "body": "Im a little mixed on whether we need a dict for this overall since its one additional place that needs modifying if we add another worker for some reason.\r\n\r\nAlso this function seems to be injecting its own default values independently of the config classes that already exist. IMO the defaults should be handled in one place"
        },
        {
          "user": "MoralCode",
          "body": "this is importing from a different place that is separate from `application/config.py` and shouldnt be used"
        },
        {
          "user": "MoralCode",
          "body": "the days_until_collect_again parameter is unused. I think it should use the parameter and the config value should be injected at the point where build_primary_repo_collect_request is called (same for all these other similar functions)"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : This seems like a good time to fix an antipattern if you see win. Should we ask @mohsinm-dev to make these changes? I see the PR passed and sort of presume that this is a non-issue for you wrt merging .. ?"
        },
        {
          "user": "sgoggins",
          "body": "same pattern @MoralCode noted above .. down a few more for each of the task sections."
        },
        {
          "user": "MoralCode",
          "body": "im not sure what you are referring to here?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3341,
      "author": "PredictiveManish",
      "created_at": "2025-10-26T04:40:18Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Don't see Podman failing and all the other CII jobs succeeding too often. We should have a GitHub / Augur badge for that! :D"
        },
        {
          "user": "MoralCode",
          "body": "Occasionally the jobs just need rerunning. Ive seen them error for random reasons, which is why I submitted that change to fix the free space on the docker builds"
        },
        {
          "user": "MoralCode",
          "body": "Do you think you could also addresss this line mentioning python3.6?\r\n\r\n```suggestion\r\nOur REST API & data collection workers query the GitHub & GitLab API to collect data about issues, pull requests, contributors, and other information about a repository. Values for GitLab and GitHub access tokens are **required** for data collection and must be provided (an invalid token can be provided if you don't plan to use one platform) .\r\n```"
        },
        {
          "user": "sgoggins",
          "body": "I have never seen the option to \"sign off and commit suggestion\" ... Also, since its not tagged as \"ready\", I'm checking."
        },
        {
          "user": "MoralCode",
          "body": "im not sure what you mean here"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3332,
      "author": "PredictiveManish",
      "created_at": "2025-10-23T04:14:12Z",
      "comments": [
        {
          "user": "PredictiveManish",
          "body": "> Might also be worth looping in the author of the prior PR that this update is for @JohnStrunk.\r\n> \r\n> Overall i dont really have much opinion on this other than these diffs seem reasonably small - will probably defer explicit approval to other maintainers who have more experience to better evaluate whether these changes are helpful\r\n\r\nYes, this issue is not that much big just a small warning! Main issue is the other part of unable to importing properly! it's just a solution for the warning!"
        },
        {
          "user": "MoralCode",
          "body": "this seems based on the name like it may be important - how do you know this isnt an issue with the linter incorrectly identifying an unused package that may actually be used?"
        },
        {
          "user": "JohnStrunk",
          "body": "This is the read-the-docs theme. It's [referenced below](https://github.com/chaoss/augur/pull/3332/files#diff-008dcb3426febd767787b1521f1fe33086313b927ea37eaab86df5fa88a51698L119), though not in a form that will be picked up by a linter.\nThe preview seems to build, but I wonder whether local builds build correctly and have the proper theme applied."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3337,
      "author": "MoralCode",
      "created_at": "2025-10-23T20:25:42Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "given that this had to be updated in two places, I'm also curious if one of the functions can be entirely removed.\r\n\r\n\r\nAlso this probably still needs updating to adjust the place in the code where the tasks are actually added to the queues"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : ah .. looks like this one is breaking docker builds."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : What are thinking re: docker build failure? Wait to merge until it passes, or solve it on another PR?"
        },
        {
          "user": "MoralCode",
          "body": "Works on my machine (and also with augur.json - although with some fiddling because podman permissions)."
        },
        {
          "user": "sgoggins",
          "body": "Docker image build still failing, @MoralCode"
        },
        {
          "user": "MoralCode",
          "body": "Rerunning. cant see an obvious error besides failing to clone chaoss/whitepaper....."
        },
        {
          "user": "MoralCode",
          "body": "> I think we have worked this one pretty close to the nub ... @MoralCode : Any reservations about merging?\r\n\r\nnope, good to merge!"
        },
        {
          "user": "sgoggins",
          "body": "Do we need to add values to the database?"
        },
        {
          "user": "MoralCode",
          "body": "yes, but thats why i filed #3356 - the values and sensible defaults already exist in the config.py file, and I think we should have the application insert them if something tries to access them and it cannot find the value.  Then users dont need to run some manual command and we can keep the DB migrations limited to only structural fixes"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3330,
      "author": "PredictiveManish",
      "created_at": "2025-10-22T16:17:20Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "not a fan of the extra/unrelated changes, but i can see how in some cases it marginally improves things (yet in others some detail is lost).\r\n\r\nI'll see what everyone else says, but Im inclined to let this stay"
        },
        {
          "user": "MoralCode",
          "body": "Was a little worried at the size of this diff at first, but i see you unwrapped the code from within an if and turned it into more of an early-fail/gate type pattern. Looks good!"
        },
        {
          "user": "MoralCode",
          "body": "i think in the original issue I was intending to propose *either* blanking out the middle or hashing. I think blanking out the middle is better overall since current users are probably more used to seeing their keys in this form (ie.. when they input them or use the CLI to check key expiry). I'll wait to see what the other maintainers think, but I suspect the value of the hashing isnt yet worth the additional dependency"
        },
        {
          "user": "MoralCode",
          "body": "I suspect this function will be helpful in other parts of the codebase too.\r\n\r\nMaintainers: where would be the best place to move this such that it could be used by the augur CLI too? im thinking the `augur.util` package maybe?"
        },
        {
          "user": "PredictiveManish",
          "body": "Thanks for your review and time, waiting for other reviews then will proceed further."
        },
        {
          "user": "PredictiveManish",
          "body": "Thanks."
        },
        {
          "user": "PredictiveManish",
          "body": "Yes I also think that it can be moved to somewhere else for making it helpful for all required place, just let me know where to move I will do it and import in this file!"
        },
        {
          "user": "PredictiveManish",
          "body": "That‚Äôs a fair point. I thought that having a short hash helps correlate which key was used without exposing any part of it (useful in environments where masking might still reveal too much).\r\nBut I agree the masking approach is simpler and more familiar.\r\nHappy to revert to that if maintainers prefer consistency with existing CLI behavior."
        },
        {
          "user": "sgoggins",
          "body": "does hashlib require a change to pyproject.toml? I think it likely does because I do not recall (its been 9 years so that recall isn't perfect) using hashlib previously on Augur."
        },
        {
          "user": "sgoggins",
          "body": "I think all the key LOGGING occurs through this file; We have caused ourself confusion in the past by creating general function libraries where localized ones were adequate. I'm in favor of generalizability. I just cannot think of a specific case where we would need it ... CLI is a good point @MoralCode ... `augur.util` is a nice centralized place and one of the first we look at if the function isn't local. ... On @MoralCode 's recommendation/suggestion, that might make sense. Then we just import `augur.util` (look through the codebase for how we do that) into this file. That seems smart!"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode makes a really good point here. I like hashing from a security perspective ... if we leave the first 4 and last 4 in place, and hash the middle part it is WAY more secure when logging, and also allows us to debug key issues as they related to particular keys. \r\n\r\nSpecifically, keys go bad for one reason or another. If we preserve no part of the key it is more secure, but then quite difficult to identify the bad keys. \r\n\r\nOne possible compromise (and replacing the middle seems like a good one already) would be to include the `id` of the key from the `augur_operations.worker_oauth` table. Such as: \r\n\r\n```bash\r\noauth_id\tname\tconsumer_key\tconsumer_secret\taccess_token\taccess_token_secret\trepo_directory\tplatform\r\n20004\tx@x.com\t0\t0\tghp_NOTREAL\t0\t\tgithub\r\n21000\tdoge@x.com\t0\t0\tghp_NOTREAL\t0\t\tgithub\r\n20005\tlessla@x.com\t0\t0\tghp_NOTREAL 0\t\tgithub\r\n```\r\n\r\nso ... 20004, 21000, and 20005 would be included in the log ... \r\n\r\nBut that \"feels\" like more work than removing the middle. I'm ok w"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I tend to agree that this change isn't necessary, and every change carries some small degree of risk."
        },
        {
          "user": "sgoggins",
          "body": "LGTM"
        },
        {
          "user": "MoralCode",
          "body": "https://docs.python.org/3/library/hashlib.html\n\nI think its part of the python standard library"
        },
        {
          "user": "PredictiveManish",
          "body": "Reverted changes!"
        },
        {
          "user": "PredictiveManish",
          "body": "Done as you suggested sir!"
        },
        {
          "user": "PredictiveManish",
          "body": "removed `key_fingerprint()` as of now, if it requires will add it later as per advancement of repo!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3326,
      "author": "PredictiveManish",
      "created_at": "2025-10-22T14:10:23Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Links to the \"issue resolved\" go to a PR."
        },
        {
          "user": "PredictiveManish",
          "body": "> Links to the \"issue resolved\" go to a PR.\r\n\r\nYes sir, but the code changes have some reviews approved by you.  \r\n[Link](https://github.com/chaoss/augur/actions/runs/15594480989/job/43921470699?pr=3183)"
        },
        {
          "user": "PredictiveManish",
          "body": "Due to very unprofessional way of resolving issue, A very very sorry from my side I am closing this for now and will come with better way of solving issues and in more professional manner, \r\nAgain sorry sir for wasting your precious time!"
        },
        {
          "user": "sgoggins",
          "body": "Not sure I follow the logic of this line replacement. Might be easier to see if I knew what issue was resolved."
        },
        {
          "user": "PredictiveManish",
          "body": "[https://](https://github.com/chaoss/augur/pull/3183/files#annotation_35600481087)\r\nThis warning initiated for removing sphinx_rtd_theme import and the metadata import is due to these variables are unable to take reference from metedata.py file."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3315,
      "author": "MoralCode",
      "created_at": "2025-10-15T21:26:32Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "@skools-here what do you think of this? I made this branch mostly just to see what would happen if I ran mypy on augur out of the box (answer: a ton of type errors i didnt want to deal with)\r\n\r\nso I ended up narrowing it to the db files and only had like 6 things to fix. It turns out mypy generally won't complain if things are untyped, which seems helpful for migrating.\r\n\r\nThe only thing left IMO is to figure out how to get the CI (i feel like one of the existing CI jobs should be able to handle it?) to run the equivalent of `uv run mypy` to ensure that things in this set of files dont regress."
        },
        {
          "user": "skools-here",
          "body": "@MoralCode  This looks great narrowing Mypy‚Äôs scope to the database files is a very practical approach.\r\n\r\nUsing uv run mypy fits nicely into our existing workflow. The main thing now is ensuring this check runs automatically in CI to prevent type regressions in future changes.\r\n\r\nI think all that‚Äôs needed is to add a step in .github/workflows/checks.yml to run Mypy. Once in place, this will work seamlessly, and we can gradually expand the set of type-checked files over time."
        },
        {
          "user": "MoralCode",
          "body": "> I think all that‚Äôs needed is to add a step in .github/workflows/checks.yml to run Mypy. Once in place, this will work seamlessly, and we can gradually expand the set of type-checked files over time.\r\n\r\nIs this something you want to do/think you would be able to do?"
        },
        {
          "user": "skools-here",
          "body": "> Is this something you want to do/think you would be able to do?\n\nI think I can try to work on this workflow addition. Would love to get your help in between though."
        },
        {
          "user": "MoralCode",
          "body": "Sounds good!\nDo you want to try and build on this PR? Or should @sgoggins merge it and we can add the CI jobs in a new PR?"
        },
        {
          "user": "skools-here",
          "body": "I‚Äôm happy to build on this PR so everything lands together. \n\nBut if you‚Äôd prefer to merge this first and handle the CI setup separately, that works for me too ‚Äî totally your call!"
        },
        {
          "user": "sgoggins",
          "body": "> **Description** This sets up mypy in a slightly different way to #3280.\r\n> \r\n> to run the type checker, run `uv run mypy`\r\n> \r\n> This PR sets up for an eventual fix to #3274\r\n> \r\n> **Notes for Reviewers** mostly just making this for reference and to see if it causes the CI jobs to freak out\r\n> \r\n> if this ends up being used, i should probably go back and squash some of the fixup commits i made\r\n> \r\n> **Signed commits**\r\n> \r\n>     * [x]  Yes, I signed my commits.\r\n\r\nYou only made 5 commits. I don't think we need to squash those ... but I am kind of a pack rat."
        },
        {
          "user": "MoralCode",
          "body": "I can do a quick check tomorrow to make sure augur still boots up and appears to work. All the changes here should be logically identical to how the code was beforehand. This is just setting up to have a type checker be able to validate that the declared types match with how the python objects/data are actually being used"
        },
        {
          "user": "sgoggins",
          "body": "Did you run Augur with these changes? On the face of it I am mildly curious if changing from `List[dict]` to a `dict` will alter expected return values for other parts of Augur."
        },
        {
          "user": "MoralCode",
          "body": "Python typings are just hints, they aren't actually going to change the properties of the data thats returned or cause errors by themselves (unless you like make a syntax error or try and use a type thats not present or something)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3309,
      "author": "MoralCode",
      "created_at": "2025-10-14T19:47:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "The message level is usually set in all caps like , `DEBUG` or `ERROR` .. does this logging checker do anything to account for differences in case? I think it needs to ..."
        },
        {
          "user": "MoralCode",
          "body": "that is added/managed by the `logging` package (i.e. when `self.logger.<whatevr>()` is called)\r\n\r\nAll we need to worry about here is the `level` parameter being passed to this function. All the existing calls to this logging helper that I see use Camel case and the existing check for whether Debug mode is requested does not account for casing, so i think its fine.\r\n\r\nI will also be likely entirely rewriting all this logic if/when i fix #3308"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3305,
      "author": "skools-here",
      "created_at": "2025-10-11T12:30:50Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "@skools-here can you rebase/squash commits and make sure all commits are signed-off?"
        },
        {
          "user": "MoralCode",
          "body": "@skools-here it seems like your rebase accidentally pulled in an extra commit from main thats unrelated"
        },
        {
          "user": "skools-here",
          "body": "yes I have fixed it now I don't how that happened though."
        },
        {
          "user": "MoralCode",
          "body": "> yes I have fixed it now I don't how that happened though.\r\n\r\nit looks like you just created a new commit that un-does the changes, which is going to cause git to effectively roll those changes back when this merges.\r\n\r\nI wish there was a better tool than git that didn't make it so easy to do this kind of thing.\r\n\r\nCould you rebase your PR on top of main (again) but only include the three commits you intend to keep? If it helps, I tend to think of operations like this more like a \"hard reset your branch to main and then cherry pick the commits you want\". Also happy to talk on the CHAOSS slack if you want more specific/detailed guidance!"
        },
        {
          "user": "skools-here",
          "body": "@MoralCode Ah, got it ‚Äî I see what happened now üòÖ I‚Äôll rebase my branch onto main and cherry-pick only the three commits related to centralized version management. Thanks for catching that!\r\nI‚Äôll clean it up and push again soon .If I run into any hiccups, I‚Äôll reach out to you on CHAOSS Slack for a help. I also think that there can be better tools than git."
        },
        {
          "user": "MoralCode",
          "body": "almost there! To avoid the need for that final merge commit from main into this branch, you'll likely need to update your fork's `main` branch so it matches this repo (if you visit your fork in the github UI it should give you a \"sync fork\" button). Then if you rebase it should set this branch up to be based on the latest version of main, not just the latest at the time you made your fork"
        },
        {
          "user": "skools-here",
          "body": "@MoralCode Thanks a lot for helping me out I was really wondering how to resolve this problem !"
        },
        {
          "user": "skools-here",
          "body": "@sgoggins ngl even I don't know what's that formatting problem :(( . ig it's my editor problem. But hopefully this pr fixed that version management issue !"
        },
        {
          "user": "MoralCode",
          "body": "Why do you import `re` (which AFAIK is for regex) and then not use it?"
        },
        {
          "user": "MoralCode",
          "body": "What is the purpose of this line?"
        },
        {
          "user": "MoralCode",
          "body": "is this file used anywhere?"
        },
        {
          "user": "MoralCode",
          "body": "This file contains a lot of formatting changes that arent directly related to the purpose of this PR.\r\n\r\nCould you be using any particular tools that are attempting to reformat things?"
        },
        {
          "user": "skools-here",
          "body": "as get_version.py is not in root directory so it sets the system path two files up so that metadata.py is interpreted."
        },
        {
          "user": "sgoggins",
          "body": "I think that is answered in the previous comment, which also explains the purpose of that line."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode ; Dot these answers collectively make things more clear?"
        },
        {
          "user": "sgoggins",
          "body": "Looking at the doc file, it does appear there is probably some IDE doing automatic reformatting."
        },
        {
          "user": "MoralCode",
          "body": "sort of. Im still struggling to see where `get_version.py` actually gets executed though. What happens if you delete it and then re-test this PR?"
        },
        {
          "user": "skools-here",
          "body": "yes i checked that get_version.py is not used docker build is getting version from metadata.py itself so i guess it can be removed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3311,
      "author": "AumOzaa",
      "created_at": "2025-10-15T06:33:00Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "@AumOzaa it looks like you just included/rebased a LOT of changes from main into this PR.\r\n\r\nCan you update your fork to match the latest version of the `main` branch and base your commits on that?\r\nHappy to help guide you through this process if you would like"
        },
        {
          "user": "AumOzaa",
          "body": "I fetched the latest upstream changes and rebased my branch (add-augur-reset-logs-docs) on top of the updated main branch.\r\n\r\nThe rebase went through successfully and I pushed the changes, but now some error from the run-linting-checks workflow, specifically the check docs step is coming up.\r\n\r\nI haven‚Äôt modified anything outside the documentation file, so I‚Äôm not sure why that‚Äôs happening. Could you please guide me on what might be causing it?"
        },
        {
          "user": "MoralCode",
          "body": "> I fetched the latest upstream changes and rebased my branch (add-augur-reset-logs-docs) on top of the updated main branch.\r\n\r\nlooks like your rebase includes an extra commit not related to this PR: a4d9efcc713faf647d41053ee7c944f7d1899136"
        },
        {
          "user": "AumOzaa",
          "body": "I‚Äôve removed the unrelated commit [a4d9efc](https://github.com/chaoss/augur/commit/a4d9efcc713faf647d41053ee7c944f7d1899136) from the branch and also updated the toc.rst file to include the new documentation. I verified the changes locally by running make clean && make html, and the build completed successfully.\r\n\r\nLooking forward to any feedback or further updates if needed."
        },
        {
          "user": "MoralCode",
          "body": "looks good! Seems like the DCO check is still detecting that a couple of the commits are not signed off.\r\n\r\nyou should be able to resolve this with another quick rebase `git rebase HEAD~5 --signoff`"
        },
        {
          "user": "AumOzaa",
          "body": "I‚Äôve done the rebase with --signoff as suggested, all recent commits should now be properly signed off.\r\nPlease let me know if there‚Äôs anything else I should adjust."
        },
        {
          "user": "MoralCode",
          "body": "I think this is ready - holding off on marking as such until the current release has been made"
        },
        {
          "user": "AumOzaa",
          "body": "Thanks a lot for your help throughout the PR process. Learned quite a bit about managing rebases and keeping PRs clean. Really appreciate your guidance and patience"
        },
        {
          "user": "AumOzaa",
          "body": "Sure,\r\nI‚Äôll check the older PR and integrate it into my doc so it‚Äôs more general."
        },
        {
          "user": "AumOzaa",
          "body": "I noticed the Podman e2e test failed, it‚Äôs possible I accidentally fetched some unrelated commits again? Could you please advise if that might be the cause, and if there‚Äôs anything I should do to fix it?\r\nAlso, I‚Äôve combined the content with the previous PR as suggested, does the documentation now look general enough, or are there any further changes needed?"
        },
        {
          "user": "MoralCode",
          "body": "> I noticed the Podman e2e test failed, it‚Äôs possible I accidentally fetched some unrelated commits again? Could you please advise if that might be the cause, and if there‚Äôs anything I should do to fix it? Also, I‚Äôve combined the content with the previous PR as suggested, does the documentation now look general enough, or are there any further changes needed?\r\n\r\nDont worry about that test, its been acting up a little lately. you only made changes to the docs so as long as the docs build works you are fine"
        },
        {
          "user": "MoralCode",
          "body": "If you can, you should also go back and signoff your commits too!"
        },
        {
          "user": "sgoggins",
          "body": "@AumOzaa / @MoralCode : I am rerunning hte end to end tests that failed to see if they just timed out or if there is a problem."
        },
        {
          "user": "giordano",
          "body": "````suggestion\n  export AUGUR_RESET_LOGS=False\n  ```\n````"
        },
        {
          "user": "MoralCode",
          "body": "is there a reason this is as a markdown file, rather than as part of the ReadtheDocs source that generates the Augur docs website at https://oss-augur.readthedocs.io/en/main/?\r\n\r\n@sgoggins do you have a preference as to where this documentation goes?"
        },
        {
          "user": "MoralCode",
          "body": "\"the sysadmin is responsible for managing log growth\"\r\n\r\nAs someone who has talked to an augur sysadmin who has dealt with this, it is quite painful to properly configure logrotate for augur. \r\n\r\nThis isnt a piece of feedback, just a note from me to link this to #3308"
        },
        {
          "user": "AumOzaa",
          "body": "This is my first open source contribution. Could you please advise if I should move this documentation into the ReadTheDocs folder or section?\r\nAlso, is there a need to convert it into .rst format and place it in the same docs/ folder?"
        },
        {
          "user": "MoralCode",
          "body": "I think that would be the  most ideal way to go yes - i think more augur users are going to look at the user-friendly docs site compared to the folder buried in the repo\r\n\r\nSorry for the delayed response!"
        },
        {
          "user": "sgoggins",
          "body": "@AumOzaa : I agree with @MoralCode 's suggestion here."
        },
        {
          "user": "MoralCode",
          "body": "Specifically the suggestion is that this should be moved to ReadTheDocs/rst format and be included in the generated docs site, rather than just as a markdown file in the repo"
        },
        {
          "user": "AumOzaa",
          "body": "Sure, I‚Äôll move it into the ReadTheDocs structure under the docs/source section and convert it into .rst format."
        },
        {
          "user": "MoralCode",
          "body": "This file should be removed since it has been moved to an `rst` file"
        },
        {
          "user": "MoralCode",
          "body": "> The rebase went through successfully and I pushed the changes, but now some error from the run-linting-checks workflow, specifically the check docs step is coming up.\n> \n> I haven‚Äôt modified anything outside the documentation file, so I‚Äôm not sure why that‚Äôs happening. Could you please guide me on what might be causing it?\n\nLooking at the logs for that failed workflow run (i had to scroll up most of the way), it says ` /home/runner/work/augur/augur/docs/source/how_to_run_augur_in_production.rst: WARNING: document isn't included in any toctree`\n\nThis essentially means that, while you added a new file for running augur in production, this file is not referenced in the table of contents (i.e. the sidebar) for the docs, and therefore people wont easily be able to find the page in the UI.\n\nTo fix this, navigate to the [docs website](https://oss-augur.readthedocs.io/) for augur and find an appropriate section to link it under (you may also have already done this when you chose the director"
        },
        {
          "user": "MoralCode",
          "body": "i feel like id want to present this as more of  collection of tips and tricks rather than a complete howto. every production setup is different"
        },
        {
          "user": "MoralCode",
          "body": "this mixes the two different methods of installing augur. suggest removing this section"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\n```\n\nThis doesnt exist"
        },
        {
          "user": "MoralCode",
          "body": "This section is entirely about one variable. I think it would be best to make a list where each variable can have a small paragraph about it, sorta like how ansible does it on this page: https://docs.ansible.com/projects/ansible/latest/reference_appendices/config.html#default-roles-path"
        },
        {
          "user": "MoralCode",
          "body": "I dont want to duplicate step-by-step setup. Either remove this section or link to the existing docker and non-docker setup pages in the docs"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3300,
      "author": "giordano",
      "created_at": "2025-10-06T21:02:51Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "the extra layer of backticks shouldnt be needed AFAIK"
        },
        {
          "user": "MoralCode",
          "body": "Would it be possible to explain why the placeholders should be kept? (i.e. it will cause things not to start up if one is left unspecified?)"
        },
        {
          "user": "giordano",
          "body": "It is: `` `.env` `` is rendered as italic, ``` ``.env`` ``` is rendered as monospace.  See the RST docs: https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html#inline-markup"
        },
        {
          "user": "MoralCode",
          "body": "oh right, i forgot this was RST and not markdown"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3287,
      "author": "MoralCode",
      "created_at": "2025-09-23T17:15:01Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Merging all of the changes under review into a second load test branch. This branch includes what is in load-test plus the reversion of the facade_tasks.py changes from last week, and bumping the celery version."
        },
        {
          "user": "MoralCode",
          "body": "> Merging all of the changes under review into a second load test branch. This branch includes what is in load-test plus the reversion of the facade_tasks.py changes from last week, and bumping the celery version.\r\n\r\ndoing this just closed this PR, which probably wasnt intentional but I think its worth revisiting our strategies for making changes"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3273,
      "author": "MoralCode",
      "created_at": "2025-09-15T21:28:07Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "oh fun, i guess one of my rebases or amends must have stripped out the DCO..."
        },
        {
          "user": "Ulincsys",
          "body": "Is there a particular reason to keep the list if we are just going to peek the first item from it on return?"
        },
        {
          "user": "MoralCode",
          "body": "i only did this to preserve the log statement. i guess if the print statement can handle the list of objects just fine, it should be fine to just throw the object at it."
        },
        {
          "user": "MoralCode",
          "body": "thanks for calling me out on my addition of tech debt lol - this probably isnt necessary, i think i was just like \"eh whatever it works\" when i wrote it and forgot to revisit"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3280,
      "author": "skools-here",
      "created_at": "2025-09-20T13:42:23Z",
      "comments": [
        {
          "user": "skools-here",
          "body": "Yes thanks for the review will be changing all the logic changes which may cause problem and will also try to reduce the use of any ."
        },
        {
          "user": "MoralCode",
          "body": "we should also probably add a CI job to check the types so its clear if something breaks on a pull request"
        },
        {
          "user": "MoralCode",
          "body": "@skools-here do you have any updates on this?\r\n\r\nno worries if not - just wanted to check if you were still interested in merging this. If not, I can potentially find another maintainer can take over and make the necessary adjustments to get this merged\r\n\r\nPart of me also wonders what would happen if mypy is run on this repo without any explicit typing added? :thinking:"
        },
        {
          "user": "skools-here",
          "body": "@MoralCode After revisiting the , I realized this might be a bit more complex than I initially expected, especially around how mypy interacts with the existing code. I don‚Äôt think I‚Äôll be able to give it the attention it needs right now, so feel free to reassign it or have someone else take it over."
        },
        {
          "user": "MoralCode",
          "body": "Superseeded by #3315"
        },
        {
          "user": "MoralCode",
          "body": "this seems like a non-typing change that removed a helpful comment - was this removed on purpose?"
        },
        {
          "user": "MoralCode",
          "body": "it might be nice to not use `Any` as the type here - does the ORM have a base/parent class that all the ORM classes inherit from? maybe thats a better thing to use?"
        },
        {
          "user": "MoralCode",
          "body": "does config_dict come from somewhere? could its type be specified more precisely than `Any`? same with  the logger"
        },
        {
          "user": "MoralCode",
          "body": "why was the order of these changed? this could cause a crash if the data type is none because it is relying on the short curcuiting behavior of `or`"
        },
        {
          "user": "MoralCode",
          "body": "if value is exactly `false` (string), this will evaluate to true."
        },
        {
          "user": "skools-here",
          "body": "I‚Äôll update convert_orm_list_to_dict_list to use the ORM base class, and refine config_dict + logger to use more specific types (Optional[logging.Logger], etc.) ."
        },
        {
          "user": "skools-here",
          "body": "Yes i will fix this this ."
        },
        {
          "user": "MoralCode",
          "body": "wait did i get this wrong?"
        },
        {
          "user": "skools-here",
          "body": "the earlier function (Not type safe one) already had that anything not false is True behavior. So according to me this must work i am not sure though ."
        },
        {
          "user": "MoralCode",
          "body": "if you change this file, you also need to run `uv sync` and commit the changes to the `uv.lock` file. this will likely help some of the CI jobs pass"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3268,
      "author": "MoralCode",
      "created_at": "2025-09-11T19:47:17Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Reviewers: if you want i can comment out the new config in the dockerfile to match the convention we use for flower"
        },
        {
          "user": "MoralCode",
          "body": "current status (as a draft): postgres monitoring seems to work (just do `docker compose up` in the `monitoring` directory once augur is running (it assumes you use the compose file in the root of the repo).\r\n\r\nFlower also (apparrently) ships with a /metrics endpoint that prometheus can ingest so im working on getting that hooked up.\r\n\r\nfeel free to play with this if anyone is interested!"
        },
        {
          "user": "MoralCode",
          "body": "Seems to be working under both podman and docker environments"
        },
        {
          "user": "MoralCode",
          "body": "This also includes both postgres and celery monitoring dashboards.\r\n\r\nTo use this you need to add a .env file in the monitoring folder containing augur db credentials (`AUGUR_DATABASE`, `AUGUR_HOST`, `AUGUR_DB_USER`, `AUGUR_DB_PASSWORD`), then you can just do a regular `<tool> compose up -d` in the monitoring dir and it will start the monitoring stack. \r\n\r\nthis is intended to run independently of augur so you can take augur down and back up and the monitoring should keep going and simply reflect a gap in the data"
        },
        {
          "user": "MoralCode",
          "body": "@sgoggins i think my force pushing dismissed your review"
        },
        {
          "user": "MoralCode",
          "body": "Given this is entirely independent, im going to maintain this separately to avoid cluttering the augur repo with extra utilities.\r\n\r\nCode will be maintained at https://github.com/oss-aspen/augur-monitoring"
        },
        {
          "user": "MoralCode",
          "body": "This line is breaking CI."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3269,
      "author": "Kushagra651",
      "created_at": "2025-09-12T10:17:56Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "ok ... i see the lint checker for broken links is working ... and that's the issue ..."
        },
        {
          "user": "MoralCode",
          "body": "why were the names removed from these jobs?"
        },
        {
          "user": "MoralCode",
          "body": "this project likely uses the CHAOSS code of conduct. https://chaoss.community/code-of-conduct/"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : This is a hidden piece of GitHub foo ... The code of conduct in the Augur repository actually points to the code of conduct at the CHAOSS org. That said, I agree that directing folks specifically to the CHAOSS code of conduct makes sense. \n\nNote that Augur is part of the SOftware part of the Governing board. \n\n<img width=\"1920\" height=\"1080\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e8e995a8-c532-47e4-9de7-fcec96113aa9\" />\n\nhttps://github.com/chaoss/community/blob/main/governance/governance.md\n\nThis direct link to the code of conduct in the community repo is probably the most stable link: \n\nhttps://github.com/chaoss/community/blob/main/governance/code-of-conduct.md ... then there's another link in that MD .. I'm not sure why that's necessary, but here we are."
        },
        {
          "user": "MoralCode",
          "body": "oh i see the tabs over the README with the code of conduct. Thats a clever github feature but also seems to be harder to link to than if it was a static file."
        },
        {
          "user": "sgoggins",
          "body": "@Kushagra651 : Can we keep the job names?"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I am presently inclined to include the CoC as a file on Augur itself for these and other reasons"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3260,
      "author": "raisuraj2004",
      "created_at": "2025-09-05T11:20:09Z",
      "comments": [
        {
          "user": "raisuraj2004",
          "body": "The documentation build (readthedocs) passed successfully, which was the main focus of this PR.\r\nThe failing Docker/Podman checks appear to be unrelated to the documentation changes made here.\r\n\r\nThis PR addresses issue #3249 by:\r\n\r\nCorrecting the running-in-production.md filename and linking it properly in the toctree.\r\nEnsuring the Sphinx docs build without warnings."
        },
        {
          "user": "sgoggins",
          "body": "@raisuraj2004 : There seems to be an error with readthedocs.io: \r\n\r\nhttps://app.readthedocs.org/projects/oss-augur/builds/29503183/"
        },
        {
          "user": "raisuraj2004",
          "body": "I‚Äôve updated the commits and pushed the latest changes.\r\n@sgoggins  Let me know if anything else is needed."
        },
        {
          "user": "MoralCode",
          "body": "why was this closed and deleted?"
        },
        {
          "user": "raisuraj2004",
          "body": "sorry for the irregularity, last 1 month i was soo much occupied  with my collage exams and some hackathon project that is why i was not getting enough time to  work on this.\r\nif you want i can restore the branch and start working on it again"
        },
        {
          "user": "sgoggins",
          "body": "I suspect it is the additional imports that are not being supported by readthedocs.io."
        },
        {
          "user": "sgoggins",
          "body": "This may be the root cause of the readthedocs.io build failing. \r\n\r\nIt looks like the library is installed as `myst-parser` based on these docs from readthedocs.io: \r\n\r\nhttps://docs.readthedocs.com/platform/stable/intro/sphinx.html#using-markdown-with-sphinx"
        },
        {
          "user": "MoralCode",
          "body": "since we are already using uv for dependency management, having a requirements.txt seems redundant.\r\n\r\nWas it difficult for you to use uv to install what you needed? do the docs need improving in that regard?"
        },
        {
          "user": "MoralCode",
          "body": "uv is installed in the prior command, using that would probably be better - happy to help get this working if you get stuck!"
        },
        {
          "user": "MoralCode",
          "body": "This is not an environment variable that exists in augur"
        },
        {
          "user": "MoralCode",
          "body": "was Generative AI used as part of the creation of this commit?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3253,
      "author": "IsaacMilarky",
      "created_at": "2025-08-27T15:30:44Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "The test would be: \r\n1. New Augur instance\r\n2. Identify 3-5 very large repositories\r\n3. Do collection for them (note that for Facade collection it typically requires an Augur restart)\r\n4. Truncate the augur_operations.collection_status table\r\n5. Restart collection after commits were collected the first time and see if it goes insanely fast, which it should if this branch does what we claim it does."
        },
        {
          "user": "MoralCode",
          "body": "in poking through the code, im actually not sure this even affects analyze_commits_in_parallel beyond removing some date related things"
        },
        {
          "user": "IsaacMilarky",
          "body": "> in poking through the code, im actually not sure this even affects analyze_commits_in_parallel beyond removing some date related things\r\n\r\nThe partial commit collection was already supported previously in the body of the `analyze_commits_in_parallel` method:\r\n\r\n```python\r\n\r\n    repo = get_repo_by_repo_id(repo_id)\r\n\r\n    #Get the huge list of commits to process.\r\n    absolute_path = get_absolute_repo_path(facade_helper.repo_base_directory, repo.repo_id, repo.repo_path, repo.repo_name)\r\n    repo_loc = (f\"{absolute_path}/.git\")\r\n    # Grab the parents of HEAD\r\n\r\n    parent_commits = get_parent_commits_set(repo_loc)\r\n\r\n    # Grab the existing commits from the database\r\n    existing_commits = get_existing_commits_set(repo_id)\r\n\r\n    # Find missing commits and add them\r\n    missing_commits = parent_commits - existing_commits\r\n\r\n    facade_helper.log_activity('Debug',f\"Commits missing from repo {repo_id}: {len(missing_commits)}\")\r\n```\r\n\r\nThese changes just effect the contributor resolution "
        },
        {
          "user": "MoralCode",
          "body": "What would the behavior of this PR be in the case of a repo deciding to rewrite the history of their git repo? Is that something we can detect and maybe just fall back to the full recollection?"
        },
        {
          "user": "IsaacMilarky",
          "body": "> What would the behavior of this PR be in the case of a repo deciding to rewrite the history of their git repo? Is that something we can detect and maybe just fall back to the full recollection?\r\n\r\nThe logic is based on git commit hashes for the main analysis logic and for the contributor resolution logic it's based on the date that the commit record was inserted. \r\n\r\nSo, if a repository is rewriting their history the hashes would presumably be different and would be collected by the main logic into the commits table. Then that new commit would be collected later and therefore not be filtered by the new logic. The date that it is filtering by is the date that the commit record was collected not the date the commit record was committed."
        },
        {
          "user": "sgoggins",
          "body": "I suggest this logic include a pull back of at least 1 day from the most recent commit in the table, as that will ensure we don't miss mid-day commits. I am not sure that this is the right location for that logic. \r\n\r\nWe could use the timestamp, but I trust timestamps less than I trust just moving the window back one day. \r\n\r\nFinally: There are a small number of repos where some dufus created a commit or two into the future. Like way into the future. So, that should be checked I think. Perhaps the most reliable failsafe would be to triangulate the last commit date with the `facade_data_last_collected` stamp in `augur_operations.collection_status` to ensure that something is not wildly out of whack. On inactive repos, the most recent commit timestamp could be years ago; but we could just use whichever date is farthest backward from today to ensure that committer misbehavior does not undermine data quality. \r\n\r\nThank you @IsaacMilarky !! This is FANTASTIC!!"
        },
        {
          "user": "sgoggins",
          "body": "This relies on the since_data not be garbaged up by dufus committers putting random dates in, similar to my other comment but possibly even more insane to troubleshoot in the future. I think it works if we undertake some of the bulletproofing I mentioned previously."
        },
        {
          "user": "sgoggins",
          "body": "Making sure `last_collected_date` is in fact the date we calculate for the most recent commit in our record."
        },
        {
          "user": "sgoggins",
          "body": "Making sure `last_collected_date` is in fact the date we calculate for the most recent commit in our record."
        },
        {
          "user": "sgoggins",
          "body": "Making sure `last_collected_date` is in fact the date we calculate for the most recent commit in our record."
        },
        {
          "user": "Ulincsys",
          "body": "This change was not referenced in your PR message. What purpose does it serve?"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode ; This looks wrong."
        },
        {
          "user": "MoralCode",
          "body": "id say maybe just revert this piece then? Seems like the makefile isn't really in use anyway"
        },
        {
          "user": "IsaacMilarky",
          "body": "Reverting this"
        },
        {
          "user": "MoralCode",
          "body": "A migration is not needed if you are simply adding a value to the database - its really only needed for changing the structure of the DB tables/columns themselves. I suspect you could add this to augur/application/config.py:~71 or so and it would get included in the database for anyone who has augur set to insert that config on startup"
        },
        {
          "user": "IsaacMilarky",
          "body": "I gotcha, I just wasn't sure where we create the config in the code. Have changed to reflect."
        },
        {
          "user": "sgoggins",
          "body": "Added at @ABrain7710 's request. The goal is to have a specific option to ensure that previously uncollected contributors are gathered. Probably the default here should be 0 ..."
        },
        {
          "user": "sgoggins",
          "body": "Per @MoralCode 's prior comment; The analyze commits in parallel method would go from the last time facade ran, but this doesn't really get used. RIght now it gets the parent commits first, and gets the existing commits in the database already, and only goes through the commit hashes for commits that are \"missing commits\" =`parent commits - existing commits`"
        },
        {
          "user": "sgoggins",
          "body": "This is not intended to affect the main contributor analysis process. It is less about 'commits' per se."
        },
        {
          "user": "sgoggins",
          "body": "Also note that the `start_date` is never used in the function called with it, which is another reason to simplify/remove it ..."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3261,
      "author": "skools-here",
      "created_at": "2025-09-09T14:40:48Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "> would make log reading less oblique for non-sys-admins.\r\n\r\nIdeally this wouldnt affect the logs, just the table printed by the CLI when checking whether the auth tokens are expired"
        },
        {
          "user": "skools-here",
          "body": "Kindly review this PR ."
        },
        {
          "user": "skools-here",
          "body": "Hey , can someone review this and tell me what fixes do I need to make ."
        },
        {
          "user": "skools-here",
          "body": "> There are still several lines of extra space that could be cleaned up, but the code looks good to me\r\n\r\nHey I fixed those extra lines kindly review it"
        },
        {
          "user": "MoralCode",
          "body": "also don't forget to signoff on your commits so the DCO check passes (`git rebase HEAD~N --signoff` where N is the number of commits in this pull request)"
        },
        {
          "user": "MoralCode",
          "body": "not sure why we dont have a linter for this but this seems like a lot of space between this function and the prior one (super minor nitpick though)"
        },
        {
          "user": "skools-here",
          "body": "ohh lol will fix this :)"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\r\n    formatted_time = local_time.strftime('%I:%M %p %Z (UTC%z)')\r\n```\r\n\r\nSince the keys usually reset in an hour or so, including the day here may not be as useful (it also makes the alignment of the table these days are printed in get a bit wonky)\r\n\r\n<img width=\"1248\" height=\"49\" alt=\"Screenshot_20250911_161546\" src=\"https://github.com/user-attachments/assets/eb9cda1b-9e65-449b-883d-8d6be3a514c7\" />\r\n<img width=\"816\" height=\"453\" alt=\"Screenshot_20250911_161534\" src=\"https://github.com/user-attachments/assets/89855028-1995-478b-8c03-f26279ba96b2\" />"
        },
        {
          "user": "skools-here",
          "body": "Yes I fixed this now!"
        },
        {
          "user": "MoralCode",
          "body": "```suggestion\r\n    formatted_time = local_time.strftime('%I:%M %p %Z (UTC%z)').center(24)\r\n```\r\n\r\nThis, in addition to changing the header line to: `print(f\"{'Key'.center(40)}   {core_request_header}   {core_reset_header.center(24)}   {graphql_request_header}   {graphql_reset_header.center(24)}\")` will make sure that the table headers remain aligned with the contents (assuming the timestamp doesn't get much longer).\r\n\r\nother than that this looks good!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3247,
      "author": "saksham23467",
      "created_at": "2025-07-31T12:32:49Z",
      "comments": [
        {
          "user": "saksham23467",
          "body": "Hi! This is my first contribution to CHAOSS. Please let me know if any changes are required. Looking forward to your feedback!"
        },
        {
          "user": "saksham23467",
          "body": "Sure, i‚Äôll make the changes in a while , i am having my exams right now.\r\n\r\nOn Mon, Sep 15, 2025 at 9:27‚ÄØAM John McGinness ***@***.***>\r\nwrote:\r\n\r\n> ***@***.**** requested changes on this pull request.\r\n>\r\n> There are extra changes in this PR that should not be included.\r\n>\r\n> Please rebase and remove the extra changes from each PR, and I can review\r\n> them independently.\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/chaoss/augur/pull/3247#pullrequestreview-3222839287>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BCCKHZZBKAL257YKR6AR4Z33SY2LRAVCNFSM6AAAAACCZY7X2KVHI2DSMVQWIX3LMV43YUDVNRWFEZLROVSXG5CSMV3GSZLXHMZTEMRSHAZTSMRYG4>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>"
        },
        {
          "user": "sgoggins",
          "body": "This has been sitting here for a while and we are going through things ... it does not look like its been tested, and its pretty isolated from our other code ... AND, these metrics are NOT USEFUL UNLESS YOU ARE USING AN API KEY that has maintainer rights on the repos you are getting data for. So, if you are running Augur only on the repos you have those privileges on you will get this data ... most OSPO driven Augur instances will not be able to capture this data."
        },
        {
          "user": "Ulincsys",
          "body": "Your error handling changes were included in this PR, and also #3248"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3254,
      "author": "xiaoha-cloud",
      "created_at": "2025-08-28T22:53:12Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "just dropping a note that the proposal this is in reference to is https://summerofcode.withgoogle.com/programs/2025/projects/WEvhcxii"
        },
        {
          "user": "sgoggins",
          "body": "@xiaoha-cloud : We are ready to begin testing. Are. you available for questions?"
        },
        {
          "user": "MoralCode",
          "body": "@xiaoha-cloud How much damage could someone cause if they were able to access the routes that require auth? \r\n\r\nFor instances that choose to make their augur frontends public, i'm fairly sure that anyone can just register, and then they would have access to these routes that allow adding/deleting/regenerating topic models (seemingly expensive/destructive actions).\r\n\r\nDoes Augur have a mechanism for more granular permissions or some kind of role-based access control to ensure that only users designated as augur admins can trigger compute-intensive actions, flood the DB, or delete stuff?"
        },
        {
          "user": "MoralCode",
          "body": "CI end to end test for docker is failing with this error:\r\n```\r\naugur-db-1      | 2025-10-20 20:39:29.767 UTC [61] ERROR:  invalid input syntax for type bigint: \"\"\r\naugur-db-1      | 2025-10-20 20:39:29.767 UTC [61] CONTEXT:  COPY subscription_types, line 1, column id: \"\"\r\naugur-db-1      | 2025-10-20 20:39:29.767 UTC [61] STATEMENT:  COPY augur_operations.subscription_types (id, name) FROM stdin;\r\naugur-db-1      | psql:/docker-entrypoint-initdb.d/augur-new-schema.sql:7384: ERROR:  invalid input syntax for type bigint: \"\"\r\naugur-db-1      | CONTEXT:  COPY subscription_types, line 1, column id: \"\"\r\n\r\naugur-db-1 exited with code 3\r\n```"
        },
        {
          "user": "xiaoha-cloud",
          "body": "> @xiaoha-cloud How much damage could someone cause if they were able to access the routes that require auth?\r\n> \r\n> For instances that choose to make their augur frontends public, i'm fairly sure that anyone can just register, and then they would have access to these routes that allow adding/deleting/regenerating topic models (seemingly expensive/destructive actions).\r\n> \r\n> Does Augur have a mechanism for more granular permissions or some kind of role-based access control to ensure that only users designated as augur admins can trigger compute-intensive actions, flood the DB, or delete stuff?\r\n\r\nI took a look at the code and found a couple of security gaps:\r\nProblem 1: Registration vulnerability\r\nIn routes.py line 146, the registration accepts an admin parameter from the form. While the frontend login page doesn't have this field, someone could just modify the HTTP request and add admin=true when registering to get admin privileges.\r\nProblem 2: Topic Modeling routes don't check permi"
        },
        {
          "user": "xiaoha-cloud",
          "body": "After thinking about it, I went with a simpler approach that I think is more practical.I added an @admin_only decorator that restricts the expensive write operations (training and optimizing models) to admin users only. Read operations like viewing, exporting, and comparing models are still available to any authenticated user. This way we prevent unauthorized users from flooding the database or triggering compute-intensive tasks, while still letting people access and analyze the data.I decided not to modify the registration system since that's a separate concern and could introduce other issues. This approach keeps things focused and maintainable - if we need more granular permissions later, it's easy to extend.The code is in commit ed3530bfc, specifically applied to the /topic-models/<repo_id>/train and /topic-models/<repo_id>/optimize routes.\r\nWould appreciate  review on this approach."
        },
        {
          "user": "Ulincsys",
          "body": "I see some TODOs in these endpoints. Are these beyond the scope of the original project proposal, or are there plans to implement these before the submission deadline?"
        },
        {
          "user": "Ulincsys",
          "body": "I see some changes in this file that are not relevant to the scope of this PR.\r\n\r\nIf you wish to go through and fix pylint errors or other issues unrelated to your PR, then please make a separate PR for that."
        },
        {
          "user": "Ulincsys",
          "body": "As with above, please do not make changes outside the scope of your PR"
        },
        {
          "user": "Ulincsys",
          "body": "The `db_session` variable as imported from `server` is already initialized, so using it in a context manager is not necessary."
        },
        {
          "user": "Ulincsys",
          "body": "Why do you use the `db_session` variable above, but create a new session here instead?"
        },
        {
          "user": "Ulincsys",
          "body": "As with above, changing out the quotation marks should be a separate PR.\r\n\r\nDoing so here vastly expands the size of the diff, and makes it more difficult to find the relevant changes for review."
        },
        {
          "user": "Ulincsys",
          "body": "Is there a specific reason to attempt to drop the table on upgrade?\r\n\r\nIt should be safe to assume that the table does not exist if the alembic revision is below 34."
        },
        {
          "user": "Ulincsys",
          "body": "Could you expand a little more on how this logging utility is used? What kinds of logs flow into this module, and where are they coming from?"
        },
        {
          "user": "Ulincsys",
          "body": "Note to self: update config path on config worker release"
        },
        {
          "user": "Ulincsys",
          "body": "Why not use `url_for()` here?"
        },
        {
          "user": "Ulincsys",
          "body": "Anywhere that hits an Augur endpoint should use `url_for()` whenever possible"
        },
        {
          "user": "xiaoha-cloud",
          "body": "The ‚Äúclustering worker‚Äù mentioned in the comments refers to the existing topic‚Äëmodeling workflow. That worker is already integrated with Celery: e.g., clustering_worker/tasks.py defines a Celery task (@celery.task base=AugurMlRepoCollectionTask, queue='ml') and imports celery_app. It also exposes synchronous helpers like train_model(...). The legacy versioned API TODOs were reminders to wire those endpoints to the same worker (optionally via Celery). In this PR, the web UI uses the view‚Äëlayer endpoints that invoke the training logic directly, so I removed the unused versioned routes to reduce confusion."
        },
        {
          "user": "xiaoha-cloud",
          "body": "Thanks for flagging ‚Äî those were local pylint-driven edits; I‚Äôve reverted them to match main and will keep lint-only fixes to a separate PR."
        },
        {
          "user": "xiaoha-cloud",
          "body": "Thanks for flagging ‚Äî those were local pylint-driven edits."
        },
        {
          "user": "xiaoha-cloud",
          "body": "The¬†logging¬†utility¬†provides structured¬†event¬†logging¬†for the¬†topic‚Äëmodeling¬†pipeline. Callers¬†use¬†a¬†single¬†helper, emit_event(logger, EVENT_NAME, repo_id=..., model_id=...,¬†payload). It¬†always¬†writes¬†a¬†JSON¬†line to¬†the¬†worker‚Äôs file¬†logs, and when DB logging¬†is¬†enabled¬†it¬†also¬†persists to¬†augur_data.topic_model_event¬†(sync¬†or¬†async¬†via Celery, with¬†safe¬†fallback to¬†file-only¬†on failure).\r\nWhat¬†flows¬†into¬†it and¬†from¬†where:\r\n* Lifecycle¬†events¬†from¬†clustering¬†worker tasks¬†(e.g., train_model): TRAIN_STARTED, TRAIN_COMPLETED, TRAIN_FAILED, with params¬†and¬†metrics¬†(coherence, counts, durations).\r\n* Retraining decision events from model‚Äëmanagement¬†logic (e.g., should_retrain¬†/ reuse¬†checks): RETRAIN_CHECK, REUSE_CANDIDATE_FOUND, RETRAIN_TRIGGERED/SKIPPED, including thresholds, growth/age¬†calculations, and¬†reason.\r\n* Optimization¬†events¬†from¬†parameter¬†search¬†(optimize_parameters): OPTIMIZATION_STARTED/COMPLETED, BEST_PARAMS_FOUND, and¬†any¬†training result/error¬†for¬†the¬†chosen¬†params.\r\n* Comp"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3252,
      "author": "Ulincsys",
      "created_at": "2025-08-27T00:06:14Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "@MoralCode I've rebased the branch and force pushed.\r\n\r\nPersonally speaking, I don't think it's always necessary to rebase. My understanding of the new development strategy was that changes should only ever flow into *release*, not that there were any restrictions on bidirectional merging with main."
        },
        {
          "user": "MoralCode",
          "body": "> My understanding of the new development strategy was that changes should only ever flow into release, not that there were any restrictions on bidirectional merging with main.\r\n\r\nYeah that might at least partly just be me making assumptions in the interest of just having one simple rule to follow rather than having to think about what the exceptions are.\r\n\r\nThat said, I agree we don't always have to rebase. If this branch was based several commits back and only had your two commits and no merge conflicts, I'd be okay with just merging (into main, once approved) without a rebase.\r\n\r\nI think the part that we should avoid is adding back-merge commits into feature branches for the purpose of updating this feature branch when that update isn't needed for the functionality of this PR/to resolve a conflict. Bringing stuff from main like that makes the diffs bigger and requires differentiating during code review between which changes are new and need approval vs what has already been approved"
        },
        {
          "user": "Ulincsys",
          "body": "Sounds good. I think we can wait, let us know when you've had a chance to get to it.\r\n\r\nOn our end, we saw that this seemingly also fixed the issue with facade getting stuck. I'm not entirely sure how this fixed that, but we were seeing it before, and we're no longer seeing it. I'm curious to see if you find the same thing on your end üëÄ"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : I'm confused about the rebase discussion. This is a change to one file from a feature branch going into main."
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode : I'm confused about the rebase discussion. This is a change to one file from a feature branch going into main.\r\n\r\nthats because it was force-pushed from [0ce574b](https://github.com/chaoss/augur/commit/0ce574bd0ff8ec9994b1aa324281cb1eb2e47fab) to [aeaf09f](https://github.com/chaoss/augur/commit/aeaf09f5d6debfcc9f4cbc5bae2cf04fa9ab55b5). if you click on the link for the original commit (the first one i listed), and then go to the parent commit, there's a merge commit that brings in changes from main that weren't needed for this PR to function - thats what was removed by the force push - turning this PR into a clean two commits on top of main that are easier to review"
        },
        {
          "user": "sgoggins",
          "body": "> > @MoralCode : I'm confused about the rebase discussion. This is a change to one file from a feature branch going into main.\r\n> \r\n> thats because it was force-pushed from [0ce574b](https://github.com/chaoss/augur/commit/0ce574bd0ff8ec9994b1aa324281cb1eb2e47fab) to [aeaf09f](https://github.com/chaoss/augur/commit/aeaf09f5d6debfcc9f4cbc5bae2cf04fa9ab55b5). if you click on the link for the original commit (the first one i listed), and then go to the parent commit, there's a merge commit that brings in changes from main that weren't needed for this PR to function - thats what was removed by the force push - turning this PR into a clean two commits on top of main that are easier to review\r\n\r\nCould this already be done? Or maybe I'm not understanding. I don't see a merge commit, but maybe I'm not seeing all the right flags. @MoralCode"
        },
        {
          "user": "Ulincsys",
          "body": "@sgoggins I removed the merge commits last week, so they are no longer present in this PR.\r\n\r\n@MoralCode Just a note: The merge commits in this branch did not originate from a PR on the GitHub side, they were produced from running `git merge main` in the terminal, and so blocking PRs in GitHub would not actually stop that from happening.\r\n\r\nAlso, have you had a chance to test out the changes? If not, I think we may wish to move forward with merging anyways, as our testing has indicated no issues so far."
        },
        {
          "user": "MoralCode",
          "body": "> Also, have you had a chance to test out the changes? If not, I think we may wish to move forward with merging anyways, as our testing has indicated no issues so far.\r\n\r\ndespite loading in (on my local instance) a sample list of repos that are known to be problematic due to their size, I'm not seeing any failures (just the large jobs getting stuck still) - sounds like this PR is tackling those kinds of outright failures, so it seems good to me! its probably not the most thorough testing in the world but I don't see a good reason to keep holding up this PR. Feel free to ship it!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3248,
      "author": "saksham23467",
      "created_at": "2025-08-01T10:33:00Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@saksham23467 : This looks promising."
        },
        {
          "user": "saksham23467",
          "body": "> @saksham23467 : This looks promising.\r\n\r\nThanks for reviewing! If everything looks good, could you approve the PR so we can move it forward?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky  / \r\n@Ulincsys : Could you review this?"
        },
        {
          "user": "MoralCode",
          "body": "ignoring the cross-pollination with the other PR, I dont see a fundamental change to the code in this PR except wrapping everything in try-catch statements..."
        },
        {
          "user": "MoralCode",
          "body": "I have force pushed and rebased this PR to both a) only include the relevant commit, and b) be based on current main.\r\n\r\nI agree with sean about the technical merits of this PR though, I suspect theres an additional component to the problem thats not being addressed"
        },
        {
          "user": "Ulincsys",
          "body": "It looks like the Clones metric API you implemented for #3247 got included in this PR.\r\n\r\nFeature implementations and bugfixes for existing infrastructure should be made into separate PRs. Please rebase and update the PR to only include the error handling changes."
        },
        {
          "user": "Ulincsys",
          "body": "Where possible and appropriate, please try to catch a specific exception class instead of a bare Exception."
        },
        {
          "user": "sgoggins",
          "body": "@saksham23467 ; I am not sure I see anything other than adding the try/catch ... and I think we want to be more specific about what we do. \r\n\r\nThere is a function call to `update_repos_with_dict` that is suppose to update the repo URL in the repo table if its changed .. this is the part we aren't sure is happening. \r\n\r\nI think we still need to handle the 404's more robustly than we are ..."
        },
        {
          "user": "MoralCode",
          "body": "im worried this may not actually stop collection. I think that was why there was an exception here in the first place"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3245,
      "author": "mohsinm-dev",
      "created_at": "2025-07-27T14:18:41Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@cdolfi : I think this addresses false duplicate types of issues."
        },
        {
          "user": "MoralCode",
          "body": "Seems like this needs to be merged still? any reason it hasnt been?"
        },
        {
          "user": "sgoggins",
          "body": "I think this helps to ensure that strings are interpreted as strings, and spaces are removed. So, it should eliminate \"false duplicates\"."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3235,
      "author": "MoralCode",
      "created_at": "2025-07-19T02:54:35Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "fixes #3234"
        },
        {
          "user": "MoralCode",
          "body": "> I think this actually fixes an issue I have been seeing. Thanks, @MoralCode\r\n\r\nAs the person who caused the issue, you're welcome :stuck_out_tongue_closed_eyes:"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3237,
      "author": "NikhilSalv",
      "created_at": "2025-07-24T23:20:32Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Thank you!"
        },
        {
          "user": "sgoggins",
          "body": "> Would it be helpful to have this cover all of the files in the generated docs?\r\n> \r\n> I also noticed this PR does not contain any changes to the README itself. would it be helpful to also fix tthe broken link in this PR as well?\r\n\r\n@MoralCode : I just don't know how the broken links could be fixed. The ones that broke most recently, for example, broke because they pointed to the CHAOSS website and we rearranged a bunch of things there ... I do not know of a way to automate broken link fixing ..."
        },
        {
          "user": "MoralCode",
          "body": "Is automatic fixing the goal of the CI job, or just alerting for new brokenness?\n\nI think we should do a scan over everything and collect all the broken links to CHAOSS, and bring them up with dawn or whoever said they were currently maintaining the website so we can either fix our links or get redirects added to help other people too."
        },
        {
          "user": "sgoggins",
          "body": "> Is automatic fixing the goal of the CI job, or just alerting for new brokenness?\r\n> \r\n> I think we should do a scan over everything and collect all the broken links to CHAOSS, and bring them up with dawn or whoever said they were currently maintaining the website so we can either fix our links or get redirects added to help other people too.\r\n\r\nI agree with this line of thinking. I think it is @ElizabethN who is managing the website right now. She is only one person, and, no disrespect to web people, but its not a great use of her time. \r\n\r\nDoes this PR seem to identify all of the broken links in our docs? Are those checks supposed to provide a list of broken links, and if so ... where. I am going to look around now."
        },
        {
          "user": "NikhilSalv",
          "body": "@sgoggins your welcome. @MoralCode  Well I tested this github action \"lycheeverse\" and it perfectly detects broken links. Below is the screenshot of the lycheeverse action summary. More over it also shows what is the API response (502 in this case).  Can we add a workflow-dispatch event in the action so that we can test that action manually from Actions >> All workflow >> Run workflow \r\n\r\n<img width=\"1029\" height=\"698\" alt=\"Screenshot 2025-07-25 at 13 05 30\" src=\"https://github.com/user-attachments/assets/d3357fb0-c834-4573-b7e3-4da446a286d3\" />"
        },
        {
          "user": "MoralCode",
          "body": "Agree with adding workflow-dispatch to allow manually triggered runs.\n\nI'd be curious to see what a run of this looks like when used on the entire repo, not just the README"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Do you want to approve, or wait for a full repo scan?"
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode : Do you want to approve, or wait for a full repo scan? \n\nIt seems like the way this action is configured, it only scans the README. I'd say we might as well have it scan the whole repo and fix as many dead links as possible, especially now that I theoretically have the ability to add redirects to the CHAOSS site"
        },
        {
          "user": "NikhilSalv",
          "body": "@MoralCode Sure, I will try to implement it for the entire source code."
        },
        {
          "user": "sgoggins",
          "body": "> @MoralCode Sure, I will try to implement it for the entire source code.\r\n\r\nWere you going to do this @NikhilSalv ?"
        },
        {
          "user": "MoralCode",
          "body": "i think this PR may be superseded by #3269 - that one seems to do the same thing but be more  up to date"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3224,
      "author": "MoralCode",
      "created_at": "2025-07-11T01:14:05Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "If possible, I would be greatly interested to figure out how to turn off the \"Unnecessary else after X\" warnings. IMO they are not helpful, and they encourage a reduction in readability."
        },
        {
          "user": "MoralCode",
          "body": "If we dont already have one, we can add a pylint config file to the repo to define a set of linting rules to enforce.\n\nhttps://pylint.pycqa.org/en/latest/user_guide/configuration/all-options.html"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3229,
      "author": "MoralCode",
      "created_at": "2025-07-15T13:14:34Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "i wouldnt exactly call this a bug fix, more just cleanup of potentially old tech debt or something - this doesnt fix anything (augur should operate exactly the same with or without this) - it just helps make the code more maintainable"
        },
        {
          "user": "Ulincsys",
          "body": "I think that the preferable location for this function would be in the `db/lib.py` file. The `augur.application.db` module is intended to be independent, and so it should not import anything from parent or sibling modules.\r\n\r\nWe struggled a lot for a long time with circular imports, and the practice of isolating this module was intended to fix that. So, instead, it's better for functionality required by the module to be included in the module, and anything outside of the module that needs it should import it from `db/`."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Have you seen @Ulincsys 's comment?"
        },
        {
          "user": "sgoggins",
          "body": "> I think that the preferable location for this function would be in the `db/lib.py` file. The `augur.application.db` module is intended to be independent, and so it should not import anything from parent or sibling modules.\r\n> \r\n> We struggled a lot for a long time with circular imports, and the practice of isolating this module was intended to fix that. So, instead, it's better for functionality required by the module to be included in the module, and anything outside of the module that needs it should import it from `db/`.\r\n\r\nThis comment ^ @MoralCode"
        },
        {
          "user": "MoralCode",
          "body": "Yep, just been distracted and haven't gotten around to moving the function"
        },
        {
          "user": "MoralCode",
          "body": "Oops, I don't think I was thinking when I made the code change, so I ended up moving it to db.utils.\n\nIt seems like it's a pretty standalone utility function, so it seems like it fits well there"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3220,
      "author": "MoralCode",
      "created_at": "2025-07-09T14:05:29Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "We do still use Jinja files, they are what the frontend is rendered with. \n\nI think instead of removing the glob alltogether, we could probably just restrict it to the templates directory, which is where all of the jinja files are located for the frontend."
        },
        {
          "user": "Ulincsys",
          "body": "@MoralCode This line is not unused, the whole file is loaded by Gunicorn at startup to configure worker and background settings. You can see where it is loaded in `backend.py` lines 74, 97, 98:\r\n\r\n```python\r\ngunicorn_location = os.getcwd() + \"/augur/api/gunicorn_conf.py\"\r\n...\r\ngunicorn_command = f\"gunicorn -c {gunicorn_location} -b {host}:{port} augur.api.server:app --log-file {gunicorn_log_file}\" \r\nserver = subprocess.Popen(gunicorn_command.split(\" \"))\r\n```"
        },
        {
          "user": "Ulincsys",
          "body": "Here's my suggested patch:\r\n\r\n```diff\r\ndiff --git a/augur/api/gunicorn_conf.py b/augur/api/gunicorn_conf.py\r\nindex 09c21161a..3e7bf5e3a 100644\r\n--- a/augur/api/gunicorn_conf.py\r\n+++ b/augur/api/gunicorn_conf.py\r\n@@ -19,7 +19,17 @@ logger = logging.getLogger(__name__)\r\n workers = multiprocessing.cpu_count() * 2 + 1\r\n umask = 0o007\r\n reload = True\r\n-reload_extra_files = glob(str(Path.cwd() / '**/*.j2'), recursive=True)\r\n+\r\n+augur_templates_dir = Path.cwd() / \"augur/templates\"\r\n+\r\n+if not augur_templates_dir.is_dir():\r\n+    logger.critical(\"Could not locate templates in Gunicorn startup\")\r\n+    exit(-1)\r\n+\r\n+reload_extra_files = glob(str(augur_templates_dir.resolve() / '**/*.j2'), recursive=True)\r\n+\r\n+# Don't  want to leave extraneous variables in config scope\r\n+del augur_templates_dir\r\n \r\n # set the log location for gunicorn    \r\n logs_directory = get_value('Logging', 'logs_directory')\r\n```"
        },
        {
          "user": "MoralCode",
          "body": "@Ulincsys \r\n\r\n> This line is not unused, the whole file is loaded by Gunicorn at startup to configure worker and background settings. You can see where it is loaded in `backend.py` lines 74, 97, 98:\r\n\r\nI'm not sure that I see where the `reload_extra_files` variable is being used in the lines you quoted. is there some implicit behavior here that I'm not familiar with?"
        },
        {
          "user": "Ulincsys",
          "body": "@MoralCode `reload_extra_files` is a Gunicorn config option. Gunicorn imports this file, and uses the globals defined in it as option definitions.\r\n\r\nYou can see the documentation for this option here: https://docs.gunicorn.org/en/stable/settings.html#reload-extra-files"
        },
        {
          "user": "MoralCode",
          "body": "ah ok. I'll update this to use your patch then. Thanks for the info!\r\n\r\n\r\nIs this reload feature likely to only be useful for development environments? Its been patched out of our prod instance for a while with seemingly no issues - maybe its worth putting behind an AUGUR_DEBUG or similar environment variable if one already exists?"
        },
        {
          "user": "Ulincsys",
          "body": "@MoralCode Yes, it's mostly a development feature, so I think putting it behind the development flag is probably appropriate.\r\n\r\nWe use the `AUGUR_DEV` environment variable to denote a development instance, so maybe adding a check for it in the file would do?\r\n\r\nThe only time it might be suitable for productions would be if the templates were to be programmatically updated during runtime somehow, but Augur does not do that, so it's not something that we necessarily need to support."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3221,
      "author": "MoralCode",
      "created_at": "2025-07-09T14:37:51Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "> I think the pylint is failing because of variable scoping.\r\n\r\nNone of that is related to the code in this PR. Could they be leftover warnings that werent fixed before #3218 got merged?"
        },
        {
          "user": "Ulincsys",
          "body": "I don't think this failure has anything to do with the changes, it's just RD being RD. This is the failing line:\r\n```\r\nRaw Output:\r\naugur/application/cli/backend.py:335:23: W0621: Redefining name 'logger' from outer scope (line 37) (redefined-outer-name)\r\nError: reviewdog: Too many results (annotations) in diff.\r\nYou may miss some annotations due to GitHub limitation for annotation created by logging command.\r\nPlease check GitHub Actions log console to see all results.\r\n\r\nLimitation:\r\n- 10 warning annotations and 10 error annotations per step\r\n- 50 annotations per job (sum of annotations from all the steps)\r\n- 50 annotations per run (separate from the job annotations, these annotations aren't created by users)\r\n```\r\n\r\nBasically, the task failed because too many warnings were emitted, not because an actual error occurred."
        },
        {
          "user": "sgoggins",
          "body": "> I don't think this failure has anything to do with the changes, it's just RD being RD. This is the failing line:\r\n> \r\n> ```\r\n> Raw Output:\r\n> augur/application/cli/backend.py:335:23: W0621: Redefining name 'logger' from outer scope (line 37) (redefined-outer-name)\r\n> Error: reviewdog: Too many results (annotations) in diff.\r\n> You may miss some annotations due to GitHub limitation for annotation created by logging command.\r\n> Please check GitHub Actions log console to see all results.\r\n> \r\n> Limitation:\r\n> - 10 warning annotations and 10 error annotations per step\r\n> - 50 annotations per job (sum of annotations from all the steps)\r\n> - 50 annotations per run (separate from the job annotations, these annotations aren't created by users)\r\n> ```\r\n> \r\n> Basically, the task failed because too many warnings were emitted, not because an actual error occurred.\r\n\r\nBut what I am seeing is a linting error, not a RTD error. @Ulincsys"
        },
        {
          "user": "Ulincsys",
          "body": "@sgoggins my apologies for the confusion. When I used \"RD\", I meant reviewdog, not readthedocs.\n\nThe linter failed because of too many warnings, but not because any actual error occurred afaict"
        },
        {
          "user": "MoralCode",
          "body": "Just installed the vscode pylint extension and it seems like these lint errors exist as far back as the current `release` branch. \r\n\r\nNot sure why RD chose this moment to make a fuss about them but i think it can be dealt with in a separate PR"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3216,
      "author": "MoralCode",
      "created_at": "2025-07-07T19:24:54Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "ok so the podman job is failing for expected reasons (i.e. #3195)"
        },
        {
          "user": "MoralCode",
          "body": "@sgoggins note I'm expecting this is likely to fail due to #3212 as well - I don't currently have a good workaround for that lifecycle hook though (at least one that won't break the openshift usecase based on my knowledge of it)."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Waiting to see what happens in the test, but looking at that issue I wonder if it is simply an issue of those two files not existing in the container yet, and maybe it could be solved with `touch` ? This could be all wrong, but I have seen failures like this before solved by simply making the file exist."
        },
        {
          "user": "JohnStrunk",
          "body": "buildah is using too much disk space:\r\n```\r\nError: committing container for step {Env:[PATH=/augur/.venv/bin:/usr/bin/:/usr/local/bin:/usr/lib:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin LANG=C.UTF-8 GPG_KEY=A035C8C19219BA821ECEA86B64E628F8D684696D PYTHON_VERSION=3.11.13 PYTHON_SHA256=8fb5f9fbc7609fa822cb31549884575db7fd9657cbffb89510b5d7975963a83a DEBIAN_FRONTEND=noninteractive UV_COMPILE_BYTECODE=1 UV_LINK_MODE=copy UV_LOCKED=1 SCC_DIR=/scc SCORECARD_DIR=/scorecard] Command:cmd Args:[/init.sh] Flags:[] Attrs:map[json:true] Message:CMD /init.sh Original:CMD [\"/init.sh\"]}: copying layers and metadata for container \"729ca85e50830fe3342a9a986119b6d26c3d62bbefa92c478ca33a070fb40cce\": writing blob: adding layer with blob \"sha256:eafd5cd469df775bd8d1792a90d4b7aaae47dbdb93bd80a8adecc5e506b65b69\": processing tar file(write /scorecard/scorecard: no space left on device): exit status 1\r\nError: Error: buildah exited with code 1\r\n```"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3208,
      "author": "MoralCode",
      "created_at": "2025-07-02T13:53:24Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Draft because I have a pending question on Slack about how to handle this new exception. as-is this PR will cause a crash at practically the same place in the code, just with a different error message/exception type"
        },
        {
          "user": "Ulincsys",
          "body": "If 410 signifies that issue and PR collection cannot continue for that repo, then it seems as though it should be treated the same as a 404."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : Are you still working on this or are you waiting for another PR?"
        },
        {
          "user": "MoralCode",
          "body": "> @MoralCode : Are you still working on this or are you waiting for another PR?\r\n\r\nthis is still WIP - i just need to add the logic to handle the new exception type i made and handle it similarly to a 404 per the above suggestion (and make sure that doesnt cause unintended side effects, like augur marking the repo as \"doesnt exist\")\r\n\r\n\r\n\r\na lot of my ability to test/review/make progress on PRs is currently blocked by getting a local copy of augur running. hoping to have something up and running soon though"
        },
        {
          "user": "MoralCode",
          "body": "End to end tests caught a missing colon (after i ran manually because the 3 min timeout cut off the stack trace)"
        },
        {
          "user": "MoralCode",
          "body": "This is ready to go now though"
        },
        {
          "user": "Ulincsys",
          "body": "It looks good to me, but I'd like input from @ABrain7710 before merging"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3218,
      "author": "ABrain7710",
      "created_at": "2025-07-08T02:42:05Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@JohnStrunk  / @MoralCode : The end to end test is timing out, but not \"failing\" in the ordinary sense. . I am wonder if the timeout is a parameter we need to set higher?"
        },
        {
          "user": "MoralCode",
          "body": "> @JohnStrunk / @MoralCode : The end to end test is timing out, but not \"failing\" in the ordinary sense. . I am wonder if the timeout is a parameter we need to set higher?\r\n\r\nThis isnt a timeout issue, the code in this PR made a change that broke something. The stacktrace above the timeout error points to:\r\n\r\n```\r\naugur-1 | File \"/augur/keyman/KeyClient.py\", line 162, in __init__\r\naugur-1 | self.stdin: PubSub = self.conn.pubsub(ignore_subscribe_messages = True)\r\naugur-1 | ^^^^^^^^^\r\naugur-1 | AttributeError: 'KeyPublisher' object has no attribute 'conn'\r\n```\r\nThis was also flagged by a bot that is installed https://github.com/chaoss/augur/pull/3218/files#r2191362618 (among many other warnings)"
        },
        {
          "user": "sgoggins",
          "body": "I think this needs to be fixed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3213,
      "author": "officialasishkumar",
      "created_at": "2025-07-06T08:27:26Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "Hello @officialasishkumar, thanks for this contribution (and apologies for the delay in getting around to this).\r\n\r\nWe've made some fairly substantial changes to the repo (notably using `uv` for python dependency management). Could you rebase this PR on top of the current `main` branch? This should also fix a lot of the linter warnings."
        },
        {
          "user": "officialasishkumar",
          "body": "Sure @MoralCode \n\nWill do by the EOD"
        },
        {
          "user": "MoralCode",
          "body": "@officialasishkumar Rebasing would probably be a better way to update this PR so that the diffs are easier to review because they only contain the changes you made, rather than also containing code from other peoples unrelated PRs that already exist on the main branch.\r\n\r\nAre you familiar with the process of rebasing in git? Happy to provide guidance if you would like"
        },
        {
          "user": "Akshatb2006",
          "body": "Hey @MoralCode \r\nCould you please review this once??"
        },
        {
          "user": "sgoggins",
          "body": "FYI -- @MoralCode is out of office until early next week."
        },
        {
          "user": "sgoggins",
          "body": "@officialasishkumar : New database objects should be in a file in `{repo root}/augur/application/schema/alembic/versions`\r\n\r\nI think with the PR open for the other GSOC team the next number in sequence is 35. \r\n\r\nThat enables alembic upgrades and downgrade."
        },
        {
          "user": "officialasishkumar",
          "body": "@sgoggins updated with commit https://github.com/chaoss/augur/pull/3213/commits/299bd909e238aeb208e95f644b8f2deaafb4809b"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 / @Ulincsys : Can you confirm that its our practice not to modify the main script for table creation, but to have the versioning script also included so that new installs just get \"all the upgrades\"?"
        },
        {
          "user": "MoralCode",
          "body": "The way i've done it in the past for other projects is that both the main schema gets modified AND migrations get created. Then if someone creates a new database, they get the latest schema (this has required a small bit of code when augur detects a new DB and creates the tables to stamp it with the current alembic version). Then that database can be upgraded as time goes on, but new dbs are always starting out on the latest version"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3211,
      "author": "MoralCode",
      "created_at": "2025-07-02T18:13:09Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "The `keyman` folder is required for the primary Augur container, because it contains the `KeyClient` and `KeyPublisher` classes, which are used by Augur for interacting with the key orchestrator.\r\n\r\nSee usage examples in `augur.application.cli.backend.start()` and `augur.tasks.github.util.github_data_access.GithubDataAccess.make_request()`"
        },
        {
          "user": "MoralCode",
          "body": "ah yeah i think i learned that the hard way when resolving the other errors I caused here lol"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3214,
      "author": "xiaoha-cloud",
      "created_at": "2025-07-07T12:01:14Z",
      "comments": [
        {
          "user": "xiaoha-cloud",
          "body": "Thanks @sgoggins for pointing this out! \r\n\r\nI've reviewed the current setup and understand that dependency management has moved to `pyproject.toml` with UV for locking. I'll go ahead and update the PR by removing the `setup.py` change and adding `pyLDAvis` under `[tool.poetry.dependencies]` in `pyproject.toml`.\r\n\r\nAfter making that change, I will have a quick sync with @MoralCode to confirm the dependency is added correctly and follows the updated standards.\r\n\r\nThanks again for the feedback!"
        },
        {
          "user": "sgoggins",
          "body": "@Xiaoha-cloud : You need to follow the instructions for reconciling the conflict with main. This reconciliation in your fork is possibly going to break your instance until we reconcile other changes to main. \r\n\r\nThe \"main thing\" that needs to happen is that we have gotten rid of the setup.py architecture ... So, that needs to go ... Then we need to add things to pyproject.toml, BUT ... \r\n\r\nBEFORE you add things to pyproject.toml we need to fix the conflict ... then I need to talk to @JohnStrunk or @MoralCode to determine HOW to modify `pyproject.toml` and `uv.lock` ..."
        },
        {
          "user": "xiaoha-cloud",
          "body": "Thanks again @sgoggins for the clarification!\r\n\r\nI've noted that the `setup.py` architecture has been deprecated and that we should now use `pyproject.toml` + `uv.lock` for all dependency management.\r\n\r\n Next Steps I‚Äôll Take:\r\n1. Resolve the merge conflict with `main`, especially removing the `setup.py` file from `clustering_worker`.\r\n2. Hold off on editing `pyproject.toml` or `uv.lock` until the conflict is fully resolved and I‚Äôve synced with @MoralCode or @JohnStrunk for the correct modification process.\r\n3. Test my instance locally post-merge to ensure the refactored worker is still functioning as expected."
        },
        {
          "user": "MoralCode",
          "body": "@Xiaoha-cloud Could you instead rebase your branch so that it is based on the current `main` branch? It seems like this PR is based on an augur version from April.\r\n\r\nDoing so would also pretty much do all of the `setup.py` -> `uv` migration for you, so all you should need to change is to adjust your \"Add pyLDAvis==3.3.1 to clustering_worker dependencies\" to instead commit the results generated by `uv add pyLDAvis==3.3.1`"
        },
        {
          "user": "xiaoha-cloud",
          "body": "@MoralCode The Docker build is failing due to geckodriver version resolution returning null from GitHub API, resulting in 404 errors."
        },
        {
          "user": "MoralCode",
          "body": "This seems maybe related to https://github.com/chaoss/augur/issues/1199"
        },
        {
          "user": "xiaoha-cloud",
          "body": "- Removed unused imports from the models file.\r\n- Deleted development-only SQL file.\r\n - Restored tox.ini for unit testing.\r\n- As suggested, I have moved the topic model migration documentation to docs/source/migrations/topic_model_meta.rst.\r\n - No changes were made to the nullable status of existing columns in production tables.\r\n- I have also added an introductory section explaining what topic modeling is, why it is useful for Augur, and how it works, written for non-experts.\r\n- This PR directly addresses the requirements described in #1199 by implementing HDP-based topic number estimation in the clustering_worker. With this change, the number of topics for LDA is now determined automatically based on the data, rather than being preset, which should improve the flexibility and accuracy of topic modeling in Augur."
        },
        {
          "user": "MoralCode",
          "body": "> As suggested, I have moved the topic model migration documentation to docs/source/migrations/topic_model_meta.rst.\r\n\r\nIs this added to the nav pages in readthedocs so that someone can navigate to it (do we even have a section in the docs currently for documenting migrations? \r\n\r\nCC @sgoggins for opinions on what to do with this particular page of docs"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode and @Xiaoha-cloud : I ran this on OSX and also ran the current version of main on OSX. Locally, both complain about tensorflow not being installed, and both also run. Frankly I am confused about how this could be the case since the OSX test is passing on this PR, but the end to end ones are not. \r\n\r\nThe end to end testing fails because of a timeout. I am wondering if the failure is actually a timeout issue."
        },
        {
          "user": "sgoggins",
          "body": "A few other notes: \r\n\r\n- I had to run `uv lock` locally to get this branch to run\r\n- When I run `make docs` locally I get no errors."
        },
        {
          "user": "xiaoha-cloud",
          "body": "Hey @MoralCode !\r\nTask 1: NMF+Count vs LDA Performance\r\n-  Replaced HDP with NMF+Count algorithm\r\n-  85.1% faster than LDA (0.020s vs 0.135s)\r\n-  92.9% better topic coherence (0.915 vs 0.474)\r\n-  8.09x speedup with larger datasets\r\nTask 2: JSON Configuration\r\n-   Replaced complex database config with config.example.json\r\n-   Easier for team members to configure topic modeling parameters\r\nTask 3: Cross-Platform TensorFlow\r\n-   Linux: tensorflow>=2.15.0,<2.16.0\r\n-   Apple Silicon: tensorflow-macos + tensorflow-metal\r\n-   Using uv dependency groups for platform compatibility\r\nTest Results: All 37 tests passed (22 unit + 6 integration + 6 system + 3 performance)\r\nThanks for helping with rebase and local testing! This version should run successfully now."
        },
        {
          "user": "xiaoha-cloud",
          "body": "Superseded by #3254 . Closing this PR to reduce review noise. The new PR rebases on current main, migrates dependencies to pyproject.toml + uv, adds migrations 34/35, implements NMF with 4‚Äëdimension auto‚Äëretraining, provides API + web UI, and addresses prior review feedback."
        },
        {
          "user": "MoralCode",
          "body": "Looks like this may in fact be a commit from Andrew that got mistakenly included in the rebase"
        },
        {
          "user": "MoralCode",
          "body": "Why was this changed?"
        },
        {
          "user": "MoralCode",
          "body": "This seems to make a change to the nullable status of another table. Was there a particular reason for this change? How would you recommend existing production databses, some with tens or hundreds of thousands of repos perform this migration if their tables have null values in them?"
        },
        {
          "user": "MoralCode",
          "body": "You seem to be importing numpy and PyLDAvis in a models file. Are these intended for performing business logic in the models? As far as I can tell they seem unused in this file"
        },
        {
          "user": "MoralCode",
          "body": "this file seems to be for unit testing - why was it removed as part of this PR?"
        },
        {
          "user": "MoralCode",
          "body": "It seems like you created a new file with a generic `create_tables` name that only creates your tables. Was this just something you were using in development? or is it part of how this PR operates?"
        },
        {
          "user": "MoralCode",
          "body": "Love to see that this is documented - i just wonder whether a README.md in the root of the repo is the best place for it. I'd recommend either:\r\n- having it be in comments within the migration file itself\r\n- putting it in the readthedocs (we may need to make a new subsection for migrations if theres other migrations that could use documenting"
        },
        {
          "user": "MoralCode",
          "body": "I think it would be nice to include documentation on what topic modeling is and/or why it may be helpful to the augur codebase (and ideally \"how\" if theres anything special happening there) in addition to just \"what\" happened.\r\n\r\nAs someone who hasn't interacted with topic modeling before, I think it would be nice to ensure that the documentation is written with non-experts in mind. It seems to me like the goal of this is to automatically (rather than manually) group items in augur, such as repositories or words from issue/PR comments, into topic categories. It would be great to have your help in understanding whether or not this is correct and making sure the knowledge is documented for future contributors."
        },
        {
          "user": "xiaoha-cloud",
          "body": "I added this condition to prevent Docker images from being pushed during pull request builds, which helps keep the registry clean and avoids publishing images for unreviewed code.\nIf the community has a different workflow or specific requirements (such as pushing images for PR previews), this change can be adjusted or reverted as needed.\nPlease advise on the preferred approach."
        },
        {
          "user": "xiaoha-cloud",
          "body": "This file was created for local development and testing purposes, to quickly set up the new topic modeling tables and fields. It is not intended to be part of the production schema or the main migration process. I have removed it from the PR to avoid confusion."
        },
        {
          "user": "xiaoha-cloud",
          "body": "The nullable=False settings in TopicModelMeta are for a new table introduced by this migration. These fields are required for each topic model record and do not affect any existing tables or data. No changes were made to the nullable status of existing columns in production tables."
        },
        {
          "user": "MoralCode",
          "body": "This is already filtered for on this line https://github.com/chaoss/augur/blob/2f860d8cae2ba95bd2450f5987dee7e9a14f30c5/.github/workflows/build_docker.yml#L292"
        },
        {
          "user": "MoralCode",
          "body": "it looks like this particular line is affecting a class called `PullRequestMessageRef` - is that one that you added?"
        },
        {
          "user": "MoralCode",
          "body": "It seems like this PR has two revisions numbered 32 - is that intentional? Seems incorrect to me"
        },
        {
          "user": "MoralCode",
          "body": "You added a reference to a file that doesnt exist - this is causing a warning in the docs build (and presumably causing it to fail)\r\n\r\nMight be nice to add a toc page (similar to the other TOC pages) to act as both a Table of contents for the migrations pages and also a general page explaining what the migrations sections of the docs are for"
        },
        {
          "user": "MoralCode",
          "body": "`/home/runner/work/augur/augur/docs/source/index.rst:7: WARNING: toctree contains reference to nonexisting document 'migrations/toc'`"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3202,
      "author": "JohnStrunk",
      "created_at": "2025-06-27T18:36:36Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "@sgoggins The root directory `/` is also read-only on most Linux distros, including Ubuntu. Is it possible that the git credentials are being stored somewhere else on Linux?"
        },
        {
          "user": "sgoggins",
          "body": "@JohnStrunk / @Ulincsys : \r\n\r\n@Ulincsys - Ultimately, when I went with the entry being blank, it let me through and created the `.get-credentials` file at Augur's root. I wonder if that is the expectation and something just went awry?\r\n\r\n`uv` does seem to behave differently on Ubuntu and OSX using bare metal. On OSX I can run install/rebuild commands like this: \r\n- OSX: `make install` or `make rebuild`\r\n- Ubuntu: `uv run make install` or `uv run make rebuild` \r\n\r\nIts probably an idiosyncracy of `uv` and different OS's ... returning back to my earlier pondering of support for both bare metal and docker ... \r\n\r\nI also got something of an odd and SIMILAR (identical?) result on bare metal Ubuntu: \r\n\r\n```bash\r\nThe Facade data collection worker will clone repositories to this machine to run its analysis.\r\nPlease select a new or existing directory for the Facade worker to use:\r\n\r\nFacade worker directory: /home/sean/uv-test-repos\r\n\r\nFile .git-credentials does not exist. Creating it...\r\ntouch: "
        },
        {
          "user": "sgoggins",
          "body": "I think \r\n- `.git-credentials`  and \r\n- Understanding what the issues are for bare metal on Ubuntu (and possibly OSX) \r\n\r\nAre the things to address here. And on the bare metal issues, we could still lower that as a design priority. Right now I think it can be merged if we sort `.git-credentials`, but I would like to know what the issues are on Ubuntu bare metal. \r\n\r\nIt may be an issue with flask_graphql, which is no longer supported and requires some refactoring."
        },
        {
          "user": "JohnStrunk",
          "body": "Reading through this, I'm seeing:\r\n- Our tests aren't covering osx.\r\n  I know nothing about Apple, but I'll try adding a job using the macos runner and see if I can get it to fail on xgboost.\r\n- xgboost needs to be upgraded.\r\n  The project version is 1.4.2 from May 2021, w/ the current version being 3.0.2. I'll go ahead and bump the version and see what happens.\r\n- `make install` vs `uv run make install`\r\n  I don't really understand this. The Makefile includes `uv run` within the commands for the `install` and `rebuild` targets. A quick test seems to suggest uv \"does the right thing\" when it's invoked multiple times.\r\n  Is there something that caused you to use 2 different invocations?\r\n- `.git-credentials`\r\n  I'm happy to look into it, but I don't understand where/why/how this is used. I'm pretty sure I've seen errors in the docker container as well. Is there a piece of functionality we could test for to make sure it's working as expected?"
        },
        {
          "user": "JohnStrunk",
          "body": "- I've added a test for macOS that at least installs the dependencies. This catches the xgboost problem\r\n- I've also upgraded xgboost, and added a constraint for graphql-server-core that was breaking the e2e test."
        },
        {
          "user": "sgoggins",
          "body": "> * I've added a test for macOS that at least installs the dependencies. This catches the xgboost problem\r\n> \r\n>     * I've also upgraded xgboost, and added a constraint for graphql-server-core that was breaking the e2e test.\r\n\r\nThank you, @JohnStrunk !! We appreciate you!!"
        },
        {
          "user": "Ulincsys",
          "body": "Does this force the project to run on 3.11? Is this a strict requirement, or a preference?"
        },
        {
          "user": "JohnStrunk",
          "body": "(expanding on my answer from slack)\r\nThe `.python-version` file [determines the version of python](https://docs.astral.sh/uv/guides/projects/#python-version) that will be used by uv when building the venv for the project. It's also used in the CI workflow as input to the `setup-python` actions to determine the version of Python used there.\r\n\r\nIt's just providing the \"default version\", not mandating a minimum. The minimum is set in `pyproject.toml`. That happens to be 3.10 due to the xgboost version upgrade (68431f1e3adb22cc756d1e7bf014b355edb41fd5). It was 3.9 prior to that.\r\n\r\nWhen I created the `.python-version` file, I went w/ the version we're using for the docker containers since that was known to work."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3203,
      "author": "JohnStrunk",
      "created_at": "2025-06-27T19:27:07Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "> Depends on https://github.com/chaoss/augur/pull/3202 <== Merge that first!\r\n\r\nI guess this is off-topic, but is this something you think Mergeify can help enforce for us in the future? IMO it would be nice to be able to have a red failing CI job present on open PRs that are somehow marked as dependent on other yet-to-be-merged PRs"
        },
        {
          "user": "MoralCode",
          "body": "Also, it looks like this PR still contains some UV related changes - should those be moved to #3202 ?"
        },
        {
          "user": "JohnStrunk",
          "body": "Yes, mergify can handle dependencies: https://docs.mergify.com/merge-protections/#depends-on (If I would have used the right syntax :cry:)\r\n\r\nThe uv-related commits are because this branch is build on top of my uv branch from #3202. Those will either go away or I can rebase once that merges. I originally tried to base this one on main directly, and I got a bunch of conflicts wrt uv."
        },
        {
          "user": "MoralCode",
          "body": "Docs build is failing due to a reference to `setup.py`"
        },
        {
          "user": "JohnStrunk",
          "body": "> Docs build is failing due to a reference to `setup.py`\r\n\r\n#3210 is the fix for the doc build on RTD"
        },
        {
          "user": "Ulincsys",
          "body": "Was this extension removed because it was unused, or for some other reason?"
        },
        {
          "user": "Ulincsys",
          "body": "What is the significance of the double underscore here?"
        },
        {
          "user": "Ulincsys",
          "body": "Is there a particular reason to remove syntax highlighting for this block?"
        },
        {
          "user": "JohnStrunk",
          "body": "It was the source of many warnings about duplicate anchors since it creates an anchor w/ the name of every section. I think I only had to correct 1 or 2 links in all of the docs as a result of disabling this. The fix was to add manual anchors to the couple of sections."
        },
        {
          "user": "JohnStrunk",
          "body": "It avoids creating a target, preventing warnings about duplicates. Explanation: https://stackoverflow.com/questions/27420317/restructured-text-rst-http-links-underscore-vs-use"
        },
        {
          "user": "JohnStrunk",
          "body": "It's not valid json, due to the `[integer:...]` line. That results in a warning:\r\n```\r\n/home/jstrunk/src/github.com/chaoss/augur/docs/source/login.rst:110: WARNING: Lexing literal_block '{\\n    \"status\": \"Validated\",\\n    \"access_token\": \"the new Bearer token\",\\n    \"refresh_token\": \"the new refresh token\",\\n    \"token_type\": \"Bearer\",\\n    \"expires\": [integer: seconds until this access_token expires]\\n}' as \"json\" resulted in an error at token: 'i'. Retrying in relaxed mode.\r\n```\r\n\r\nI chose to just make it text instead of try and figure out how to explain the integer parameter separately since comments aren't allowed in proper json either :cry:"
        },
        {
          "user": "Ulincsys",
          "body": "Does RST support HJSON highlighting? That format allows comments, so if it can then it may be useful to switch it to that"
        },
        {
          "user": "JohnStrunk",
          "body": "Looks like pygments will take json5. I switched it to that."
        },
        {
          "user": "Ulincsys",
          "body": "Great! There's still one more text block in the file that needs updated to json5, but other than that it looks good to me"
        },
        {
          "user": "JohnStrunk",
          "body": "got them both now. :facepalm:"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3198,
      "author": "sgoggins",
      "created_at": "2025-06-25T18:56:49Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@mergifyio backport release"
        },
        {
          "user": "JohnStrunk",
          "body": "I have split this back into the 2 PRs that originally generated these commits:\r\n- #3202\r\n- #3203\r\n\r\n... closing this PR."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3201,
      "author": "MoralCode",
      "created_at": "2025-06-25T20:37:32Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "This goes with #3200 and should ideally be merged very soon after it"
        },
        {
          "user": "MoralCode",
          "body": "marking as draft since it seems quite likely that theres a lot more documentation thats worth adding. \r\n\r\nIMO we should fully document the expectations for merges/the whole merge and release process beyond just branching strategy, especially for the benefit of onboarding new contributors."
        },
        {
          "user": "MoralCode",
          "body": "Plan going forward:\r\n- create a page on readthedocs documenting our standard release process in detail (or updating any that already exist)\r\n- update CONTRIBUTING.md to lightly mention this process and link to the readthedocs so new contributors know the expectations"
        },
        {
          "user": "sgoggins",
          "body": "Note: Addressing the concern of \"holding up main\" during the release process:\r\nWhen it comes time for \"we'd like to start a new release\", release can be updated to the current main. From this point on, release would be in \"hotfix\" mode:\r\n\r\nrelease gets tested, and when bugs are discovered, they are PRed into main and backported to release once they merge.\r\nNormal PRs to main continue w/o the backport (they will not go into the upcoming release).\r\nOnce happy w/ the state of release, it is tagged w/ the version, becoming an official release.\r\nHotfixes for that release go to main and are backported, followed by a new \"Z\" tag/release.\r\n\r\nThe downside of the above is that during the initial phase of each release, it's hard to create a hotfix. One fix to that would be to have release-x.y branches instead of just one branch named release.\r\nHere's how that could go:\r\n\r\nIt's time for a new release, so release-x.y is created from main.\r\nrelease-x.y is tested and fixes go into main w/ backport to"
        },
        {
          "user": "sgoggins",
          "body": "We are discussing how this would work. We think : \r\n- Everything gets merged into main\r\n- When we do a release it all gets merged into release\r\n- If there are hot fixes into main, those may need to be cherry picked into release. \r\n\r\n\r\nI think we have this understanding correct."
        },
        {
          "user": "ABrain7710",
          "body": "To avoid having to delay changes to the main branch while preparing a release we would like the process to be \r\n1. Create a branch named`release-<release_name>` from the commit proposed for release. \r\n2. Test the `release-<release_name>` branch \r\n3. Create a pr from `release-<release_name>` into release when the changes look good\r\n\r\nIf any fixes are needed to the `release-<release_name>` they can be made to it directly and then it can be merged into `release` and `main`"
        },
        {
          "user": "sgoggins",
          "body": "@JohnStrunk / @MoralCode : Does this make sense and work for our discussed goals? I think so ... but I remain new to uv."
        },
        {
          "user": "MoralCode",
          "body": "Yeah that sounds right. Did you think this section could be better worded?\n\nThe specific part you're commenting on here is referring to the normal release process of merge all of me into release. The hot thick stuff is described separately a little bit further down (As a sort of amendment to the regular release process)"
        },
        {
          "user": "MoralCode",
          "body": "this isnt directly related to `uv`. \r\n\r\nI think i agree with the \"create a separate branch so that main can keep moving without auto-updating the release PR\" portion of the proposal. It just sounds like this part:\r\n\r\n> If any fixes are needed to the release-<release_name> they can be made to it directly and then it can be merged into release and main\r\n\r\nrisks bringing back a lot of the issues that we avoid with the \"all changes land in main first\" policy. I worry about us being in a situation where a) a release has a lot of time pressure (i.e. shiping a critical fix thats causing data loss or something), b) we have to add a hotfix to the release branch, c) we forget to merge the hotfix back into main.\r\n\r\nI think a better version would be:\r\nSteps 1-3: as written, except maybe swap 2 and 3, since creating the PR will trigger automated testing and CI jobs and things in that PR\r\n\r\nif any fixes are needed to the release, they are made to main. If the fix is the next commit after the release"
        },
        {
          "user": "JohnStrunk",
          "body": "Addressing the concern of \"holding up main\" during the release process:\r\nWhen it comes time for \"we'd like to start a new release\", `release` can be updated to the current `main`. From this point on, `release` would be in \"hotfix\" mode:\r\n- `release` gets tested, and when bugs are discovered, they are PRed into main and backported to release once they merge.\r\n- Normal PRs to `main` continue w/o the backport (they will not go into the upcoming release).\r\n- Once happy w/ the state of `release`, it is tagged w/ the version, becoming an official release.\r\n- Hotfixes for that release go to `main` and are backported, followed by a new \"Z\" tag/release.\r\n\r\nThe downside of the above is that during the initial phase of each release, it's hard to create a hotfix. One fix to that would be to have `release-x.y` branches instead of just one branch named `release`.\r\nHere's how that could go:\r\n- It's time for a new release, so `release-x.y` is created from `main`.\r\n- `release-x.y` is tested and fixes g"
        },
        {
          "user": "JohnStrunk",
          "body": "I don't think we want to imply that `release` is always a version that is blessed for running in production. That's really only tagged versions."
        },
        {
          "user": "MoralCode",
          "body": "Do we think it would be useful to downstream users to deploy from just the release branch (vs a release tag) if they want the latest release automatically?"
        },
        {
          "user": "JohnStrunk",
          "body": "We can provide floating (container) tags to support auto upgrade from release-to-release, but I think users are taking a risk if they go that route. It's really important to understand what's being deployed to production."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3206,
      "author": "sgoggins",
      "created_at": "2025-07-02T00:21:05Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "I don't understand what this PR is doing\r\n\r\nIt purports to be merging main into release, but it seems as though, in the current state of the repo (main is cf69b9ea9ebcbe235404d856c914947a8daa2a39, release is 47ceea4b941811df907569cc41f36857eff98e6d), release is only behind main by 3 merge commits (the merges for prs 3200, 3202, and 3204 in that order).\r\n\r\n1) This PR seems like it contains just the straight up commits - is that GitHub's UI trying to be clever and unraveling each of the merges in the UI? \r\n\r\n2) Even if so, I think #3203 should be rebased and merged since it fixes the failing docs builds and depends on the now-merged 3202\r\n\r\n3) I think #3201 should be in this release as it documents the new branching model. We dont want any new contributors that look at the release docs between now and the release after the one in this PR to be trying to use the old process or basing their changes on the now-deprecated `dev` branch\r\n\r\n4) since this is a regular release, mergify should not"
        },
        {
          "user": "JohnStrunk",
          "body": "@MoralCode You're right that the hashes aren't the same. It appears to be that it's not including the merge commits, just the underlying commits themselves. I *think* this is ok for our purposes.\r\n\r\nAnother option would be to have a workflow that does a `git branch -f release main` to really set them equal."
        },
        {
          "user": "MoralCode",
          "body": "id rather check if theres an actual setting that controls that - mostly so we can turn it off and keep the commits organized/grouped by which merge/feature they were for to avoid confusion and/or weird bugs"
        },
        {
          "user": "sgoggins",
          "body": "> There are unaddressed questions about what this PR aims to do\r\n\r\nThis PR is to create a release from what is in main @MoralCode"
        },
        {
          "user": "sgoggins",
          "body": "> I don't understand what this PR is doing\r\n> \r\n> It purports to be merging main into release, but it seems as though, in the current state of the repo (main is [cf69b9e](https://github.com/chaoss/augur/commit/cf69b9ea9ebcbe235404d856c914947a8daa2a39), release is [47ceea4](https://github.com/chaoss/augur/commit/47ceea4b941811df907569cc41f36857eff98e6d)), release is only behind main by 3 merge commits (the merges for prs 3200, 3202, and 3204 in that order).\r\n> \r\n>     1. This PR seems like it contains just the straight up commits - is that GitHub's UI trying to be clever and unraveling each of the merges in the UI?\r\n> \r\n>     2. Even if so, I think [Try 2: Fix warnings/errors in docs & ensure clean builds #3203](https://github.com/chaoss/augur/pull/3203) should be rebased and merged since it fixes the failing docs builds and depends on the now-merged 3202\r\n> \r\n>     3. I think [Update documentation for new branching model #3201](https://github.com/chaoss/augur/pull/3201) should be in th"
        },
        {
          "user": "sgoggins",
          "body": "We are currently conducting the high-volume collection test on `main` before the merge."
        },
        {
          "user": "MoralCode",
          "body": "> This PR is to create a release from what is in main @MoralCode\r\n\r\nThat part makes sense - I'm just worried about the risk of creating regressions given that this PR doesn't seem to line up with what's actually on main\r\n\r\n> @MoralCode You're right that the hashes aren't the same. It appears that it's not including the merge commits, just the underlying commits themselves.\r\n\r\nDid we ever find a solution to the issue of why the commits in this PR don't line up with what is on `main`? (i.e. the early history of this PR shows a bunch of commits that should have been part of merges)\r\n\r\nExample: commit 706e5dcd217d096b0400e657be97979dbabaa5db should not be listed on this page as being directly part of this PR because it's a commit on a feature branch. It should instead be indirectly included via the merge commit 4e64a177dc33b8e48ecbcca9697d15a1a9910062 that was already approved and merged to main. If you ctrl-F this page for \"706e5d\" you can see it is directly part of this PR. I think somet"
        },
        {
          "user": "sgoggins",
          "body": "I think this may be causing an issue where not found URL's are causing breaking errors."
        },
        {
          "user": "sgoggins",
          "body": "Maybe some issues here ... related to the disposal of database connections."
        },
        {
          "user": "sgoggins",
          "body": "This is generating errors in testing. @MoralCode .. basically we are getting errors when these resource exceptions are hit and the job fails. Perhaps that is intended. Just checking."
        },
        {
          "user": "sgoggins",
          "body": "This seems possibly wrong. @MoralCode / @Ulincsys ... we have changed the import from `as conn` to simply be the library. I don't see where `conn` exists as an import any longer. If this fails, it seems it could be the source of the database connection leaks on `main` right now."
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode / @Ulincsys : Here as well, `conn` is referenced but I don't think it exists any longer."
        },
        {
          "user": "sgoggins",
          "body": "here is where the `as conn` is removed, but is still in use through the rest of the file."
        },
        {
          "user": "sgoggins",
          "body": "no `conn`"
        },
        {
          "user": "sgoggins",
          "body": "ok .. here `conn` exists as a call to a method."
        },
        {
          "user": "sgoggins",
          "body": "The change here is moving the refernce from the library to this call to the `get_redis_connection()` method."
        },
        {
          "user": "MoralCode",
          "body": "fixed in #3235"
        },
        {
          "user": "MoralCode",
          "body": "Can you elaborate on the issues you are seeing? This is a gunicorn config, so it shouldn't be affecting DB connections"
        },
        {
          "user": "MoralCode",
          "body": "I suspect this is fixed by #3235 (TL;DR my fault).\r\n\r\nIf a resource returns 410 Gone from github it is handled similarly to a 404 (i.e. bail out of the retry loop and keep going with collection rather than propagating the exception up to the worker and stopping everything)"
        },
        {
          "user": "sgoggins",
          "body": "I think you are right."
        },
        {
          "user": "MoralCode",
          "body": "That sounds plausible to me. I remember seeing that this keyclient file got refactored, but maybe it needs a deeper look"
        },
        {
          "user": "sgoggins",
          "body": "Later on in my review it seemed like the object was getting used and reassigned in the new class made specifically for that ... I am suspicious of Redis in general, perhaps being used in a way that creates a database connection but doesn't let go of it ... or the process loses it ... Like I said, there is no change that appears to directly alter the way we are connecting to the database ... which is everyone's favorite type of bug, right?"
        },
        {
          "user": "sgoggins",
          "body": "@MoralCode : In short, I have my POstgresql instance set to 3,000 connections .. and within one hour of starting Augur, they are all consumed. Which is bad in myriad ways, right? For comparison, the version of Augur in release uses max 200 connections over weeks."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3204,
      "author": "JohnStrunk",
      "created_at": "2025-06-27T19:36:47Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "was the conditional login supposed to be a conditional push? I imagine we would only want to push updates to keyman for either merges to `main` or merges to `release`, right?"
        },
        {
          "user": "JohnStrunk",
          "body": "The conditional login was a leftover from an earlier iteration of the workflow. That same condition actually gates the entire job: https://github.com/chaoss/augur/pull/3204/files#diff-c7f993a522ae12469fcfb15fc43197a8be4d9ef9e1350d98e775b2603eec9bd0R138-R139\r\n\r\nThe branch specification does need to be updated. #3200 will get that."
        },
        {
          "user": "MoralCode",
          "body": "Does this conflict with or depend on 3200? or can they both be merged independently?"
        },
        {
          "user": "JohnStrunk",
          "body": "> Does this conflict with or depend on 3200? or can they both be merged independently?\r\n\r\nDoesn't conflict, but given the choice, I'd do #3200 1st just to make sure the containers get tagged correctly when this goes in."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3181,
      "author": "jberkus",
      "created_at": "2025-06-10T00:44:22Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "We use Alembic for db migrations, so this change may also need to be added to a revision there.\r\n\r\nOur revisions directory is located in `augur/application/schema/alembic/versions`"
        },
        {
          "user": "sgoggins",
          "body": "LGTM"
        },
        {
          "user": "sgoggins",
          "body": "PR #3184 is being tested to ensure there's an upgrade and downgrade path for this change."
        },
        {
          "user": "sgoggins",
          "body": "I made an incremental change following our usual strategy in PR #3184 ... Whenever Augur is installed, it runs the script referenced here, and then all of the update scripts since this was created. Keeping the ORM stable and aligned is easier if we add an increment \"down the road\" instead of changing the core install; especially for Augur instances currently in place. THANK YOU @jberkus ! The maintenance guideposts on our part need to be more clear."
        },
        {
          "user": "jberkus",
          "body": "Um, why did you close this PR?  What does it have to do with a psycopg2 update?"
        },
        {
          "user": "jberkus",
          "body": "sorry about that bit, here my Python checker is just removing a trailing newline."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3169,
      "author": "ABrain7710",
      "created_at": "2025-06-03T23:54:21Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "The fixes are causing files 404 failures to error out all of secondary collection, which was not happening prior to this patch. \r\n\r\nSo, any time there is a file not at the endpoint, the whole secondary collection fails for the repo. These missing files are common, and not errors. We need a solution that solves the issue without propagating these as errors @ABrain7710 ..."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins Do you have a stack trace for these 404 errors? They should be handled but it is hard to tell what is happening without a stack trace"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3183,
      "author": "JohnStrunk",
      "created_at": "2025-06-11T20:01:53Z",
      "comments": [
        {
          "user": "JohnStrunk",
          "body": "The RTD build is currently broken for `dev` due to the switch to uv. RTD is using the `.readthedocs.yml` from main which still has the old setup.py-based build.\r\n\r\nhttps://app.readthedocs.org/api/v2/build/28480746.txt shows the config file that's being used, which is from main, not dev."
        },
        {
          "user": "PredictiveManish",
          "body": "There are some warnings inside the updated code by you sir @JohnStrunk it requires simple changes if you're doing this let me know otherwise I will do that as I'm new to this org these small changes will help me to understand better."
        },
        {
          "user": "sgoggins",
          "body": "OK ... wow. This is out of date.. Noting the need to fix it later."
        },
        {
          "user": "PredictiveManish",
          "body": "Is this fixed sir??"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3148,
      "author": "JohnStrunk",
      "created_at": "2025-05-05T19:57:46Z",
      "comments": [
        {
          "user": "JohnStrunk",
          "body": "@sgoggins @Ulincsys Please take a look when you get a chance. If you're good w/ it, I'll get to work on revising the docs."
        },
        {
          "user": "JohnStrunk",
          "body": "@sgoggins I've made the doc changes. This should be ready."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3153,
      "author": "sgoggins",
      "created_at": "2025-05-17T08:37:48Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I think the Docker issue is related to storing secrets OR it could be that the golang-builder image we are referencing doesn't exist anymore. @JohnStrunk ... what do you think?"
        },
        {
          "user": "JohnStrunk",
          "body": "> I think the Docker issue is related to storing secrets OR it could be that the golang-builder image we are referencing doesn't exist anymore. @JohnStrunk ... what do you think?\r\n\r\nThere was a bad merge along the line someplace. In the backend Dockerfile, the name of the stage that builds the golang executables doesn't match the name being used to copy them into the final image:\r\n\r\n```\r\nFROM golang:1.23-bullseye AS golang\r\n```\r\nvs\r\n```\r\nCOPY --from=golang-builder --chmod=u=rw,u+X,go=r,go+X \"/scc\" \"/scc/scc\"\r\n```\r\n\r\nChange the FROM line to be `... AS golang-builder`"
        },
        {
          "user": "ABrain7710",
          "body": "We don't want this because this will potentially obfuscate errors that are happening. We could potentially do this in the future, but right now we don't really look at logs to see the health of collection, we look at flower. So this would hide the error from flower"
        },
        {
          "user": "ABrain7710",
          "body": "Same here"
        },
        {
          "user": "ABrain7710",
          "body": "This logic should live in the pr files, pr commits, and pt comments collection files. \n\nIt's not the responsibility of GitHub data access to understand how to handle responses from the GitHub api. Its responsibilities are to communicate the result of data retrieval (success by not throwing an exception or failure by throwing an exception), handle authentication and ensure fault tolerance from rate limits.\n\nEssentially each of those needs to wrap the call to GitHub data access in a try catch and the specifically catch the UrlNotFoundException. Then the the catch you can do whatever logic that's needed for the specific data that's being collected.\n\nIt looks like it is already handled for files and messages, but not for commits"
        },
        {
          "user": "ABrain7710",
          "body": "I'm not sure why the existing code  isn't using GitHub graphql data access, but I think it would be good to try and use it here since it already throw 404 exceptions and invalid data exceptions"
        },
        {
          "user": "sgoggins",
          "body": "OK. We were getting message errors where if there were no messages it failed."
        },
        {
          "user": "sgoggins",
          "body": "So rewrite the repo_info logic to hit graphql instead of the REST API?"
        },
        {
          "user": "ABrain7710",
          "body": "Are you saying when we request all messages for a repo and it doesn't have any it will return a 404? \n\nIf so we should catch the UrlNotFoundException in the call to the bulk messages endpoint"
        },
        {
          "user": "ABrain7710",
          "body": "I didn't realize this was using the GitHub api. If it is then it should be using the GithubDataAccess class"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3151,
      "author": "JohnStrunk",
      "created_at": "2025-05-07T21:05:08Z",
      "comments": [
        {
          "user": "JohnStrunk",
          "body": "> Possibly out of scope for this PR but should maybe fix these warnings:\r\n> \r\n> ```\r\n> LegacyKeyValueFormat: \"ENV key=value\" should be used instead of legacy \"ENV key value\"\r\n> ```\r\n\r\n#3154"
        },
        {
          "user": "erikerlandson",
          "body": "Is removing branch spec here deliberate?"
        },
        {
          "user": "JohnStrunk",
          "body": "Yeah. I see no reason to skip these tests for any PR. In the event we get a long-lived feature branch, this test should probably still run."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3142,
      "author": "cdolfi",
      "created_at": "2025-04-30T20:09:35Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I want to ensure this won't break anything that @JohnStrunk did to make Augur deployable on OpenShift. And I don't know enough to know if that is a risk or not. The change \"looks\" benign to something like that; which are the last words most people who crash systems utter."
        },
        {
          "user": "cdolfi",
          "body": "@sgoggins good call. I will say this is currently breaking/causing immense amount of failures if you build post 03/15 (release date of new version) so we will want to find a solution ASAP even if this isn't the one. We are using this change on our instance"
        },
        {
          "user": "JohnStrunk",
          "body": "I'm going to suggest we try the following:\r\nIn the current version of main, we've switched to building directly via `go install`. Instead of switching the debian version, let's try building static binaries by adding:\r\n`ENV CGO_ENABLED=0` right below the `ENV GOBIN=/`.\r\nThis breaks the dependency on the glibc version between the builder and final containers. There are some limitations when disabling cgo, so I need someone to test that scc and scorecard both still work in the final image.\r\n\r\nIn my local branch, w/ the CGO change, I can at least run the `version` command on both of them as opposed to getting the glibc version error."
        },
        {
          "user": "cdolfi",
          "body": "@JohnStrunk Im trying to remember them exactly, the issue was with these https://github.com/cdolfi/augur/blob/2da45ae478c0beef821ca2247b942f058b3113fd/docker/backend/Dockerfile#L123-L124. SCC and scorecard were both causing a lot of errors to occur. Ill build current main and see what happens, then add the change you have described above. Would you be able to put the change you are describing in a code block for I can get the indentions and spacing right?"
        },
        {
          "user": "cdolfi",
          "body": "@sgoggins @JohnStrunk Tried to build main and got the following \r\n\r\n`Step 17/38 : COPY --chmod=u=rw,u+X,go=r,go+X ./README.md .\r\nthe --chmod option requires BuildKit. Refer to https://docs.docker.com/go/buildkit/ to learn how to build images with BuildKit enabled`\r\n\r\nIll wait until the AM and I hear from @GregSutcliffe on how to handle this"
        },
        {
          "user": "GregSutcliffe",
          "body": ">  I would have expected static golang binaries, so I'm a bit puzzled about why the version of debian would matter. @cdolfi Is there a copy of the errors somewhere?\r\n\r\n@JohnStrunk they are static, but Debian 11 uses GLIBC 2.31, Debain 12 has GLIBC 2.32, so the binary cannot run."
        },
        {
          "user": "GregSutcliffe",
          "body": "Posting at midnight means I forgot some points, let me expand:\r\n- The issue is a difference in GLIBC between the builder and the execution. I don't have the exact output to hand, but you'll get a symbol error if you try to run scc or scorecard in the augur container.\r\n- The change to the GO build was written by @MoralCode in Feb. At that time Debian 11 was the default, so the Go build container matched the Augur container.\r\n- Debain 12 was released on March 15th, at this point the \"1.23\" Go container now points to Bookworm which uses a different GLIBC\r\n- So right now, as we don't target a specific Debian version for Go but do for Augur, the binaries created by the Go builder can't be executed by the Augur container\r\n\r\nRight now, no one can build the container with working SCC / Scorecard. This patch *restores* the functionality as originally working & tested by ensuring we use the Bullseye version of Go 1.23. Since it's (a) broken and (b) not changing anything, I regard this is both im"
        },
        {
          "user": "GregSutcliffe",
          "body": "I fired up the vanilla build of 0.86.0 and reproduced the error, here you go:\r\n```\r\n$ docker run -it augur:v0.86.0 -c bash\r\nroot@73fa29492449:/augur# /root/scc/scc\r\n/root/scc/scc: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /root/scc/scc)\r\n/root/scc/scc: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /root/scc/scc)\r\nroot@73fa29492449:/augur# /root/scorecard \r\n/root/scorecard: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /root/scorecard)\r\n/root/scorecard: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /root/scorecard)\r\n```"
        },
        {
          "user": "JohnStrunk",
          "body": "> > I would have expected static golang binaries, so I'm a bit puzzled about why the version of debian would matter. @cdolfi Is there a copy of the errors somewhere?\r\n> \r\n> @JohnStrunk they are static, but Debian 11 uses GLIBC 2.31, Debain 12 has GLIBC 2.32, so the binary cannot run.\r\n\r\nUnless CGO is disabled, we end up w/ a dynamic executable (and so the dependency on glibc version).\r\n\r\n```console\r\n[jstrunk temp]$ GOBIN=`pwd` CGO_ENABLED=1 go install github.com/boyter/scc/v3@v3.4.0\r\n[jstrunk temp]$ ldd scc\r\n\tlinux-vdso.so.1 (0x00007ff1c7dee000)\r\n\tlibresolv.so.2 => /lib64/libresolv.so.2 (0x00007ff1c7db6000)\r\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007ff1c7bc3000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007ff1c7df0000)\r\n[jstrunk temp]$ GOBIN=`pwd` CGO_ENABLED=0 go install github.com/boyter/scc/v3@v3.4.0\r\n[jstrunk temp]$ ldd scc\r\n\tnot a dynamic executable\r\n```\r\n\r\nAnd I can confirm the CGO change makes it at least runnable:\r\n```console\r\n[jstrunk main* augur]$ docker run -it --rm augur /scc/scc --v"
        },
        {
          "user": "cdolfi",
          "body": "Update: I was able to build the container but can not test the problems described above because this is what I hit: \r\n\r\n#3146"
        },
        {
          "user": "cdolfi",
          "body": "@sgoggins To summarize the conversion above, @JohnStrunk has suggested a completely different change to solve the issue, but I was unable to test whether that change works, or if this one is necessary or fixes the problem with the updates from dev. I opened this PR before dev was merged into main. I opened a different issue detailing that I was not able to test out this problem as I ran into a completely different issue trying to run the main branch with the updates from dev. #3146"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3123,
      "author": "sgoggins",
      "created_at": "2025-04-08T15:22:41Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Latest update is fixing some issues and the task is usually succeeding: \r\n\r\n```\r\n(ai) sean@linda:~/github/ai.chaoss$ cat nohup.out | grep \"Retry of 'git rev-list --count HEAD' failed\" | wc -l\r\n58\r\n(ai) sean@linda:~/github/ai.chaoss$ cat nohup.out | grep \"Error running 'git fsck':\" | wc -l\r\n65\r\n\r\n```"
        },
        {
          "user": "sgoggins",
          "body": "A reasonable point. investigating the issues logged here right now."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3100,
      "author": "JohnStrunk",
      "created_at": "2025-04-01T19:48:15Z",
      "comments": [
        {
          "user": "JohnStrunk",
          "body": "@sgoggins I noticed my PR from yesterday was causing some failed checks. This should fix it."
        },
        {
          "user": "sgoggins",
          "body": "@JohnStrunk : Just to confirm my understanding here: We will push new images when a new release is tagged now?"
        },
        {
          "user": "JohnStrunk",
          "body": "It should. The tags are applied here, with the final line being the one for releases:\r\n\r\n```yaml\r\n          tags: |\r\n            type=raw,value=devel-latest,enable=${{ (github.event_name == 'push' || github.event_name == 'workflow_dispatch') && github.ref == 'refs/heads/dev' }}\r\n            type=raw,value=latest,enable=${{ github.event_name == 'release' }}\r\n            type=raw,value=${{ github.event.release.tag_name }},enable=${{ github.event_name == 'release' }}\r\n```\r\n\r\nThe tags are then provided as a step output to the build/push step as a comma separated list. My change is gating whether we try to push (or only build) based on whether any tags are provided.\r\n\r\nThe release this morning [looks like it built & pushed correctly](https://github.com/chaoss/augur/actions/runs/14198432553/job/39779170197). This change shouldn't interfere."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3084,
      "author": "officialasishkumar",
      "created_at": "2025-03-21T12:48:40Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@officialasishkumar : What issue is this PR addressing?"
        },
        {
          "user": "officialasishkumar",
          "body": "@sgoggins I was getting an error \"SSL SYSCALL error: EOF detected.\" which was because the db connection becomes stale after the first dashboard load. the problem that i think was that static pool reuses the same connection even when it is closed.\r\n\r\nissue: https://github.com/chaoss/augur/issues/3081"
        },
        {
          "user": "Ulincsys",
          "body": "I've not done repro testing on this yet, but I'll bring it up later during our meeting.\n\nI'll try to see if I can trigger the same behavior on the admin-changes branch pre-patch. \n\nThe PR for this should not be made into main, as the interface for this is a new feature, and also because we'll need to perform some extra testing to ensure it doesn't break other components during runtime."
        },
        {
          "user": "officialasishkumar",
          "body": "@Ulincsys which branch should this pr go into?"
        },
        {
          "user": "sgoggins",
          "body": "@officialasishkumar : I think @Ulincsys would recommend the PR go into `dev`, but perhaps `admin-changes`."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3093,
      "author": "JohnStrunk",
      "created_at": "2025-03-31T20:08:29Z",
      "comments": [
        {
          "user": "JohnStrunk",
          "body": "I've left this as a draft pending feedback on what the proper handling of `latest` and `devel-latest` image tags should be.\r\n- The original workflow would only update `latest` during a release, matching it to the most recently released version.\r\n- `devel-latest` would get updated any time there was a push to either `main` or `dev`, and I don't think that's an intended behavior.\r\n\r\nWhat would you like the behavior to be?"
        },
        {
          "user": "sgoggins",
          "body": "@JohnStrunk : My first thought, which I acknowledge is perhaps uselessly vague, is to have the behavior be consistent with what other projects would use. I think matching user expectations is important. \r\n\r\nLeft to my own devices I think it makes sense to update devel-latest when changes are pushed to dev."
        },
        {
          "user": "JohnStrunk",
          "body": "ok. I think I understand the project branching model as (somewhat loosely):\r\n- New development goes into `dev`\r\n- At some point `dev` is merged to `main`\r\n- Releases are tagged from `main`\r\n\r\nWith the above, I think having `dev` map to `devel-latest` is fine, and only updating `latest` w/ a release is ok."
        },
        {
          "user": "JohnStrunk",
          "body": "Updated and ready for review.\r\nThis is targeted at main, but I *think* it will also need to be cherry-picked to `dev` in order for it to work on that branch as intended.\r\nI'm also happy to rebase this on dev and CP the other way, too."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3078,
      "author": "EngCaioFonseca",
      "created_at": "2025-03-19T22:47:18Z",
      "comments": [
        {
          "user": "cdolfi",
          "body": "@EngCaioFonseca squash commits pls"
        },
        {
          "user": "cdolfi",
          "body": "@sgoggins This will be a good PR to test with the new docker based test environment. Please do not merge until tested :)"
        },
        {
          "user": "sgoggins",
          "body": "I recognize this is duplicative @EngCaioFonseca ... The trick with this is sometimes Docker's behavior is inconsistent with regards especially to making the wheel library available, which is necessary for some of the container build steps."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3064,
      "author": "officialasishkumar",
      "created_at": "2025-03-17T18:04:29Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@officialasishkumar : What problem are we solving, or feature are we adding?"
        },
        {
          "user": "officialasishkumar",
          "body": "A live reload feature for docs, so that any changes can get reflected in the docs as soon as we edit it."
        },
        {
          "user": "MoralCode",
          "body": "I could see that being useful from a developer infrastructure perspective (and also help new contributors more easily make docs edits)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3076,
      "author": "MoralCode",
      "created_at": "2025-03-19T19:53:21Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@MoralCode : I've ignored this because its in DRAFT mode. Should we do it?"
        },
        {
          "user": "MoralCode",
          "body": "oh, uuh if its been causing issues then sure - or maybe at least for consistency?\r\n\r\n@cdolfi have you seen errors relating to this?"
        },
        {
          "user": "cdolfi",
          "body": "We are multiple iterations beyond this, can close"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3055,
      "author": "MoralCode",
      "created_at": "2025-03-14T03:38:02Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "ok, so this fix solves the narrow issue that cali reported.\r\n\r\nI have yet to confirm whether the `scorecard` binary has a similar issue.\r\n\r\n@cdolfi do you see any issues relating to scorecard processes in your augur instance? When does that run in relation to when fascade tries to run the `scc` binary?"
        },
        {
          "user": "cdolfi",
          "body": "Yes I do, the error is in #3052 . Facade in all cases I know of runs before secondary. The error also makes sense to be coming from this where it has nothing to reference to bc it failed while attempting. I logged the major bugs still in our instance at the same time, but getting this PR in will clear up a lot of errors for us to see what else is going on."
        },
        {
          "user": "cdolfi",
          "body": "Is this ready to go from draft to a full PR? I'm very pro small PRs that each tackle something"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3048,
      "author": "AllenHsm",
      "created_at": "2025-03-12T06:23:12Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@AllenHsm : What is the benefit to Augur users?"
        },
        {
          "user": "AllenHsm",
          "body": "> @AllenHsm : What is the benefit to Augur users?\r\n\r\nThanks for the question! I think DBT has the potential to make it easier for user to work with Augur data, because dbt enables users to build clean and reusable views, such that we do not have to write complex SQL every time. It also adds testing and is easier to scale analytics."
        },
        {
          "user": "sgoggins",
          "body": "@AllenHsm : thank you for addressing this issue! I am curious if there are some instructions for manifesting the \"hello world\" you could provide? (i.e., what are the steps for use? )"
        },
        {
          "user": "AllenHsm",
          "body": "> Could you provide some instructions on how to use this?\r\n\r\nOf course! Basically, users only need two commands:\r\n```bash\r\naugur dbt run\r\n```\r\nand\r\n```bash \r\naugur dbt test\r\n```\r\n## augur dbt run\r\nWhen users call `augur dbt run`, dbt will read the config, find the path to the `models` folder, and run all the sql files at this location. So it is the sql file in `models` that actually determines the behavior of dbt. \r\n\r\nBased on the sql codes, dbt will generate a `view` or `table` in Augur Postgres DB. In this hello world project, for example,  the only model `repo_activity.sql` calculates the total number of commits and issues for each repository, and stores the result as a physical table in Augur's DB (because in sql it claims `{{ config(materialized='table') }}`). \r\n\r\n## augur dbt test\r\nFor the test command, the _yml_ files under the `tests` folder make assertions about the results generated by models, and after running the test command, dbt will tell you whether the requirements are "
        },
        {
          "user": "sgoggins",
          "body": "@copilot\r\n\r\n> The DBT commands in the CLI functions include a manually specified '--profiles-dir' parameter while run_dbt_command already appends this flag using the computed profiles path. Consider removing the hardcoded '--profiles-dir' arguments from the CLI command invocations to avoid duplication and potential conflicts.\r\n\r\nI do not believe we can trust dbt to **accurately** compute the profile path to where we want it to be."
        },
        {
          "user": "sgoggins",
          "body": "@AllenHsm : So dbt would call this function in the hello world? Or would the materialized view be created automatically?"
        },
        {
          "user": "AllenHsm",
          "body": "> @copilot\r\n> \r\n> > The DBT commands in the CLI functions include a manually specified '--profiles-dir' parameter while run_dbt_command already appends this flag using the computed profiles path. Consider removing the hardcoded '--profiles-dir' arguments from the CLI command invocations to avoid duplication and potential conflicts.\r\n> \r\n> I do not believe we can trust dbt to **accurately** compute the profile path to where we want it to be.\r\n\r\nI just read it through and found that I have already resolved the profile path at line 26:\r\n`result = subprocess.run([dbt_executable] + command + [\"--profiles-dir\", dbt_profiles_path], check=True)`. So at line 35 when it calls run_dbt_command, it is duplicate to add the path again. \r\nI think it would be better to delete `+ [\"--profiles-dir\", dbt_profiles_path]` in line 26, because maybe line 35's call to run_dbt_command is more straightforward to understand and easier to modify."
        },
        {
          "user": "AllenHsm",
          "body": "@sgoggins Yes, when the user calls \"augur dbt run\", dbt will first look at `dbt_project.yml` and scan the path at line 15: `model-paths: [\"augur/application/dbt/models\"]`. After that, it executes all the sql files in the `models` folder."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3044,
      "author": "demoncoder-crypto",
      "created_at": "2025-03-09T01:48:50Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "Hello @demoncoder-crypto \r\n\r\nThank you for taking the time to contribute to Augur! I see that you have done many things in this PR, but I wanted to clarify a few points about the tracking issue https://github.com/chaoss/augur/issues/3041, and also to lay out some information about the branch structure of Augur.\r\n\r\nWhich branch should a PR target?\r\n---\r\n- With regards to when to merge into the _main_ branch, this is reserved for **critical security patches** and **hotfixes** (IE: bugfixes). \r\n- All new features and feature improvements unrelated to problems in production (IE: not a hotfix) must go into _dev_ first for preliminary testing. Only after testing is done on our various stakeholder deployment configurations, are changes in _dev_ released to main.\r\n\r\nWe welcome contributions in other parts of Augur unrelated to any particular feature you may wish to work on, but those contributions should each be made in a separate PR, and in their own individual branches (all taken from _dev_)"
        },
        {
          "user": "demoncoder-crypto",
          "body": "Thank you so much for such detailed response, I will start working on the things you mentioned and start improving it slowly. I really appreciate the feedback"
        },
        {
          "user": "demoncoder-crypto",
          "body": "I made my own tests to run them, i can push those tests too. I am so sorry for creating so much of a mess I will Try to fix it again if possible, otherwise you can decide it to close. If that works please let me know"
        },
        {
          "user": "Ulincsys",
          "body": "**Closing on recommendation**\r\n\r\nThe linked issue has been updated to include specific requirements for this interface. If you are still interested in contributing, we welcome you to open another PR, while keeping the following points in mind:\r\n\r\nScope\r\n---\r\nThe scope of your PR should be constrained to one particular feature, fix, or change. Making many small or otherwise disparate changes unrelated to the main goal of your PR will make it more difficult to review and approve.\r\n\r\nBranch\r\n---\r\nAny new feature branches for Augur, unless otherwise specified, must be based on *dev*, and must PR back into *dev* for testing. In the case of #3041, changes must be based on the *admin-changes* branch and PR back into *admin-changes*. Please review the expanded issue description for specific requirements if you are still interested in working on this issue.\r\n\r\nOther contributions\r\n---\r\nIf you are interested in working on other contributions in Augur, you are welcome to. Please just keep in mind"
        },
        {
          "user": "Ulincsys",
          "body": "This function is included from `augur.application.util`, and redefining it here is a logical error."
        },
        {
          "user": "Ulincsys",
          "body": "This function is included from `augur.application.util`, and redefining it here is a logical error."
        },
        {
          "user": "Ulincsys",
          "body": "How does this implementation improve upon the existing one?"
        },
        {
          "user": "Ulincsys",
          "body": "Repos are filtered on a per-user basis for logged-in visitors, and that functionality must not be removed."
        },
        {
          "user": "Ulincsys",
          "body": "How does this implementation improve upon the existing one? What are the reasons for the changes you have made here? Why has user-based filtering been removed?"
        },
        {
          "user": "Ulincsys",
          "body": "Why has the page title been removed?"
        },
        {
          "user": "Ulincsys",
          "body": "There is no such function on the User class called `get_by_login`, and that file was not updated in this PR to add it."
        },
        {
          "user": "Ulincsys",
          "body": "There is no such function on the User class called `check_password`, and that file was not updated in this PR to add it."
        },
        {
          "user": "Ulincsys",
          "body": "The root page of the application is configurable, and so it must not be hardcoded here."
        },
        {
          "user": "Ulincsys",
          "body": "Checking the `response_type` is part of the Oauth standard, and cannot be omitted."
        },
        {
          "user": "Ulincsys",
          "body": "Endpoints returning a non-view response should not go in this file, all routes in this file must return a view. Routes returning JSON data or any other non-view components should be placed in either `augur.api.view.api` or `augur.api.routes`."
        },
        {
          "user": "Ulincsys",
          "body": "Endpoints returning a non-view response should not go in this file, all routes in this file must return a view. Routes returning JSON data or any other non-view components should be placed in either `augur.api.view.api` or `augur.api.routes`."
        },
        {
          "user": "Ulincsys",
          "body": "Endpoints returning a non-view response should not go in this file, all routes in this file must return a view. Routes returning JSON data or any other non-view components should be placed in either `augur.api.view.api` or `augur.api.routes`."
        },
        {
          "user": "Ulincsys",
          "body": "The `User.get_groups()` function returns a tuple of `(Iterable[UserGroup], {\"status\": \"success\"})`. The second element of the tuple is not related to the user's favorites."
        },
        {
          "user": "Ulincsys",
          "body": "The `groups-table` template does not take a `favorites` argument, as `favorited` is already a column in the UserGroups table, so there is no need to separate the favorites out of the list of groups like this."
        },
        {
          "user": "Ulincsys",
          "body": "The `groups-table` template does not take a `favorites` argument, and that file was not updated in this PR to add it."
        },
        {
          "user": "Ulincsys",
          "body": "There are changes for this route that need to be merged from another branch, as this route is under development."
        },
        {
          "user": "Ulincsys",
          "body": "What is the purpose of adding these actions here?"
        },
        {
          "user": "demoncoder-crypto",
          "body": "You are right about this when working on this issue, I understood briefly about the codebase and made changes on the issues asking Ide without full consideration. It is indeed a logical error I will fix this immediately."
        },
        {
          "user": "demoncoder-crypto",
          "body": "My reasons for leaving/implementing it this way were:\r\nI was primarily focused on addressing the specific issues identified in the PR feedback and didn't critically evaluate all aspects of the code. I was trying to maintain the same behavior while fixing only the identified issues."
        },
        {
          "user": "demoncoder-crypto",
          "body": "I should have preserved the user-based filtering for repositories which is a key functionality. Looking at the code I implemented, I see that I didn't properly understand or maintain this important distinction."
        },
        {
          "user": "demoncoder-crypto",
          "body": "I made an assumption that the second element was related to favorites based on seeing references to favorites in other parts of the code."
        },
        {
          "user": "demoncoder-crypto",
          "body": "Looks like I completely misunderstood how favorite groups were handled in the codebase, I thought favorites needed to be processed separately. I messed up the status return value with favorites data."
        },
        {
          "user": "demoncoder-crypto",
          "body": "Understood."
        },
        {
          "user": "demoncoder-crypto",
          "body": "I thought additional show/hide logic was needed because i thought navigation system required explicit hide/show logic for each tab."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 3012,
      "author": "MoralCode",
      "created_at": "2025-02-23T14:03:39Z",
      "comments": [
        {
          "user": "MoralCode",
          "body": "after screenshot of podman history command, seems like the biggest users of space now are apt dependencies and the NLTK stuff.\r\n\r\n![Screenshot_20250225_210503](https://github.com/user-attachments/assets/cfad12c9-54cf-4d36-b3e5-df2011bf4eaa)"
        },
        {
          "user": "MoralCode",
          "body": "Im gonna mark this as ready since it seems like some or all of the things i mentioned as TODO's could be done later or arent necessary.\r\n\r\nAlso i'm not sure how to deduplicate with the graphical dockerfile architecturally/using the features of docker without having to build the non-graphical container into an image and \"import\" it using a `FROM`"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2996,
      "author": "Ulincsys",
      "created_at": "2025-02-13T18:49:46Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Ulincsys : Is there a reason this is still in draft mode? Do we want @GregSutcliffe to test this branch on his docker config?"
        },
        {
          "user": "Ulincsys",
          "body": "I'm not currently capable of running the docker build, ideally we would need **somebody** to test it before we push it to the main branch."
        },
        {
          "user": "sgoggins",
          "body": "OK. That makes sense. We will see if @GregSutcliffe has time and is comfortable doing that ... otherwise I will set out to test it in the morning."
        },
        {
          "user": "GregSutcliffe",
          "body": "I already tried just doing a COPY in my environment yesterday, and it didn't fix the issue I'm afraid."
        },
        {
          "user": "Ulincsys",
          "body": "Hi @GregSutcliffe \r\n\r\nI was able to (eventually) get Docker working on my end.\r\n\r\nI found that the version of Python we're using to run the Docker build does not seem able to import from a module which does not contain an `__init__.py`. We tested this on a few different versions of Python on bare-metal, and none of them complained about it! After adding that, I was able to run collection via Docker compose from a clean environment, and verified that the key orchestrator was running properly.\r\n![image](https://github.com/user-attachments/assets/b8c04186-a286-4e7e-810c-07ef281ffe2f)\r\n\r\nPlease let us know if you still have issues with the build, but otherwise I think this is probably good to patch into main."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2982,
      "author": "lpanni",
      "created_at": "2025-02-04T09:59:56Z",
      "comments": [
        {
          "user": "GregSutcliffe",
          "body": "This looks sane to me, I can test it when we are ready to redeploy after #2994 is fixed"
        },
        {
          "user": "lpanni",
          "body": "I haven't updated this in a while. Seems like most of the are obsolete after #3012 was merged. \r\nClosing this as this does not provide any benefit anymore."
        },
        {
          "user": "MoralCode",
          "body": "Was the intention here to move all the build steps up to the start so they could become a separate build container like in https://github.com/chaoss/augur/pull/2947?"
        },
        {
          "user": "lpanni",
          "body": "Not really, the intention was to move everything thats cacheable up, so that my local testing builds are faster.\r\nWhile doing that, I also noticed some duplicate statements and decided to cleanup the entire dockerfile to make it more understandable."
        },
        {
          "user": "sgoggins",
          "body": "@lpanni : In practice when I test Docker builts on Ubuntu versions and OSX versions (with and without apple silicon) I experience more consistent results with the duplication. It does not make sense to me either."
        },
        {
          "user": "lpanni",
          "body": "I had no problems on ubuntu, but couldn't test on macOS. Does this need further investigation?"
        },
        {
          "user": "JohnStrunk",
          "body": "> @lpanni : In practice when I test Docker builts on Ubuntu versions and OSX versions (with and without apple silicon) I experience more consistent results with the duplication. It does not make sense to me either.\r\n\r\nIn looking at the Dockerfile, one thing that's caught my attention is the use (or not, as the case may be) of `venv`. I think this may be a part of what's causing inconsistent results. Specifically, there's the line:\r\n```Dockerfile\r\nRUN python3 -m venv /opt/venv\r\n```\r\nwhich creates a venv, but we never actually activate it anywhere. the `/opt/venv/bin/pip install` commands do run the version of pip that exists inside the venv, but that's different from actually calling `activate`.\r\nIn my own experiments, I've looked at dropping the venv entirely and just installing onto the container's native python installation. The result is significantly different in terms of what gets built and installed."
        },
        {
          "user": "lpanni",
          "body": "@JohnStrunk yeah that's right, I didn't really think about that. Maybe this is an improvement still worth making, even if this PR is no longer relevant."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2981,
      "author": "lpanni",
      "created_at": "2025-02-03T10:33:46Z",
      "comments": [
        {
          "user": "GregSutcliffe",
          "body": "Can't comment on the Sillicon stuff, but :+1: on the rest"
        },
        {
          "user": "MoralCode",
          "body": "an additional change that could be useful in this PR (since changes are already being made to docker docs):\r\n\r\ni did notice that the docker build command on [this page](https://oss-augur.readthedocs.io/en/main/docker/docker.html) has a filepath slightly wrong (FYI im using podman on a debian based system), it should be:\r\n`$ docker build -t <tag_name> -f docker/<service name>/Dockerfile .` (i.e. removing the `util/` from the path to the dockerfiles.\r\n\r\nalso the three options available for subdirectories are now `backend`, `database`, and `rabbitmq` - `frontend` no longer exists"
        },
        {
          "user": "sgoggins",
          "body": "`environment.txt` is a template for the expected file `.env`"
        },
        {
          "user": "sgoggins",
          "body": "This tracks with improvements and changes recently made by @cdolfi . Thanks!"
        },
        {
          "user": "lpanni",
          "body": "Added a small explanation."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2947,
      "author": "Mbaoma",
      "created_at": "2024-11-06T15:34:32Z",
      "comments": [
        {
          "user": "GregSutcliffe",
          "body": "This looks pretty good to me for the most part - however, it looks like the dependency scripts (`RUN ./scripts/docker/install-workers-deps.sh` and `RUN ./scripts/docker/install-go.sh`) are no longer being run? I can see you are calling a `chmod` on them, but they no longer appear as a RUN - that might account for the speedup?"
        },
        {
          "user": "Mbaoma",
          "body": "@GregSutcliffe Thank you for catching that! Yes, that accounts for the speedup, as those scripts are typically resource-intensive. However, upon review, I ran the installation scripts in the `runtime` stage, to ensure the dependencies are installed before the application starts."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2902,
      "author": "Ulincsys",
      "created_at": "2024-08-27T22:23:55Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Does this only affect view?"
        },
        {
          "user": "sgoggins",
          "body": "Is this one just incorporating the latest from @ABrain7710 ?"
        },
        {
          "user": "Ulincsys",
          "body": "No, the changes are unrelated"
        },
        {
          "user": "Ulincsys",
          "body": "No, it previously would reset all log files globally. So now the log files will continue to exist after starting Augur"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2820,
      "author": "IsaacMilarky",
      "created_at": "2024-06-11T17:25:37Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Is this ready?"
        },
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky : Is this ready?\r\n\r\nYes sorry I think I forgot to make this a real PR."
        },
        {
          "user": "sgoggins",
          "body": "I think we want `fill_empty_affiliations` to still work."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2821,
      "author": "Preshh0",
      "created_at": "2024-06-13T23:17:50Z",
      "comments": [
        {
          "user": "geekygirldawn",
          "body": "I'm not sure how we should be handling the changes to the name of the metric within Augur, but @sgoggins or someone on the Augur maintainer team should be able to provide some guidance."
        },
        {
          "user": "Preshh0",
          "body": "Alright, @geekygirldawn."
        },
        {
          "user": "sgoggins",
          "body": "@Preshh0 : Unfortunately making this change will be a bit more work. I know for sure there are files in : \r\naugur/api and docs/ that will need to be addressed."
        },
        {
          "user": "Preshh0",
          "body": "Alrighty then. Do I close it entirely? Or leave it open and wait until whenever there is time to work on it? @sgoggins"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2815,
      "author": "Ulincsys",
      "created_at": "2024-06-10T02:59:23Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I made this a draft so we do not add it to the debugging stack on dev, which is pretty close to release."
        },
        {
          "user": "sgoggins",
          "body": "IS this the branch we want people checking out forever on Docker?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky ?"
        },
        {
          "user": "sgoggins",
          "body": "Why would this not be required?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2801,
      "author": "ABrain7710",
      "created_at": "2024-05-20T22:54:13Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : what's the status of this one?"
        },
        {
          "user": "ABrain7710",
          "body": "In progress. To make this work easier and the end result more reliable I'm working on improving the GithubPaginator in another branch. The GithubPaginator has needed improving for awhile"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : What's the status of this one with regards to testing? Should we merge it now that we have done a release."
        },
        {
          "user": "ABrain7710",
          "body": "This one is in progress and dependent on the GitHub paginator changes to work"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : Is this ready?"
        },
        {
          "user": "sgoggins",
          "body": "> This one is in progress and dependent on the GitHub paginator changes to work\r\n\r\nThose are the ones we are currently testing in `dev`, or that we released last week?"
        },
        {
          "user": "ABrain7710",
          "body": "No this is not ready. It is dependent on the changes that are in dev and needs some changes to use those"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2800,
      "author": "ABrain7710",
      "created_at": "2024-05-17T02:46:48Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : What's the status of this one with regards to testing? Should we merge it now that we have done a release."
        },
        {
          "user": "ABrain7710",
          "body": "This is complete, but I haven't had a chance to test it yet. It is a bit of a difficult test.It is a very small change though so if it was reviewed throughly it could be probably be merged"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2807,
      "author": "sgoggins",
      "created_at": "2024-05-23T10:22:27Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I am not sure what the review dog wants."
        },
        {
          "user": "sgoggins",
          "body": "Dear ReviewDog: Get over yourself."
        },
        {
          "user": "sgoggins",
          "body": "This is a spot where mapping variables started to confuse me."
        },
        {
          "user": "sgoggins",
          "body": "ibid"
        },
        {
          "user": "sgoggins",
          "body": "ibid"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2812,
      "author": "sgoggins",
      "created_at": "2024-06-07T15:10:16Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "There are some typos, mostly related to `absoulte` as a spelling for `absolute`, but lets just let it ride since the error is a variable name and consistent throughout. At least for this release."
        },
        {
          "user": "Ulincsys",
          "body": "This recursive function call passes more arguments than the function can take"
        },
        {
          "user": "Ulincsys",
          "body": "This recursive function call passes more arguments than the function can take"
        },
        {
          "user": "Ulincsys",
          "body": "Given that several recursive calls to this function pass a session variable, but a session is defined within the function at line 202, my assumption is that the recursive function calls need to be updated."
        },
        {
          "user": "Ulincsys",
          "body": "Should fix misspelling for clarity"
        },
        {
          "user": "Ulincsys",
          "body": "`logger` is a required positional argument for [this class initializer](https://github.com/chaoss/augur/blob/b2e9ea665f7f5071bc53b545ff4344f1fbe1e2f3/augur/tasks/github/util/github_task_session.py#L40)."
        },
        {
          "user": "Ulincsys",
          "body": "`logger` is a required positional argument for [this class initializer](https://github.com/chaoss/augur/blob/b2e9ea665f7f5071bc53b545ff4344f1fbe1e2f3/augur/tasks/github/util/github_task_session.py#L40)."
        },
        {
          "user": "Ulincsys",
          "body": "`logger` is a required positional argument for [this class initializer](https://github.com/chaoss/augur/blob/b2e9ea665f7f5071bc53b545ff4344f1fbe1e2f3/augur/tasks/github/util/github_task_session.py#L40)."
        },
        {
          "user": "Ulincsys",
          "body": "Should fix misspelling for clarity"
        },
        {
          "user": "Ulincsys",
          "body": "Should fix misspelling for clarity"
        },
        {
          "user": "Ulincsys",
          "body": "Should fix misspelling for clarity"
        },
        {
          "user": "Ulincsys",
          "body": "Should fix misspelling for clarity"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2790,
      "author": "sgoggins",
      "created_at": "2024-05-11T21:09:53Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "This specific change deals with an out of memory error generated by the PR Task for the 11 most massive repositories in the public collection of 104,000 repositories. In effect, it works like it did before UNLESS there are more than 200 PRs on a repo. Then it does the database commit every 200 PRs"
        },
        {
          "user": "sgoggins",
          "body": "Ratcheting up the number of secondary tasks processing at once."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2777,
      "author": "ABrain7710",
      "created_at": "2024-04-27T21:18:16Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "Is there a specific exception we can catch? What happens if some other exception occurs which doesn't necessitate a rollback?"
        },
        {
          "user": "ABrain7710",
          "body": "There wasn't a specific exception that I could find (if you can find one other than rolling back when we get the PendingRollbackException that would be awesome). I don't think calling rollback when nothing happened like during an operational exception should do anything."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2739,
      "author": "Ulincsys",
      "created_at": "2024-03-13T22:05:03Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "Oh I just saw that it checks the return code never mind."
        },
        {
          "user": "IsaacMilarky",
          "body": "We should probably set check to `True` here so it doesn't fail silently."
        },
        {
          "user": "IsaacMilarky",
          "body": "https://pylint.readthedocs.io/en/latest/user_guide/messages/warning/subprocess-run-check.html"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2734,
      "author": "IsaacMilarky",
      "created_at": "2024-03-12T15:26:38Z",
      "comments": [
        {
          "user": "decause-gov",
          "body": "Let's give a shoutout to Justin and the OSPO at Microsoft here :)"
        },
        {
          "user": "sgoggins",
          "body": "Shout out to Justin and Microsoft!! :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2719,
      "author": "IsaacMilarky",
      "created_at": "2024-02-26T20:24:35Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "It appears that controller.add_cli_repo has been removed"
        },
        {
          "user": "IsaacMilarky",
          "body": "Oh that was a typo when I was removing a test print statement before making the PR. My bad"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2684,
      "author": "GaryPWhite",
      "created_at": "2024-02-15T15:00:21Z",
      "comments": [
        {
          "user": "GaryPWhite",
          "body": "if we don't want the rabbitmq credentials to be out and about in the compose file, we may need to add something to the scripts that set up docker. Let me know if that's preferable, or if this is fine as-is!"
        },
        {
          "user": "sgoggins",
          "body": "@GaryPWhite : Our automated docker build seems to not like some aspect ... though I suspect this is an idiosyncracy that might be easily fixed? \r\n\r\n```\r\n#6 [2/4] COPY --chown=rabbitmq:rabbitmq augur.conf /etc/rabbitmq/conf.d/\r\n#6 ERROR: failed to calculate checksum of ref 625296d6-9be1-4356-a58b-91c3a8df5f0b::vijqe506c466y2g2arus31hxl: \"/augur.conf\": not found\r\n\r\n#7 [1/4] FROM docker.io/library/rabbitmq:3.12-management-alpine@sha256:28892f3ab8acefc71950a058dd50bace1cbbf28417649678180a2ce73995406f\r\n#7 resolve docker.io/library/rabbitmq:3.12-management-alpine@sha256:28892f3ab8acefc71950a058dd50bace1cbbf28417649678180a2ce73995406f done\r\n#7 sha256:f961ab691b2c344fffdc5ff90772bf0a5c011399ed1234e9c7bdce96fda9996c 3.28kB / 3.28kB done\r\n#7 sha256:28892f3ab8acefc71950a058dd50bace1cbbf28417649678180a2ce73995406f 8.86kB / 8.86kB done\r\n#7 sha256:13de8e3bac800bb3e2176bf8ab922eaf7380a6c4722024c7e0e98c3b41e84a9e 10.66kB / 10.66kB done\r\n#7 CANCELED\r\n------\r\n > [2/4] COPY --chown=rabbitmq:rabbitmq augu"
        },
        {
          "user": "sgoggins",
          "body": "> if we don't want the rabbitmq credentials to be out and about in the compose file, we may need to add something to the scripts that set up docker. Let me know if that's preferable, or if this is fine as-is!\r\n\r\nI think it would be optimal if we advised people to create a file called `env.list` that loaded the environment variables we ask for, and then also the RabbitMQ requirement variables. @GaryPWhite"
        },
        {
          "user": "GaryPWhite",
          "body": "no worries -- I can set that up!"
        },
        {
          "user": "GaryPWhite",
          "body": "> @GaryPWhite : Our automated docker build seems to not like some aspect ... though I suspect this is an idiosyncracy that might be easily fixed?\r\n```\r\n\r\nYeah seems likely that I missed something about how the CI builds / runs. I'll give it another swing."
        },
        {
          "user": "GaryPWhite",
          "body": "@sgoggins - I looked through documentation in the repo and tried to do this in a way consistent w/ the rest of the environment variables -- let me know if there's anything else you would like to see."
        },
        {
          "user": "sgoggins",
          "body": "@GaryPWhite : heyOH! Container builds on GitHub! W00t!!"
        },
        {
          "user": "GaryPWhite",
          "body": "awesome possum :) thanks for the guidance, Sean!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2678,
      "author": "IsaacMilarky",
      "created_at": "2024-02-08T14:43:00Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Is the question @ABrain7710 raised addressed? \r\n\r\n**The logic in ping_github_for_repo_move doesn't appear to be quite right. It appears to not be setting the repos that return a 404 (deleted repos) to a status of IGNORE. It throwing an excpetion for 404, succeeding if it the status wasn't a 301, and setting the repos that are 301 (moved) to IGNORE. We need to be setting 404s to IGNORE and erroring repos that are 301 so they can be retried**"
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins No the requested changes have not been addressed. I messaged Isaac and he agreed the logic is off"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2666,
      "author": "IsaacMilarky",
      "created_at": "2024-01-17T21:46:28Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "Example of Pylint check in use on this PR: https://github.com/DSACMS/metrics/pull/74"
        },
        {
          "user": "sgoggins",
          "body": "I am currently fixing the docs build error that exists across the board following readthedocs.io changes last week."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2665,
      "author": "sgoggins",
      "created_at": "2024-01-17T00:10:53Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : any idea why the docker builds are failing on the latest PR?"
        },
        {
          "user": "IsaacMilarky",
          "body": "Testing dev today I ran into issues using the cli. It wasn't recognizing the server subcommand so I couldn't run collection on macOS. It might be a mac issue but I can't verify that at the moment."
        },
        {
          "user": "sgoggins",
          "body": "> Testing dev today I ran into issues using the cli. It wasn't recognizing the server subcommand so I couldn't run collection on macOS. It might be a mac issue but I can't verify that at the moment.\r\n\r\nDo you mean the `backend` command?"
        },
        {
          "user": "IsaacMilarky",
          "body": "> Do you mean the `backend` command?\r\n\r\nI did not see that command being recognized either. I was also able to replicate this problem on my linux machine. It seems that only a fraction of the subcommands are being recognized.\r\n![Screenshot_20240212_104129](https://github.com/chaoss/augur/assets/24639268/8830e903-79ce-44fd-a774-70e902db6558)"
        },
        {
          "user": "IsaacMilarky",
          "body": "> > Do you mean the `backend` command?\r\n> \r\n> I did not see that command being recognized either. I was also able to replicate this problem on my linux machine. It seems that only a fraction of the subcommands are being recognized. ![Screenshot_20240212_104129](https://private-user-images.githubusercontent.com/24639268/304158867-8830e903-79ce-44fd-a774-70e902db6558.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDc3ODIxMzIsIm5iZiI6MTcwNzc4MTgzMiwicGF0aCI6Ii8yNDYzOTI2OC8zMDQxNTg4NjctODgzMGU5MDMtNzljZS00NGZkLWE3NzQtNzBlOTAyZGI2NTU4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAyMTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMjEyVDIzNTAzMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWU0YzExYzVhZDIxMDg1MjMyY2Y0Y2Y2YjFhMmFmNzRmNjg1NTM3ZGU1OWRlZmM5MTE1OWJhNzc5MWQ3NzE1OTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2572,
      "author": "IsaacMilarky",
      "created_at": "2023-10-30T17:42:47Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "> I think all the `engine.connect()` should be using a context manager to ensure the connection is being disposed of. I also don't think we should be removing valid relationships from the orm as this removes functionality without any benefit that I can see\r\n\r\nI made the suggested changes. I think the orm relationship thing should be resolved in a separate pr so I just reverted all of my changes to the orm relationships for now."
        },
        {
          "user": "Ulincsys",
          "body": "I think it's fine to merge for testing, but before this makes it into main, we need to ensure that the repo load controller gets updated with the below syntax (or something similar). This is just here for testing, and is not intended to be final"
        },
        {
          "user": "ABrain7710",
          "body": "I think we should use `with engine.connect()` to make sure all these connections are closed"
        },
        {
          "user": "ABrain7710",
          "body": "These are not redundant. `repo = relationship(\"Repo\")` still needs to be present on the UserRepo class to enable to ability to do UserRepo.repo and get back the related Repo object. Placing a relationship on the UserRepo relationship on the Repo class has no effect on the UserRepo class."
        },
        {
          "user": "ABrain7710",
          "body": "Similar to what I mentioned in another comment. I think we should use `with engine.connect()` to make sure the connection is disposed afterwards"
        },
        {
          "user": "ABrain7710",
          "body": "This should use the `conn` variable that is defined by the context manager"
        },
        {
          "user": "ABrain7710",
          "body": "This is still commented out"
        },
        {
          "user": "ABrain7710",
          "body": "Needs context manager"
        },
        {
          "user": "ABrain7710",
          "body": "Needs context manager"
        },
        {
          "user": "ABrain7710",
          "body": "Needs context manager"
        },
        {
          "user": "ABrain7710",
          "body": "Needs context manager"
        },
        {
          "user": "ABrain7710",
          "body": "This needs to stay in the secondary collection since it has a decorator of `@celery.task(base=AugurSecondaryRepoCollectionTask)\r\n`"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2564,
      "author": "kaxada",
      "created_at": "2023-10-30T12:56:33Z",
      "comments": [
        {
          "user": "kaxada",
          "body": "@sgoggins and @Ulincsys I think this solution suffices. WDYT?"
        },
        {
          "user": "Ulincsys",
          "body": "It should be merged into dev though, we typically don't merge directly into main"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2546,
      "author": "IsaacMilarky",
      "created_at": "2023-10-10T21:49:02Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky : Have we tested this with the 7 repo starting set to ensure that this branch generates commit data identical to the current method, and also clears out the working_commits table?\r\n\r\nI tested it with a single repo, I did not test it with all 7 starting repos. I will check the 7 starting repos after merging dev"
        },
        {
          "user": "sgoggins",
          "body": "Am I right that this is making everything map directly, allowing us to remove mapping code below?"
        },
        {
          "user": "sgoggins",
          "body": "What is happening here appears to be simply a refactoring of how working commits are trimmed. Basically putting it into a method. Is that right, @IsaacMilarky ?"
        },
        {
          "user": "sgoggins",
          "body": "Here down is the factored out trim_commits method, correct, @IsaacMilarky ... trying to make sure I understand what's happening."
        },
        {
          "user": "ABrain7710",
          "body": "Is it possible to detect an invalid timezone offset before doing the database insert? If so we should detect it in the analyze_commit method and have it update the timestamps to be the placeholder_date."
        },
        {
          "user": "ABrain7710",
          "body": "commit_record is not defined in this scope since it is outside the for loop"
        },
        {
          "user": "ABrain7710",
          "body": "commit_record is not defined in this scope since it is outside the for loop"
        },
        {
          "user": "ABrain7710",
          "body": "This insert needs to have the same error handling as below"
        },
        {
          "user": "IsaacMilarky",
          "body": "Yes exactly this also uses a bulk operation instead of sending a query for every commit to trim."
        },
        {
          "user": "IsaacMilarky",
          "body": "Yes mapping is not needed since I just use the table field names in this branch."
        },
        {
          "user": "ABrain7710",
          "body": "This appears to only take the last file encountered in the git log since the recordToInsert variable is being overwritten for each file found. I could be misunderstanding the parsing, but recordToInsert is be overwritten by the last call (the one outside the for loop) to generate_commit_record. So all the calls to generate_commit_record inside the for loop won't matter"
        },
        {
          "user": "IsaacMilarky",
          "body": "It should be possible from what I remember. You're right this change should be made."
        },
        {
          "user": "IsaacMilarky",
          "body": "Oh I don't know how I didn't notice that. I will make the method return a list next time with all of the files included."
        },
        {
          "user": "ABrain7710",
          "body": "This query to remove the working commits appears to be at the wrong indentation level, which might be causing silent issues"
        },
        {
          "user": "ABrain7710",
          "body": "I think this method might be cleaner if it took in the list of records and then tried to insert them. And if an exception occurs and the insert was on more than one row then we log the multiple record error message, and split in half then try again. But if an exception occurs and the number or records is 1 then we check if it a DataError exception and do all the logic and error logging for a single record insert. Put simply it moves the if len(records) == 1 into the exception block to determine what to log or how to react"
        },
        {
          "user": "IsaacMilarky",
          "body": "Yeah this should be indented will fix"
        },
        {
          "user": "IsaacMilarky",
          "body": "I implemented this change. I think it makes it slightly more readable"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2544,
      "author": "Shiva953",
      "created_at": "2023-10-07T06:49:50Z",
      "comments": [
        {
          "user": "Shiva953",
          "body": "@ABrain7710 any updates on this?"
        },
        {
          "user": "Shiva953",
          "body": "@sgoggins doneüëç"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2522,
      "author": "IsaacMilarky",
      "created_at": "2023-09-05T19:57:22Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky : Have we tested this branch?\r\n\r\nYes"
        },
        {
          "user": "ABrain7710",
          "body": "I don't think new_status should be a parameter that the constructor takes, since it is derivable from the name. And we aren't currently every passing it into the constructor we are either keeping the default parameter value or deriving it from the fact that it is a facade collection request.\r\n\r\nI don't think additional_conditions should be a parameter that the constructor takes either because we aren't using the value"
        },
        {
          "user": "ABrain7710",
          "body": "I think this should be extracted out into a function called get_active_repo_count(status). So the get_valid_repos method is easer to read without having to worry about how this sql query works"
        },
        {
          "user": "ABrain7710",
          "body": "Same thing with this as I mentioned above. This could be refactored out into get_users()"
        },
        {
          "user": "ABrain7710",
          "body": "I don't see where this function is splitting the user list into 4 sections"
        },
        {
          "user": "ABrain7710",
          "body": "I mentioned this below as well, but it appears the splitting of the list into 4 chunks isn't happening in this method call"
        },
        {
          "user": "IsaacMilarky",
          "body": "Agreed"
        },
        {
          "user": "IsaacMilarky",
          "body": "I think this would work well as a method for CollectionRequest"
        },
        {
          "user": "IsaacMilarky",
          "body": "Oh you're totally right this will be fixed"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2504,
      "author": "sgoggins",
      "created_at": "2023-08-28T05:24:38Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky \r\n@ABrain7710 \r\n\r\nI was surprised by how much more effective introducing randomization in all three places than in any one of them extended or eliminated periods where the API Rate Limit was exceeded. \r\n\r\nI tried each of them one at a time, and the triple shuffle has API key stops less than 1/2 the time as an single or combination shuffle. \r\n\r\nNOTE: This PR now also includes a fix to the repo_info task. Previously we were pulling the `main` branch commits (actually, it was worse than that: it was `master`), so we were missing about 25% of commit counts, and getting counts off of sometimes \"not the default branch\". Now its accurate, and on the default branch commit count, so the alignment with our facade commit counting will be perfect. This makes it a lot easier to accurately verify commit collection."
        },
        {
          "user": "sgoggins",
          "body": "> I'm unsure there is an issue with Github API keys being assigned randomly. I say this because the current implementation is as simple as it gets. We store a list of keys and assign a random key to every request we make. So unless the random.choice function isn't working, I don't think this is the issue.\r\n\r\nI noted this in my specific comments: but I went through several iterations trying to get all the data fully collected, and the three different shuffles occur at different points in execution and are causing key reuse at such a low rate that with a sufficient number of keys we hardly ever run out on a pretty large database. \r\n\r\nIndividually or in pairs, we reused the same key more often. So, if we think about how unpredictable job size will be, the fact that the triple approach is working with way less API key stalls, I think randomization is kind of an optimal way to do this; it worked really well on a large collection."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins I made an additional observation on the key rotation issue in the discord here: https://discord.com/channels/839539671671504907/915622840798158859/1146192017420996738"
        },
        {
          "user": "ABrain7710",
          "body": "This won't do anything because this isn't how we are getting the api keys from redis."
        },
        {
          "user": "ABrain7710",
          "body": "I believe the goal here is to randomize the order. If so random.shuffle should be used since Random.sample is used to get a random subset of a list. This will randomly order the list but it is less clear what the goal is"
        },
        {
          "user": "ABrain7710",
          "body": "This only gets executed the first time the GithubApiKeyHandler is created after that the keys will be stored in Redis so this function will return in the `if redis_keys` block."
        },
        {
          "user": "ABrain7710",
          "body": "I don't think this is needed as this is just going to randomize the order of the keys that are cached in Redis the first time the GithubApiKeyHandler is created. So this will just make the keys in Redis stored in a different order"
        },
        {
          "user": "sgoggins",
          "body": "spop does a randomized retrieval, while rpop does it in the order. The issue with using the order is that we will never know and don't want to try to know how big each job is before we do it. This balances out our key counts. I proved this by changing it and running it and seeing a HUGE gain in collection rate."
        },
        {
          "user": "sgoggins",
          "body": "In short, we get more durable randomness from random.sample than random.shuffle ... random.shuffle reorders the original list, but it does this in memory, it doesn't reorder what is stored in redis. random.sample does a \"better\" job of getting us novel keys from a list every time. I tested both, and was reusing the same key about 3x as often with shuffle compared to random.  \r\n\r\nFrom Here: https://blog.enterprisedna.co/python-shuffle-list/\r\n\r\nIt‚Äôs essential to note that the shuffle() function returns None and modifies the original list or [array](https://blog.enterprisedna.co/normalize-numpy-array/). Therefore, it‚Äôs unsuitable for cases where you must maintain the original list order.\r\n\r\nTo return a new [list ](https://blog.enterprisedna.co/how-to-generate-all-combinations-of-a-list-in-python/)containing elements from the original list without modifying it, you can use the [sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) function from the random lib"
        },
        {
          "user": "sgoggins",
          "body": "That's ok. What was happening is we'd always get them in table order, so by randomizing how redis is first populated we don't start with the same list, which makes the first hour of any restart go slower because it runs out of keys (at least going from previous, non-randomized configuration to the changes I made)."
        },
        {
          "user": "sgoggins",
          "body": "**That's ok. What was happening is we'd always get them in table order, so by randomizing how redis is first populated we don't start with the same list, which makes the first hour of any restart go slower because it runs out of keys (at least going from previous, non-randomized configuration to the changes I made).**"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2477,
      "author": "IsaacMilarky",
      "created_at": "2023-08-08T19:10:28Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Should I merge this into a copy of dev and test yet?"
        },
        {
          "user": "IsaacMilarky",
          "body": "Not yet I need to upgrade the pandas version and test it."
        },
        {
          "user": "sgoggins",
          "body": "> Not yet I need to upgrade the pandas version and test it.\r\n\r\nDon't be surprised if updating the pandas version requires you to then upgrade other libraries. I have tried \"doing them all\" and it causes a lot to break ... mostly because of the SQLAlchemy fix issues. \r\n\r\n\r\nYou *might* consider trying the setup.py (and setup.py for all the data_analysis tasks) from this branch: \r\n\r\nhttps://github.com/chaoss/augur/tree/dev-sqlalchemy-lib-updates\r\n\r\nI kept all the specified versions in comments, but basically took all the versions out ... DB stuff is all that seems to *not* work ... It would sort of be the \"extreme\" approach ... I could also merge your branch into it and back out the updates you made to setup.py ... \r\n\r\nIn fact, why don't I do that just in case it works. It won't hurt anything because the branch is dead without the SQLAlchemy updates."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2473,
      "author": "sgoggins",
      "created_at": "2023-07-25T21:44:46Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I'm thinking this commented out for your testing?"
        },
        {
          "user": "sgoggins",
          "body": "Same"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2476,
      "author": "Seltyk",
      "created_at": "2023-08-07T20:25:11Z",
      "comments": [
        {
          "user": "Seltyk",
          "body": "Further docs testing shows that if I set `type: array` the response schema looks fine but is described as an array. If I set `type: object` it doesn't show at all. The OpenAPI spec says that the schema object is a superset of JSON Schema, which defines both \"array\" and \"object\" as instance types. Interestingly, Augur's `spec.yml` doesn't appear to fit the OpenAPI documentation, but if that were the case, surely the docs wouldn't build correctly?"
        },
        {
          "user": "Seltyk",
          "body": "Another thought: this would make `/repos/:id` return more data per repo than `/repos`. This isn't dangerous, but it does mean inconsistency, which is not pleasant for frontends to parse. One of them ought to change."
        },
        {
          "user": "sgoggins",
          "body": "@Seltyk : What kind of environment did you test this against? I'm trying to decide if I should merge into dev, or create a different branch and take it for a spin soon one way or another."
        },
        {
          "user": "Seltyk",
          "body": "You might want to take it for a spin first, but the only *functional* change I made was adding an endpoint, so in theory it shouldn't have any issues going straight to dev"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2468,
      "author": "Seltyk",
      "created_at": "2023-07-10T18:38:27Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Seltyk : Let me know when you think this is ready."
        },
        {
          "user": "Seltyk",
          "body": "It *could* be called done now, but the `get_args` type hints contain a really nasty footgun (i.e. forcing every argument to be an `int`) which limits future scalability. Were we using a statically-typed language, having `get_args` accept a type argument would solve this issue, but since this is a Python project, some other solution probably needs to be found instead (unless Python has some weird implementation of generic types I can leverage). The other big problem is that input sanitization begins and ends at casting the `str` parameters to `int`s. Better than nothing, but it feels like a bad idea.\r\n\r\nThis whole PR was made under the assumption that the code written for it would only be used for the PR itself. That was a **terrible** assumption to make and I'm very disappointed in myself.\r\n\r\ntl;dr -- this can be merged now, because it already works, or I could take another crack at cleaning up my bad code. The obvious problem, of course, is that I don't know how soon I'll be able to d"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2474,
      "author": "Seltyk",
      "created_at": "2023-08-01T19:40:26Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "~~The equality method of `ClientApplication` should check that the `other` object is of the same class type as `self` before performing the ID comparison, and return `False` if it is not. Currently, if one were to try comparing it against an object without the `id` attribute, it would throw an exception.~~\r\n\r\nActually, I misunderstood the changes made here. `ClientApplication` is a subclass of the SQLAlchemy `declarative_base` class, which provides the functionality observed, the comparison should be correct. Also, the linter's output regarding `class.attribute == False` is not accurate for the same reason. The conditional in this instance returns a callable for use in `filter()`, it does not resolve to a boolean.\r\n\r\nReference for this behavior can be found here: https://docs.sqlalchemy.org/en/13/orm/query.html#sqlalchemy.orm.query.Query.filter"
        },
        {
          "user": "Seltyk",
          "body": "> `ClientApplication` is a subclass of the SQLAlchemy `declarative_base` class, which provides the functionality observed\r\n\r\nAt a glance, the `declarative_base` call chain never defines equality for its objects, and the docs don't mention equality or the `__eq__` method. That said, if it does define this equality, I'm getting `{\"status\": \"Invalid application\"}` when in theory I shouldn't. This PR was intended to address that issue, and in my testing, it does.\r\n\r\n> The conditional in this instance returns a callable for use in `filter()`, it does not resolve to a boolean.\r\n\r\nThere were two `== Bool` instances. One is `checkPassword`, which is the result of a function that returns a bool, so this one should be no issue. The other, which I think is what you mentioned, is `UserGroup.favorited`. I had to stare at it for a few minutes here, but I see what you're getting at now. I'll ~~file a bug report with Ruff and~~ revert that change.\r\n\r\nEDIT: there is already [a bug report](https://githu"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2472,
      "author": "Seltyk",
      "created_at": "2023-07-20T16:16:57Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "The doc updates look good to me. I'm not sure I understand what the SSL issue is you've mentioned? I'm able to authenticate with a client locally from an instance of augur served behind HTTPS."
        },
        {
          "user": "Seltyk",
          "body": "The Jinja template `authorization.j2` gives Flask the redirect target to handle temporary auth code generation to then be handed back to Jinja. From what I can tell, if that target lacks SSL (because, say, the redirect is to `http://localho.st`), [the endpoint rejects immediately](https://github.com/chaoss/augur/blob/dev/augur/api/routes/user.py#L74) and Jinja is left with a `{\"status\": \"SSL required\"}` object when [it expects an object with a `code` field](https://github.com/chaoss/augur/blob/dev/augur/templates/authorization.j2#L39). No `code` field means `data.code` is `undefined`.\r\n\r\nIt's possible this is my experience alone, but I'm puzzled that it happens at all."
        },
        {
          "user": "Ulincsys",
          "body": "The application's redirect URL is not considered as part of the request to generate a temporary auth code. As long as the user agent makes the request to the backend with https as the scheme, then the requirement for SSL should be met (assuming that the certs have been setup on the host).\r\n\r\nIf the instance of Augur you're querying is hosted behind a server like Nginx or Apache, you'll additionally need to make sure you have the following parameter set in your `sites-enabled` configuration under the location which targets the backend:\r\n```\r\nproxy_set_header        X-Forwarded-Proto           $scheme;\r\n```"
        },
        {
          "user": "Seltyk",
          "body": "Further testing reveals I'm actually getting a 426 from `/user/authorize` when I click the \"authorize\" button, which is not resolved by the nginx config you mentioned. `AUGUR_DEV=1` does fix the issue, however, which strongly implies there are some SSL shenanigans happening with my frontend. I will tweak my PR when the solution is found."
        },
        {
          "user": "Seltyk",
          "body": "4 days of confusion down to one little typo. Fixed in the latest commit. This doesn't solve the SSL thing mentioned above, but it solves another problem that had been lurking in my code the whole darn time."
        },
        {
          "user": "Ulincsys",
          "body": "If you have some time on Wednesday or Thursday @Seltyk I think it might help to meet via Zoom to resolve the SSL issue."
        },
        {
          "user": "Seltyk",
          "body": "I'm available until 16:00 EDT today and until 18:00 EDT tomorrow. GitHub says you're in CDT, so that should be easy to work out."
        },
        {
          "user": "Ulincsys",
          "body": "Let's plan for 3pm CDT Thursday. My work email should be visible on my profile page, if you'd like to reach out there we can arrange the meeting link."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2462,
      "author": "Ulincsys",
      "created_at": "2023-07-06T04:51:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Removing `User.py` smells wrong."
        },
        {
          "user": "sgoggins",
          "body": "Don't the Visualization endpoints rely on this method?"
        },
        {
          "user": "Ulincsys",
          "body": "User.py was the view-side wrapper for the User endpoints on the backend. Since the frontend and the backend now exist in the same app, this wrapper is no longer used.\r\n\r\nIt is a different file than the User.py file which holds the user-related backend endpoints"
        },
        {
          "user": "Ulincsys",
          "body": "No, the visualization endpoints do not rely on any methods in the fontend code.\r\n\r\nIf you are talking about the report page which uses the visualization endpoints, those use a different function for downloading and caching the images."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2455,
      "author": "Ulincsys",
      "created_at": "2023-06-28T05:57:46Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Ulincsys : This is still labeled \"in progress\". Is it ready to be merged? It should probably have dev merged into it and then get tested at this point."
        },
        {
          "user": "Ulincsys",
          "body": "We need abuse prevention mechanisms integrated into this before it can go live. The mail service integration works, but as it stands now a user can just force Augur to send unlimited mail requests."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2444,
      "author": "Ulincsys",
      "created_at": "2023-06-20T02:17:27Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : Can you check the DB stuff tonight?"
        },
        {
          "user": "sgoggins",
          "body": "@Ulincsys / @ABrain7710 \r\n@Ulincsys : Could you create a simple markdown doc explaining how to USE the API, with some examples, and what the endpoints are specifically? \r\n\r\n@ABrain7710 / @Ulincsys : Could we get the same for login. They are related and I actually don't know how to test any of this myself without that info. :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2409,
      "author": "IsaacMilarky",
      "created_at": "2023-05-15T17:45:12Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "I don't think we still need the `concurrency` config option, since we have `worker_process_vmem_cap` now"
        },
        {
          "user": "IsaacMilarky",
          "body": "You're right I didn't notice that"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2407,
      "author": "IsaacMilarky",
      "created_at": "2023-05-11T18:52:38Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I think this is good. Does celery reserve only a percentage of available memory. We wouldn‚Äôt want it to take it all."
        },
        {
          "user": "IsaacMilarky",
          "body": "It for sure won't take up all of the memory. I don't know the exact proportion at the moment given the custom celery settings we have."
        },
        {
          "user": "sgoggins",
          "body": "Can we add some checks to ensure there‚Äôs some kind of cap? Is the underlying issue that celery isn‚Äôt grabbing enough memory?"
        },
        {
          "user": "IsaacMilarky",
          "body": "I just added a flat 30% cap of the total memory to keep it simple."
        },
        {
          "user": "ABrain7710",
          "body": "I think 2 needs to be subtracted from `max_process_estimate` otherwise on small systems more than 30 percent of virtual memory will be used."
        },
        {
          "user": "IsaacMilarky",
          "body": "That makes sense. I made the change."
        },
        {
          "user": "ABrain7710",
          "body": "We need to either add a min of 1 to this, or return an error if that the system does not have enough memory to run Augur because a system with 8 GB of RAM with Augur configured to use 30 percent of virtual memory will currently run 2 scheduling processes, 1 core process, 0 secondary processes, and 0 facade processes. Note: With a 30 percent usage around 8.2 GB is what is needed to for 2 scheduling processes and 1 of all the others. At 20 percent usage 12.3 GB is needed"
        },
        {
          "user": "IsaacMilarky",
          "body": "I think we should bump it up to at least 40% and then add a minimum process of 1."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins was suggesting to drop the limit to 20% to account for the rabbitmq, redis, and database memory usage. I also don't think 40% is a reasonable number for larger servers where multiple instances are being run. With this, I think it should be configurable as a number between 0 and 1. Then we can just raise an error if not enough memory is allocated to it, and notify them to change the config. This allows for the flexibility of small systems where 1 augur instance is the only thing running, and larger systems where there are many instances running"
        },
        {
          "user": "IsaacMilarky",
          "body": "We already have a hard limit on the maximum level of processes each worker can have for larger instances. I think for now a default cap of 20-30% would be fine. I think it is a good idea to put the percentage in the config though."
        },
        {
          "user": "ABrain7710",
          "body": "Yeah I didn't notice that before, this sounds good to me"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2396,
      "author": "IsaacMilarky",
      "created_at": "2023-05-03T18:48:59Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I want @ABrain7710 to review this before we merge it."
        },
        {
          "user": "IsaacMilarky",
          "body": "> This LGTM .. with the assumption that something in here is deleting the old clone, and making a new one ... or moving the old one. Either way, we can't afford to have the old clones and the new clones both on disk. It would be too costly for augur users, and not something they expect. \n\nThe old clones are deleted and then cloned again via an alembic script."
        },
        {
          "user": "IsaacMilarky",
          "body": "> The only thing I see that needs added is a query that updates the core and secondary statues to pending if the issue_pr_sum is NULL\r\n\r\nThat makes sense. I have made the change"
        },
        {
          "user": "ABrain7710",
          "body": "I think this is parsing out the org / owner name so the variable name should be org or owner for clarity."
        },
        {
          "user": "ABrain7710",
          "body": "After thinking on this, I think it would be better if we just wrote a function in this alembic script that creates the new path with the repo id and path identifier. Then used a mv command to move the clone to the new directory. We should be able to do this because we already have the location of the facade directory, and we can tell which directories are old because they are directories that are just an integer (repo_group_id) rather than the new format which is an integer-string (repo_id-repo_path). I think this would make more sense to existing users, and all the facade repos wouldn't have to go back through the process of moving through statues (this isn't a huge deal it just clogs up facade for new repos until of these reset ones make it through which isn't ideal)"
        },
        {
          "user": "IsaacMilarky",
          "body": "That makes sense"
        },
        {
          "user": "IsaacMilarky",
          "body": "I didn't want to do this because we want to calculate the weight for old repos anyways and its not that much more to ask to add the cloning overhead to that weight calculation since it happens in the clone_repos method. Also depending on the configuration that people have on their instances moving each repo could take a long time which is unexpected for an alembic script."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : So, what do you think?"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky / @sgoggins What Isaac mentioned makes sense. If we are taking this approach with old repos for facade I think we should also update the core and secondary tasks so we ensure they compute the issue_pr_sum. To make sure we don't reset every repo on padres though we should only update core and secondary tasks to pending if the issue_pr_sum is NULL."
        },
        {
          "user": "ABrain7710",
          "body": "Just to be safe I think we should also set the task ids to NULL"
        },
        {
          "user": "IsaacMilarky",
          "body": "Made the change"
        },
        {
          "user": "ABrain7710",
          "body": "I think we should only run this on repos that don't have a commit_count or have a repos that are stored in the old structure. The reason being that I would like this script to reset all of facade on a huge instane if someone accidentally downgrades the database"
        },
        {
          "user": "IsaacMilarky",
          "body": "If they wanted to downgrade the schema it would be proper to also reset the facade repos again. We also can't check based on the commit_count because the revision before this one has commit_count without the directory change. I think it's fine how it is in my opinion."
        },
        {
          "user": "IsaacMilarky",
          "body": "I don't think it matters if someone accidentally clears their facade repos while downgrading the schema since it's so fast to clone."
        },
        {
          "user": "ABrain7710",
          "body": "Reply to first part: How would it be proper? I don't see why that would be the desired behavior. Usually in my experience downgrades are to bring the database back to the prior state, but resetting the repos doesn't do anything to reset to the old state. \r\n\r\nReply to second part: I think we can do it based on commit_count we would run it if the facade directory was wrong or the commit_count doesn't exist since they are both valid times to do it.\r\n\r\nReply to third part: I do think it matters, because although it is fast to clone, each repo still has to go through the collecting phase and if there are 22,000 repos that go reset and there collections finished instantly (since the commits exist) it would take around 6 hours for all the repos to get back through to success and this is not even considering the time to add all the tasks to the queue, and the time to clone."
        },
        {
          "user": "IsaacMilarky",
          "body": "> I do think it matters, because although it is fast to clone, each repo still has to go through the collecting phase and if there are 22,000 repos that go reset and there collections finished instantly (since the commits exist) it would take around 6 hours for all the repos to get back through to success and this is not even considering the time to add all the tasks to the queue, and the time to clone.\r\n\r\nThe only issue with this is that it sets all the repos to new but otherwise it doesn't really change the underlying behavior of facade. I do agree that people could see that as a problem though since people want to prioritize the newly added repos."
        },
        {
          "user": "ABrain7710",
          "body": "I approved because it does solve the problem. I'm just a bit apprehensive about doing this without conditions because it may not do what people would expect it to do when it is run multiple times"
        },
        {
          "user": "IsaacMilarky",
          "body": "> I approved because it does solve the problem. I'm just a bit apprehensive about doing this without conditions because it may not do what people would expect it to do when it is run multiple times\r\n\r\nI see the concern but I think any issue this alembic script might cause would be more of an inconvenience caused by not knowing facade repos are all being deleted. If we want to we can add a confirm prompt so that people are absolutely aware that their facade directories are being deleted. If we want to we can also mark the old repos or something so that they aren't re-collected as new."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2394,
      "author": "IsaacMilarky",
      "created_at": "2023-05-03T17:37:21Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky / @sgoggins  I don't think this was necessary, because repo is set to Failed Clone right before the `GitCloneError` is raised. Line 167 of repofetch.py does it"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I know it wasn't always working. I don't know if this patch solves that or not."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2369,
      "author": "IsaacMilarky",
      "created_at": "2023-04-28T19:00:31Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "So is this *only* going to run new repos?"
        },
        {
          "user": "ABrain7710",
          "body": "It will always run new repos first if they exist, and then if we didn't hit the max repo count when scheduling new repos we schedule more old repos until we hit the max repo count or if there aren't enough old repos (repos collected more than a day ago) we just schedule as many as we can"
        },
        {
          "user": "ABrain7710",
          "body": "I think changing `desired_status` to `status_column` would be more clear."
        },
        {
          "user": "ABrain7710",
          "body": "I think `weight` would be more descriptive variable name, because `sort=order` doesn't make much sense to me"
        },
        {
          "user": "ABrain7710",
          "body": "Why is the limit 2 times the usual amount in the queries?"
        },
        {
          "user": "ABrain7710",
          "body": "I think `valid_repo_ids` would be a more descriptive, `valid_repo_git_ids` isn't super clear to me, because the ids are of the repo not the `repo_git`"
        },
        {
          "user": "ABrain7710",
          "body": "I believe there should still be a check before starting old repos to see if the the limit is less than or equal to 0. To cover a case like this: The loop is in its last iteration and the limit is 5. Then 5 repos are started so the limit is 0. The loop then exits, so the limit check in the for loop is never reached to return. So it would continue on to start new repos even though the limit is 0"
        },
        {
          "user": "ABrain7710",
          "body": "Returning if the limit is less than of equal to 0 just like you do above in the new repos scheduling is much easier to read"
        },
        {
          "user": "ABrain7710",
          "body": "I think these queries should be factored out into a `get_user_list_repo_ids` function or something similar to that. Since they are doing the same thing they just have different statues."
        },
        {
          "user": "IsaacMilarky",
          "body": "That makes sense"
        },
        {
          "user": "IsaacMilarky",
          "body": "Because I thought that it made sense to query more than the desired limit before applying the additional conditions of the second orm query that actually gets the repo_git. Looking back I think it makes more sense to scrap the second orm query altogether and just pass in a string object that concatenates all the conditions and binds them to the query."
        },
        {
          "user": "IsaacMilarky",
          "body": "I agree. I'm nixing the redundant orm query"
        },
        {
          "user": "IsaacMilarky",
          "body": "It would return before it would start any repos. It would query the users table unnecessarily though"
        },
        {
          "user": "IsaacMilarky",
          "body": "That makes sense"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2362,
      "author": "ABrain7710",
      "created_at": "2023-04-27T14:29:03Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "Wouldn't we need to also add a check to when we are scheduling the clone phase to take into account the collecting repos on the clone side of the pipe? I think this general solution would work but I think this current setup allows more clones then what is specified in the function call."
        },
        {
          "user": "IsaacMilarky",
          "body": "I think adding the cloning as a periodic task will cause problems with cloning multiple things at once and with having multiple instances of this task active at once. The solution to this, in my opinion, is to make it so that the task schedules itself at the end of its loop when it runs out of repos to clone on a delay. That way, we would never run more than one instance of the task at once but we would still check for repos to clone every five minutes."
        },
        {
          "user": "IsaacMilarky",
          "body": "I think this task should re-schedule itself for five minutes in the future and exit in the event that there aren't enough repositories to clone. This way we will always check to clone repos at least every five minutes and we avoid having multiple instances of this task running at once"
        },
        {
          "user": "ABrain7710",
          "body": "Multiple instances of the same task at once isn't an issue, and it is actually desirable behavior, because if we have enough repos to initialize that a clone task is taking 5 minutes then it would be good to have another task to help finish them faster"
        },
        {
          "user": "IsaacMilarky",
          "body": "I just worry about the undefined upper bounds of how many tasks we are scheduling. I think it does make sense to have more than one task working to clone repos at a time but I would prefer if the amount of tasks cloning were predefined or at least had an upper limit of some sort."
        },
        {
          "user": "ABrain7710",
          "body": "Okay yeah that makes sense. I wasn't thinking about the case where the collection tasks are using all of the queue and the clone task has to wait until they are done to be processed"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2346,
      "author": "IsaacMilarky",
      "created_at": "2023-04-21T20:42:12Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "Wouldn't the core data last collected still be NULL when the `issue_pr_task_update_weight_util` runs, since core collection isn't done yet. I'm confused as to why updating the secondary and facade weights are done in similar ways, but core is completely different. Could we do it the same way for core?"
        },
        {
          "user": "IsaacMilarky",
          "body": "It is done in the same way for core. That chord is to update the issue and pr raw count from the primary tasks. The method at the end of the hook then updates it following the collection without updating the issue and pr raw count."
        },
        {
          "user": "IsaacMilarky",
          "body": "core_task_success_util updates the core weight and secondary weight in the same way as secondary_task_success_util. The call to issue_pr_task_update_weight_util is just to update the raw count"
        },
        {
          "user": "ABrain7710",
          "body": "Oh, I see now. That makes sense"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2339,
      "author": "IsaacMilarky",
      "created_at": "2023-04-20T20:37:43Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think it would be good if we listed out all the cases we are wanting to avoid. Then write a boolean expression that matches each case. Then all we would have to do is wrap each case in NOT and place an OR in between each. I'm having a lot of trouble going through and wrapping my head around these conversions and I think there are some errors. So I think it would be best if we used this simple structure of \r\nNot(invalid case) OR NOT(invalid_case) OR NOT(invalid_case) within each check"
        },
        {
          "user": "ABrain7710",
          "body": "I'm getting really confused on this check. Wouldn't this be the one case we want to restrict?\r\n`NOT(core_status = 'Pending' AND secondary_status='Collecting')`"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2333,
      "author": "mscherer",
      "created_at": "2023-04-20T14:20:06Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "This will cause an `ImportError`, because `logger` cannot be imported before it is created. It must be imported from `init` after `init_logging()` is called."
        },
        {
          "user": "Ulincsys",
          "body": "Closing as this has unresolved breaking changes. Please feel free to reopen if a resolution is reached."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2314,
      "author": "mscherer",
      "created_at": "2023-04-12T13:41:29Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "This is a good change however it should still catch any exceptions Path.mkdir raises and respond like how it did before when we didn't get a return code. It should update its internal logs when it is unable to create the directory."
        },
        {
          "user": "IsaacMilarky",
          "body": "Just put the mkdir line in a try/except block and put the body of the if statement on line 123 in the exception handle. Otherwise looks good."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2316,
      "author": "IsaacMilarky",
      "created_at": "2023-04-12T15:52:37Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky John and I thought of another issue. Whenever a repo has already been collected it will wait for 30 days till it collects again. The issue with this is at the end of the 30 days the weight of the repos will always be 0 since we are calculating the date weight by looking at the time since last collected. I think in this case when it is collecting again we just subtract 30 from the days since last collected so that it follows the same procedure as new repos do. Does this make sense? There are more details to this solution I briefly mentioned, but I think it is too complex to discuss in a pr comment"
        },
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky John and I thought of another issue. Whenever a repo has already been collected it will wait for 30 days till it collects again. The issue with this is at the end of the 30 days the weight of the repos will always be 0 since we are calculating the date weight by looking at the time since last collected. I think in this case when it is collecting again we just subtract 30 from the days since last collected so that it follows the same procedure as new repos do. Does this make sense? There are more details to this solution I briefly mentioned, but I think it is too complex to discuss in a pr comment\r\n\r\nI kind of like that idea. We could just make it so that if it has a timestamp of when it was last collected just subtract 30 from the days and calculate the weight that way. That would probably be the cleanest solution"
        },
        {
          "user": "sgoggins",
          "body": "I converted the PR to a draft just to make sure I don't merge it before intended."
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky Why was this `_broadcast_signal_to_processes` moved down. I may be missing something, but it doesn't appear functionally different, and it seems to separate the related code in the function `get_augur_processes` is for `_broadcast_signal_to_processes` and the list comprehension is for the if statement. This separates those relationships though"
        },
        {
          "user": "ABrain7710",
          "body": "Could we make this an orm query? Because it is so simple I don't see the need in using a raw sql statement"
        },
        {
          "user": "ABrain7710",
          "body": "What happens if collection runs and the `core_weight` is None?"
        },
        {
          "user": "ABrain7710",
          "body": "I don't see where the `RedisScalar` class is used?"
        },
        {
          "user": "IsaacMilarky",
          "body": "It was throwing errors when it was in the old order. I think this was because when the processes were being killed it was clearing the linux stat file which is what the process name was coming from. It was erroring almost every time before for me."
        },
        {
          "user": "ABrain7710",
          "body": "That makes sense. I don't think I ever ran collection after making that change"
        },
        {
          "user": "IsaacMilarky",
          "body": "It's not used. It was used in a previous commit on the branch though. It can be removed."
        },
        {
          "user": "IsaacMilarky",
          "body": "core_weight can be None. It just means that it is de-prioritized when sorting by core_weight."
        },
        {
          "user": "IsaacMilarky",
          "body": "That's fair."
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think we should add filters to this query so that it only returns the repos that can be scheduled (one's that have a collection date older than 30 days). This will make sure that we aren't calculating the repo weight for not reason and it ensures we don't have to deal with the number of days being negative.\r\n\r\nThis creates another issue though. If we don't update the weight until it is available to collect then when 30 days comes around it will have the same weight as when it was last collected. My first thought it to simply have this task make two queries. One for repos that are older than 30 days, and one for repos that are older than 28 days. For the older than 30 days repos we would keep the logic the same, but for the older than 28 days repo we could calculate the weight like it is 1 hour old. This would mean when 30 days comes around all the repos weights would be set like they are 1 hour old rather than the same weight they had when they were last collected. \r\n\r\n"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky / @ABrain7710 / @Ulincsys : What if, as I think I read suggested earlier, when we get to the end of any new repos, we just say \"work from less recently collected to most recently collected, plus or minus the other weighting factors\"? \r\n\r\nI may be oversimplifying .. conceptually thought this seems somewhat logical. Effectively, collection becomes continuous. \r\n\r\nYou are also free to ignore this comment entirely and carry on. :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2308,
      "author": "c0d33ngr",
      "created_at": "2023-04-09T12:28:02Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@c0d33ngr : We're keen to see the questions in the review address and merge this! :)"
        },
        {
          "user": "sgoggins",
          "body": "It looks like there is an indentation error for these three lines that need to be corrected."
        },
        {
          "user": "sgoggins",
          "body": "Does this handle cases, if applicable, where several imports are made on the same line?"
        },
        {
          "user": "sgoggins",
          "body": "Does this handle cases, if applicable, where several imports are made on the same line?"
        },
        {
          "user": "sgoggins",
          "body": "Does this handle cases, if applicable, where several imports are made on the same line?"
        },
        {
          "user": "sgoggins",
          "body": "Does this handle cases, if applicable, where several imports are made on the same line?"
        },
        {
          "user": "sgoggins",
          "body": "Does this handle cases, if applicable, where several imports are made on the same line?"
        },
        {
          "user": "sgoggins",
          "body": "We don't *think* rust allows multiple imports on one line like Python. We don't know about the other languages."
        },
        {
          "user": "c0d33ngr",
          "body": "Yes, I saw on GitHub but looks alright in my code editor(Neovim). I'll fix from GitHub web"
        },
        {
          "user": "c0d33ngr",
          "body": "Yes, rust don't allow multiple imports from a single line. I'm updating function"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2294,
      "author": "ABrain7710",
      "created_at": "2023-04-06T17:15:24Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "We should probably print an 'invalid command' message to stderr when this happens"
        },
        {
          "user": "ABrain7710",
          "body": "The `click` library already prints this by default.\r\n\r\nHere is an example when I put in `augur backen start`\r\n\r\nUsage: augur [OPTIONS] COMMAND [ARGS]...\r\nTry 'augur --help' for help.\r\n\r\nError: No such command 'backen'."
        },
        {
          "user": "IsaacMilarky",
          "body": "I gotcha that makes sense."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2285,
      "author": "IsaacMilarky",
      "created_at": "2023-04-04T18:07:10Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@sgoggins Can this be reverted? I think I accidentally left a comment rather than requesting changes. I would like those small things to be done before it is merged."
        },
        {
          "user": "ABrain7710",
          "body": "Need to use context manager with the `GithubTaskManfiest` to ensure everything is closed"
        },
        {
          "user": "ABrain7710",
          "body": "This function should be changed, so it takes `augur_db`, `logger`, and `repo_id` as arguments. The manifest class is not made to be passed around, it is made to be a utility class that makes it easier to create all the needed objects for a github task and that all those objects are closed properly."
        },
        {
          "user": "ABrain7710",
          "body": "Similar to above. This should take a logger, key_auth, url, and timeout_wait"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2264,
      "author": "sgoggins",
      "created_at": "2023-03-23T01:40:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "There is also a patch for the commits table here, setting the affiliation data to `NULL` instead of a string \"NULL\". The updates on the string \"NULL\" are very expensive."
        },
        {
          "user": "ABrain7710",
          "body": "I agree with @IsaacMilarky comment. Maybe like 40 processes for core and 15 for secondary? This would about triple the number of processes each worker"
        },
        {
          "user": "sgoggins",
          "body": "> \r\n\r\nI went with 30 for primary and 20 for secondary @ABrain7710 because secondary takes so much longer and core is always waiting for it to finish."
        },
        {
          "user": "IsaacMilarky",
          "body": "I'm slightly worried that this might crowd out the other task processes since facade shares a worker queue with the core task collection. Now that we are switching to having 50 processes available for the core worker we could do something like splitting it 50/50 by having start_tasks schedule 25 repos each for facade and core collection."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : OK. This makes a lot of sense. I did not understand that this was coming out of the core allocation. I will adjust."
        },
        {
          "user": "IsaacMilarky",
          "body": "Shouldn't we make the primary collection start 30 repos and then have facade collection start 30 repos to evenly distribute the available processes among the repos being scheduled since we have 60 processes? I would prefer to not put more messages on the queue than we need to and in this pr it is scheduling 85 repos at once for 60 processes. Especially since we aren't using eventlet anymore. Is there a reason we are scheduling so many repos at once?  We will still have to keep the messages for these repos in the queue bc of all the jobs we are doing for each repo but under this configuration we have like ~25 repos just sitting in the rabbitmq queue doing nothing and not even have a reason to be in the queue because none of those would have tasks being processed by the worker processes at that point."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Without that `AND cmt_ght_author_id is NULL` we are updating a *lot* more rows than we need to *every* time. I think this helps explain why the commits table started to bloat. I checked this with the following SQL `select * from commits where cmt_ght_author_id is NULL limit 1000` and \r\n```sql\r\nSELECT\r\n\t* \r\nFROM\r\n\tcommits \r\nWHERE\r\n  cmt_ght_author_id IS NULL AND\r\n\t( cmt_author_raw_email = 'dev@shardingsphere.apache.org' OR cmt_author_email = 'dev@shardingsphere.apache.org' ) \r\n\tLIMIT 10\r\n```\r\n\r\nWe will be skipping a significant number of costly updates."
        },
        {
          "user": "sgoggins",
          "body": "Put another way: Every time postgresql does an update on a row, it copies the row to new physical space that's slowly recovered with autovacuum. I strongly suspect that by updating every row, even if it was already populated, was creating a ton of dead rows on the commits table very quickly. My working theory is that this will fix this problem. I am going to test that theory around March 29."
        },
        {
          "user": "IsaacMilarky",
          "body": "We are scheduling 80 repos for 70 processes (60 on primary 20 on facade). I don't think we should do this. I think we _really_ should schedule a number of repos less than or equal to the number of processes we have. Otherwise we put things in rabbitmq when we don't have to. I think we shouldn't use rabbitmq if we don't have to bc large queue sizes have been an issue in the past."
        },
        {
          "user": "IsaacMilarky",
          "body": "That makes sense to me. This looks much better."
        },
        {
          "user": "IsaacMilarky",
          "body": "We should not schedule more repos than processes because it provides no benefit and can only cause issues, as we already have the information for that pending repo in the db. If we schedule more repos than processes we will have a repo in the rabbitmq queue doing nothing because it has no processes. Repos that are running still _have_ to use rabbitmq because there are multiple jobs per repo and it has to store the messages for these jobs in rabbitmq. And repos that don't have available processes should not have messages in rabbitmq"
        },
        {
          "user": "IsaacMilarky",
          "body": "In the future we should get the amount of repos to schedule from the amount of processes we have available and then divide them among the collection hooks. This way one repo gets one process. For now we can just hard code it I think."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2236,
      "author": "IsaacMilarky",
      "created_at": "2023-03-13T17:12:23Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "> The cases we are encountering include those where the repo has previously been cloned and counted, then goes away. How are these cases handled?\r\n\r\nFacade's status is different from the other tasks so this logic won't effect that. Right now if a repo can't be cloned or updated it has a status of \"Failed Clone\""
        },
        {
          "user": "sgoggins",
          "body": "When we get 404's we should probably do at least one retry before updating the description."
        },
        {
          "user": "sgoggins",
          "body": "What is the current equivalent of setting the status to 'New' for recloning? We should probably do that as well. Maybe its in here and we don't see it?"
        },
        {
          "user": "sgoggins",
          "body": "Maybe this is where a repo gets set to be recloned the next time?"
        },
        {
          "user": "IsaacMilarky",
          "body": "detect_move is only used for non-facade tasks. Facade has it's own logic to handle if repos can't be cloned. Facade set's the status to 'Failed Clone' if we can't clone it."
        },
        {
          "user": "IsaacMilarky",
          "body": "This updates the repo url with the one provided by github but it doesn't affect facade."
        },
        {
          "user": "IsaacMilarky",
          "body": "I agree I will implement that"
        },
        {
          "user": "sgoggins",
          "body": "What if its deleted after we have already cloned it and populated commits? Should we have a different status for that?"
        },
        {
          "user": "IsaacMilarky",
          "body": "I don't think it makes much of a difference. We could make an extra status, something like 'Stale', to be more clear about the repo's status in the database."
        },
        {
          "user": "sgoggins",
          "body": "I think the thing that's important is making sure we don't get a singular network issue that marks all the repositories some kind of \"stale'."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2235,
      "author": "JamesKunstle",
      "created_at": "2023-03-12T00:22:11Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I think we need to add this to the setup.py for the task. @ABrain7710 / @IsaacMilarky ?"
        },
        {
          "user": "IsaacMilarky",
          "body": "ast is builtin"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2233,
      "author": "sgoggins",
      "created_at": "2023-03-10T18:24:29Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 / @IsaacMilarky : I'm not sure what additional changes might be important for the next release. It seems the RabbitMQ issue on large, re-collection of data (15,000+ repos already collected and making the nth pass), where we sometimes lost communication is solved."
        },
        {
          "user": "IsaacMilarky",
          "body": "LGTM. I have been running a dev instance locally all day without any apparent issues"
        },
        {
          "user": "IsaacMilarky",
          "body": "This file should probably be renamed in the future considering we renamed the corresponding class. It's not worth holding up the pr to rename it though."
        },
        {
          "user": "IsaacMilarky",
          "body": "This is a typo the base class should be AugurSecondaryRepoCollectionTask. I made a new pr to address this issue: https://github.com/chaoss/augur/pull/2243"
        },
        {
          "user": "IsaacMilarky",
          "body": "Was this fixed?"
        },
        {
          "user": "IsaacMilarky",
          "body": "retrieve_all_clones_data and process_clones_data should be in the core.py file of the traffic directory ideally just for organizational reasons. Although, it should still work without these being in a separate file."
        },
        {
          "user": "ABrain7710",
          "body": "Yes, according to a message in discord"
        },
        {
          "user": "ABrain7710",
          "body": "There doesn't need to be function defined for this. That upgrades when upgrade is True and downgrades when it is False. Instead the upgrade logic should up put into the `upgrade` function and the `downgrade` logic should be put into the `downgrade` function."
        },
        {
          "user": "ABrain7710",
          "body": "Why are these changes put into `augur_full.sql` and not into a schema revision? I can't find anywhere `augur_full.sql` is even referenced"
        },
        {
          "user": "ABrain7710",
          "body": "Any specific reason why this machine learning worker uses `numpy>=1.22.0` when the other machine learning workers use `numpy==1.22.0`. Seems like if a new version of numpy is released this could break the insight worker since it would install the newest version"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think we should change this so all the dependency data is inserted all at once. So we aren't creating a database transaction for every single dependency that is processed"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think this should insert all the of data at once so we aren't opening up a database transaction for every single row"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think this should insert all the data at once so we aren't creating a database transaction for every piece of data"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I think this should insert all the data at once so we aren't creating a database transaction for every piece of data"
        },
        {
          "user": "ABrain7710",
          "body": "My plan was to rename it after we fully factor out the `GithubTaskSession` logic. Currently this file still contains the `GithubTaskSesssion` class so we can slowly convert over to using the `GithubTaskManifest` instead"
        },
        {
          "user": "sgoggins",
          "body": "I agree that sounds much better."
        },
        {
          "user": "sgoggins",
          "body": "No. @ABrain7710 : That is a ghost limb from how it was expressed before."
        },
        {
          "user": "sgoggins",
          "body": "agree"
        },
        {
          "user": "sgoggins",
          "body": "I agree."
        },
        {
          "user": "sgoggins",
          "body": "Yes. That would be faster and better."
        },
        {
          "user": "sgoggins",
          "body": "I'm not sure. They came in from a fork. Perhaps it was old?"
        },
        {
          "user": "sgoggins",
          "body": "OK. It works as it is now. I'm not against a change, but this is expensive time wise to test and validate, and I've done that for what's here."
        },
        {
          "user": "IsaacMilarky",
          "body": "Sounds good I will make this change"
        },
        {
          "user": "sgoggins",
          "body": "I have no strong opinions here. I think this person probably followed a random task example they encountered."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2227,
      "author": "IsaacMilarky",
      "created_at": "2023-03-09T01:11:21Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I think we are getting rid of many of the confusing different settings. yes?"
        },
        {
          "user": "sgoggins",
          "body": "Will taking this out of a try except cause the collection to fail in the case that a person is not identified?"
        },
        {
          "user": "sgoggins",
          "body": "I definitely want @ABrain7710 to review this file"
        },
        {
          "user": "IsaacMilarky",
          "body": "Yes some have been removed but not all. Delete_marked_repos particularly should probably be removed because we never remove repos."
        },
        {
          "user": "ABrain7710",
          "body": "No, because it uses `first` which will return None if it doesn't exist. Where `one` expects a row to exist"
        },
        {
          "user": "IsaacMilarky",
          "body": "No it will not."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2220,
      "author": "sgoggins",
      "created_at": "2023-03-07T21:09:31Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : I think I addressed this point by merging dev into this branch: https://github.com/chaoss/augur/pull/2220#discussion_r1131361291"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : I might have missed something. Getting this error at runtime... looking into it:\r\n```\r\n[2023-03-19 14:54:45,961: ERROR/ForkPoolWorker-1] Task augur.tasks.start_tasks.augur_collection_monitor[4a790a8d-e655-42d6-b599-337d5f4abc36] raised unexpected: NameError(\"name 'generate_facade_chain' is not defined\")\r\nTraceback (most recent call last):\r\n  File \"/home/sean/github/virtualenv/berkeley/lib/python3.8/site-packages/celery/app/trace.py\", line 451, in trace_task\r\n    R = retval = fun(*args, **kwargs)\r\n  File \"/home/sean/github/virtualenv/berkeley/lib/python3.8/site-packages/celery/app/trace.py\", line 734, in __protected_call__\r\n    return self.run(*args, **kwargs)\r\n  File \"/home/sean/github/berkeley/augur/tasks/start_tasks.py\", line 364, in augur_collection_monitor\r\n    start_primary_collection(session, max_repo=50, days=30)\r\n  File \"/home/sean/github/berkeley/augur/tasks/start_tasks.py\", line 231, in start_primary_collection\r\n    primary_augur_collection.start_data_collecti"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky / @ABrain7710 : What needs fixing here?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky / @ABrain7710 : is this ok?"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710  / @IsaacMilarky : Is this the right way?"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 / @IsaacMilarky : Is this the right way to do this?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky / @ABrain7710 : This looks right. Just checking."
        },
        {
          "user": "sgoggins",
          "body": "I think this is fine because to run our frontend, we do still need this file."
        },
        {
          "user": "IsaacMilarky",
          "body": "There should be a unique constraint on the repo_id if you plan on using postgres 'on conflict' inserts."
        },
        {
          "user": "IsaacMilarky",
          "body": "This function LGTM unless it's throwing errors."
        },
        {
          "user": "IsaacMilarky",
          "body": "If these changes to the releases table and the user_repos table are intentional then they should probably go in a separate revision. Alembic also sometimes adds spurious edits to the schema depending on the state of the database. Otherwise looks good"
        },
        {
          "user": "IsaacMilarky",
          "body": "The proper way to do this is with alembic which you did already. I would not do it this way."
        },
        {
          "user": "IsaacMilarky",
          "body": "Yep this is correct."
        },
        {
          "user": "IsaacMilarky",
          "body": "This is old and this new section needs to be removed."
        },
        {
          "user": "IsaacMilarky",
          "body": "collect_github_repo_clones_data should be moved into the repo_task_group group."
        },
        {
          "user": "IsaacMilarky",
          "body": "Are we using vue still? This looks pretty old."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 / @IsaacMilarky : They are using user_repos in the augur_operations schema as the foreign key. It would be more consistent with our current approach to make the repo table the foreign key."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : I merged from `dev` into this branch and I think that would fix this ."
        },
        {
          "user": "sgoggins",
          "body": "I did this, and then I realized this is like \"releases\", or repo_info... we want to hold the historical record for the repos. There should not be any conflicts since the primary key is an autoincrement @IsaacMilarky"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2191,
      "author": "gliptak",
      "created_at": "2023-02-25T02:59:49Z",
      "comments": [
        {
          "user": "gliptak",
          "body": "No particular issues, trying to augment the Python bump from the other PR. With that said, i don't see `docker run` in the logs, so the condition doesn't seem to be correct ... If you see this low value, please close the PR. As a follow-up, some sort of an integrity check could be implemented for all images/subsystems"
        },
        {
          "user": "sgoggins",
          "body": "@gliptak : Is this ready for review?"
        },
        {
          "user": "gliptak",
          "body": "@sgoggins as you have interest, i will work to figure out why `docker run` didn't trigger"
        },
        {
          "user": "gliptak",
          "body": "https://github.com/chaoss/augur/actions/runs/4380248052/jobs/7667102095\r\n\r\n```\r\n2023-03-10T01:06:09.8300879Z + docker run --rm --entrypoint /opt/venv/bin/augur ghcr.io/chaoss/augur_backend:latest --help\r\n2023-03-10T01:06:11.6556476Z ERROR no way to get connection to the database. \r\n2023-03-10T01:06:11.6557596Z \t\t\t\t\t\t    There is no db.config.json and the AUGUR_DB environment variable is not set\r\n2023-03-10T01:06:11.6558391Z \t\t\t\t\t\t    Please run make install or set the AUGUR_DB environment then run make install\r\n```\r\n\r\nmaybe `--version` flag could be added/ran as followup"
        },
        {
          "user": "gliptak",
          "body": "@sgoggins please review"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2188,
      "author": "gliptak",
      "created_at": "2023-02-24T02:45:37Z",
      "comments": [
        {
          "user": "gliptak",
          "body": "@sgoggins 3.10 was added based on build success (1.21.6 has the 3.10 wheels)"
        },
        {
          "user": "sgoggins",
          "body": "@gliptak @Ulincsys @ABrain7710 @IsaacMilarky : Merging this into `dev-ubuntu-test` branch and going to run on an EC2."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2186,
      "author": "IsaacMilarky",
      "created_at": "2023-02-22T19:00:56Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "> If I am understanding these changes correctly, it looks like Facade is still setting the repo_name and repo_path, it just doesn't depend on those fields to be in a certain state anymore. I think that we should be filling the repo_path and repo_name whenever a repo is added, so that we can be certain it existing since any repo that is added will have them set. The method to put this in is in called `insert` and is on the `Repo` class in the `augur_data.py` file.\r\n\r\nSounds good. I didn't know it was that simple with our orm setup."
        },
        {
          "user": "IsaacMilarky",
          "body": "> Do we still need the UPDATE query on line 96 of `facade05repofetch.py` that sets the `repo_name` and `repo_path`? Since we are inserting the `repo_name` and `repo_path` with every new repo. Also I think there should be a revision script that inserts the `repo_name` and `repo_path` for any repos that don't have the `repo_path` or `repo_name`\r\n\r\nI was reluctant to remove those updates since if we remove them we are trusting our regex to always match the way that we parse the repo name and path for every possible git url to the way that facade gets it from the git log. It should work without the update statements as long as we are mindful of these fields corresponding to facade's repo directory. I agree about the revision script I can add that."
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky Okay, so does this mean Facade still relies on the `repo_name` and `repo_path` it just doesn't depend on them being `NULL`? Also it seems if we are worried about the regex not producing the same results as Facade then we should put the way Facade is parsing it into a function, and then use that function in the `Repo.insert()` method and in the schema script. Then we would be confident that it is parsing them the way Facade needs them."
        },
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky Okay, so does this mean Facade still relies on the `repo_name` and `repo_path` it just doesn't depend on them being `NULL`? Also it seems if we are worried about the regex not producing the same results as Facade then we should put the way Facade is parsing it into a function, and then use that function in the `Repo.insert()` function and in the schema script. Then we would be confident that it is parsing them the way Facade needs them.\r\n\r\nFacade still needs to keep track of the file that it has cloned a repo from previously for how we are doing collection. We can't really do it the same way that facade does it when they are inserted since that relies on the git repo being cloned onto disk. It does python indexing and some regex to get the path and name once the repo has been cloned."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2184,
      "author": "IsaacMilarky",
      "created_at": "2023-02-21T15:52:59Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Does this make sense for me to test first?\r\nAlso, I think some docs about how the jobs are managed in facade would be helpful."
        },
        {
          "user": "IsaacMilarky",
          "body": "> I'm a bit confused with some of the changes. I thought we were going to have only the `facade_status` since the `repo_status` is only relating to Facade so it isn't really a `repo_status`. I'm now just confused as to why we need both. Couldn't we just have a `facade_status` that has values of (\"Pending\", \"Update\", \"Failed Clone\", \"Success\", \"Errored\")? I thought this is what we came to the other day.\r\n\r\nYou're right I'll make those changes. I think I just had forgotten that when I was making the clean_collection_status method since that resets the collection status of interrupted tasks to pending and from that I forgot to remove the repo_status field since that keeps track of the status of the git repo"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky This should only include, the changes that are needed for this pr. I can change this if you would like"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2159,
      "author": "ABrain7710",
      "created_at": "2023-01-28T16:36:40Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : What are your thoughts on the status of this PR?"
        },
        {
          "user": "sgoggins",
          "body": "This could possibly be the source of the connection bloating I am seeing at runtime, including high volumes of rollback transactions."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2143,
      "author": "sgoggins",
      "created_at": "2023-01-24T15:24:05Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Fixing this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/sean/github/virtualenv/ag3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1276, in _execute_context\r\n    self.dialect.do_execute(\r\n  File \"/home/sean/github/virtualenv/ag3/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 608, in do_execute\r\n    cursor.execute(statement, parameters)\r\npsycopg2.errors.UndefinedTable: relation \"augur_data.explorer_commits_and_committers_daily_count\" does not exist\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/sean/github/virtualenv/ag3/lib/python3.8/site-packages/celery/app/trace.py\", line 451, in trace_task\r\n    R = retval = fun(*args, **kwargs)\r\n  File \"/home/sean/github/virtualenv/ag3/lib/python3.8/site-packages/celery/app/trace.py\", line 734, in __protected_call__\r\n    return self.run(*args, **kwargs)\r\n  File \"/home/sean/github/ag3/augur/tasks/db/refresh_materialized_views"
        },
        {
          "user": "ABrain7710",
          "body": "This function isn't needed. You should just be able to call `add_materialized_views_15()` in the `upgrade()` and `downgrade()` functions"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I made the change. Good catch!  Can you tell I was copying one of your scripts without completely understanding how it works? I am learning to manage the schema in Alembic. ;)"
        },
        {
          "user": "ABrain7710",
          "body": "This needs to call `add_materialized_views_15()`"
        },
        {
          "user": "ABrain7710",
          "body": "This needs to call `add_materialized_views_15()`"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2144,
      "author": "sgoggins",
      "created_at": "2023-01-24T17:22:42Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I fixed the version related merge conflicts. So, technically the main branch is listed as a version ahead of where it really is during the period of review for this PR."
        },
        {
          "user": "sgoggins",
          "body": "I will not formally release the version until we are agreed that it is ready, FYI."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2139,
      "author": "sgoggins",
      "created_at": "2023-01-22T22:56:10Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "There should only be one downgrade function per schema script"
        },
        {
          "user": "ABrain7710",
          "body": "It doesn't look like this function is ever called"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2133,
      "author": "ABrain7710",
      "created_at": "2023-01-21T16:45:37Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@sgoggins I made some changes to the changes you made in commit `Strings with size zero throw errors`. The issue wasn't that the strings with size zero. The issue was with the if statements before hand. The if statement that checked if the key `name` exists did not check if the value wasn't None, while the if statement for the email did check for this. So I changed the code to use the dictionary method `get()` and `or` statements to fix the issue and make it more readable"
        },
        {
          "user": "sgoggins",
          "body": "If I was casting these are text its probably because the frontend relies on it... checking."
        },
        {
          "user": "sgoggins",
          "body": "I confirmed that we get an issue if we don't cast the result as text: \r\n```\r\n2023-01-21 16:34:20 linda augur.api.server[200488] ERROR Exception on /api/unstable/repos/61187/contributors [GET]\r\nTraceback (most recent call last):\r\n  File \"/home/sean/github/virtualenv/k12/lib/python3.8/site-packages/flask/app.py\", line 2073, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/home/sean/github/virtualenv/k12/lib/python3.8/site-packages/flask/app.py\", line 1518, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/home/sean/github/virtualenv/k12/lib/python3.8/site-packages/flask_cors/extension.py\", line 165, in wrapped_function\r\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\r\n  File \"/home/sean/github/virtualenv/k12/lib/python3.8/site-packages/flask/app.py\", line 1516, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/home/sean/github/virtualenv/k12/lib/python3.8/site-packages/flask/app.py\", line 1502, in dispatch"
        },
        {
          "user": "ABrain7710",
          "body": "Weird, I don't know anything about that. I'm assuming that this branch is just old and the old changes wrote over the dev changes. I can make that change really quick though"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2119,
      "author": "mscherer",
      "created_at": "2023-01-12T16:17:11Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Can you take a look at this one and let me know if you need an EC2 to experiment."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Can you look at this one as well?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2112,
      "author": "mscherer",
      "created_at": "2023-01-09T15:19:56Z",
      "comments": [
        {
          "user": "mscherer",
          "body": "Ok so I just tested it, and it doesn't fix the problem it seems :("
        },
        {
          "user": "mscherer",
          "body": "Or maybe that's my deployment who is incorrect. It work when i test manually, and it seems to still download the latest stable."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2105,
      "author": "sgoggins",
      "created_at": "2023-01-01T18:18:13Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : If you could fix the tests that would be great!"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : How much work is updating the tests to cover the new strategy?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2136,
      "author": "IsaacMilarky",
      "created_at": "2023-01-21T22:19:09Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky It appears this is more than just docs updates. Is there another pr that needs to be merged before this one so that the other changes are already is dev?"
        },
        {
          "user": "IsaacMilarky",
          "body": "> @IsaacMilarky It appears this is more than just docs updates. Is there another pr that needs to be merged before this one so that the other changes are already is dev?\r\n\r\nThose other changes were in this pull request: https://github.com/chaoss/augur/pull/2130. I do not know why they show up as new changes in this pull request."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2107,
      "author": "sgoggins",
      "created_at": "2023-01-01T19:06:03Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : don't we want to follow redirects?"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I think we also need to set repo_status='New', repo_path=NULL, and repo_name=NULL here."
        },
        {
          "user": "sgoggins",
          "body": "Presuming we are deleting everything, which is what it looks like .. then we'd be needing to also reset the repo in this way."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2098,
      "author": "meetagrawal09",
      "created_at": "2022-12-27T11:35:20Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I need to sit down with you to finish merging this. There's a schema change file that's out of order with work that happened since this was created."
        },
        {
          "user": "sgoggins",
          "body": "@meetagrawal09 : Could you make this a new file? I think if you look at the `dev` branch, the next sequence file would be `augur/schema/3_` (probably `3_traffic_additions.py`\r\n\r\nPay attention to the other files in that directory, as there are alembic-based forward and backward migration components."
        },
        {
          "user": "sgoggins",
          "body": "@meetagrawal09 : Same as note above, If you could make these changes part of a schema migration script that is preferable. If you need help figuring out how to do that, we can setup a chat."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I think this looks like the right place to do this .. can you confirm?"
        },
        {
          "user": "meetagrawal09",
          "body": "@sgoggins I have auto-generated the schema migration script from the model `RepoClass` that I had defined, using the command `alembic revision --autogenerate --rev-id \"3\" -m \"traffic additions\"` \r\n\r\nDo let me know if I need to do something more for `augur_full.sql`"
        },
        {
          "user": "meetagrawal09",
          "body": "@sgoggins can you please guide me as to what tool is used for schema migration scripts here or if the alembic version file generated would be the one sufficient."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2013,
      "author": "sgoggins",
      "created_at": "2022-10-25T19:11:41Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "This was a class demo PR."
        },
        {
          "user": "sgoggins",
          "body": "What is this file?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2014,
      "author": "witchtrish",
      "created_at": "2022-10-26T00:10:22Z",
      "comments": [
        {
          "user": "ABrain7710",
          "body": "I believe there is a missing * here on line 8"
        },
        {
          "user": "Preshh0",
          "body": "Here."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 2001,
      "author": "sgoggins",
      "created_at": "2022-10-06T00:19:26Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I think you can do everything we aren't waiting to hear from @IsaacMilarky about."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : Can you review this?"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I'm assuming this was your change. I think we may need a `/` at the end of the logs dir. I'd at least like to check and make sure before this is merged"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky I'm assuming this is your change. I think the logs dir may need a `/` at the end. I'd at least like to check before this is merged."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins or @IsaacMilarky: Can you catch the specific exception instead of the base Exception class?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky / @ABrain7710 : I confirmed there is a trailing slash when its stored in the database. That is working, so ... probably keep it."
        },
        {
          "user": "sgoggins",
          "body": "Confirmed. Trailing slash is stored as of today."
        },
        {
          "user": "ABrain7710",
          "body": "@ABrain7710 I need to change the revision id on this file"
        },
        {
          "user": "ABrain7710",
          "body": "@ABrain7710 I need to remove this file because it is obsolete"
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky Can we catch the specific exception here? Also in what case has this call thrown and exception?"
        },
        {
          "user": "ABrain7710",
          "body": "This cntrb natural keys needs to be `cntrb_id`"
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins I would like to change this to throw an exception when in development but not throw an exception during production. We can use @Ulincsys dev environment variable.  The only other option than that is to throw an exception in production and have people open issues when they get exceptions, but I don't think we want that."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins / @IsaacMilarky This should be `[\"repo_id\", \"gh_issue_id\"]` not `[\"issue_url\"]`. If a repo moves, the issue URL will change and we will get duplicate `gh_issue_ids` since the gh issue id stays the same, but the URL changes."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins / @IsaacMilarky This should be [\"repo_id\", \"pr_src_id\"] not [\"pr_url\"]. If a repo moves, the pr URL will change and we will get duplicate pr_src_ids since the pr src id stays the same, but the URL changes."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I don't know what the specific exception was ... @IsaacMilarky : Do you recall?"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : I fixed this."
        },
        {
          "user": "sgoggins",
          "body": "i.e., we don't need the runtime.py?"
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : What @ABrain7710 says here makes sense to me, and I am also wondering if there is a reason we need this to be the natural key. When we first get commit users we don't have the cntrb_login, so I think the cntrb_id is the \"unique thing\" ... let me know."
        },
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky : What @ABrain7710 is saying here makes sense to me."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : If we do not throw an exception does it simply not update the issue and move ahead? I will trust your judgement on this one. Do what you think should be done."
        },
        {
          "user": "sgoggins",
          "body": "I agree. I thought we changed this one already. ?"
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins Is this supposed to be merged in?"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : These are changes I made to correspond with changes in the alembic script .. or to signal necessary changes to the alembic script. I am not sure how to write those yet."
        },
        {
          "user": "ABrain7710",
          "body": "Exactly, I just removed it."
        },
        {
          "user": "ABrain7710",
          "body": "@IsaacMilarky Actually this is on the old, `config.py` file. I'm not sure why this was changed. I've simply kept this file around for reference."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins Yes, if we catch the exception, it will fail to insert the row, but the process will keep running. So, the issue assignees and labels will not be inserted, and the task will finish. If we do this for production instances and then raise the errors in development so we can fix them, it causes two things. First is a lot less user testing of the code because the errors are being squashed, and they are never notified of it, which means we are not notified. Second, we have to test a lot more because we won't get as many issues from people.\r\n\r\nI'm not saying I have a problem with this approach. This is actually the approach I like the most. I'm just stating that this requires us to do a lot more large-scale testing to find the weird bugs."
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins This is what I'm proposing.\r\n```\r\n        try:\r\n            issue_return_data = session.insert_data(issue_dicts, Issue, issue_natural_keys, return_columns=issue_return_columns, string_fields=issue_string_columns)\r\n        except IntegrityError as e:\r\n            logger.error(f\"Ran into integrity error:{e} \\n Offending data: \\n{issue_dicts}\")\r\n\r\n            if development:\r\n                raise e\r\n```"
        },
        {
          "user": "IsaacMilarky",
          "body": "This variable is not used and this file should be commented out as it is not used anymore."
        },
        {
          "user": "IsaacMilarky",
          "body": "The location of this file should be moved as per Andrew's suggestion.\r\n@ABrain7710"
        },
        {
          "user": "IsaacMilarky",
          "body": "File should also be moved @ABrain7710.\r\nWe should also create an /augur/util/ module."
        },
        {
          "user": "IsaacMilarky",
          "body": "This was meant to prevent an error in the docker collection. I need to go back and make it so that the docker image doesn't touch the open file limit because that doesn't work inside a docker container."
        },
        {
          "user": "IsaacMilarky",
          "body": "This shouldn't be here in the new version. I need to change it so that it re-raises the error."
        },
        {
          "user": "IsaacMilarky",
          "body": "I agree with this change I just think I never got around to implementing it."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1967,
      "author": "sgoggins",
      "created_at": "2022-09-02T22:06:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710  / @IsaacMilarky : I assume we should close this without merging?"
        },
        {
          "user": "ABrain7710",
          "body": "@sgoggins Yes this should be closed and not merged"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1968,
      "author": "Priya730",
      "created_at": "2022-09-04T05:36:52Z",
      "comments": [
        {
          "user": "Priya730",
          "body": "@Ulincsys please review this PR"
        },
        {
          "user": "sgoggins",
          "body": "@Ulincsys : Can you review this?"
        },
        {
          "user": "Priya730",
          "body": "> I think that the add user command will fail without adding the admin argument in the call to construct the `User` object (since that column has a NOT_NULL constraint). I see that the command line option for this was commented out.\r\n\r\nYes I realised that and was doing the same changes right now"
        },
        {
          "user": "Priya730",
          "body": "@Ulincsys  Can you confirm with me whether the current schema has admin? If yes, then I believe the changes for firstname and lastname in the PR will only be applicable."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1953,
      "author": "Priya730",
      "created_at": "2022-08-15T09:31:44Z",
      "comments": [
        {
          "user": "Ulincsys",
          "body": "The user endpoints should use the ORM to communicate with the database, consistent with the rest of the application.\n\nAdditionally the function decorators are not properly implemented on the endpoints. However, this regression was introduced in an external commit from another branch, and should be fixed there prior to merging."
        },
        {
          "user": "Priya730",
          "body": "@Ulincsys Please suggest improvements. Also, the function decorators are as per a previous commit on augur-new, so that is not changed. Should I import server if the implementation is complete?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1921,
      "author": "mscherer",
      "created_at": "2022-07-21T11:20:06Z",
      "comments": [
        {
          "user": "mscherer",
          "body": "converted to draft since for now, it doesn't build (at least on my laptop). I pushed so we can discuss the breakage (and I can exclude my laptop as a cause)"
        },
        {
          "user": "mscherer",
          "body": "I wonder if the error is linked to vue 4.0 ( https://github.com/vuedoc/parser/commit/8e8684a7c6bfcbb62b1077a07697f02caa69e009 )"
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : OK ... I have it down to failing on a fairly hairy missing file. Which is our fault."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1916,
      "author": "Preshh0",
      "created_at": "2022-07-11T23:29:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I actually think this line is a typo, @Preshh0 ... the image name is `A2.png`"
        },
        {
          "user": "sgoggins",
          "body": "@Preshh0"
        },
        {
          "user": "Preshh0",
          "body": "Line 12?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1912,
      "author": "Priya730",
      "created_at": "2022-07-08T05:34:26Z",
      "comments": [
        {
          "user": "Priya730",
          "body": "Current behaviour:\r\n![current](https://user-images.githubusercontent.com/60316903/179342991-b0a0aa04-6ea3-49a7-86dd-01817ea4dd1f.png)"
        },
        {
          "user": "sgoggins",
          "body": "@Priya730 : Is this ready to merge?"
        },
        {
          "user": "Priya730",
          "body": "@sgoggins Please review, branch ready to merge"
        },
        {
          "user": "Priya730",
          "body": "to work on: \r\nuse a different model instead of flag for admin, will be easy to differentiate between user and admin"
        },
        {
          "user": "Priya730",
          "body": "unnecessary line space"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1904,
      "author": "mscherer",
      "created_at": "2022-07-01T14:31:39Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@mscherer : Do you have an idea why the nginx / npm stuff is failing on GitHub. I assume its not failing locally for you. Can you think of any configs we may need to change?"
        },
        {
          "user": "mscherer",
          "body": "I think the issue was a js deps upgrade. I know my patch is not changing that, I will take a look and provides a patch."
        },
        {
          "user": "mscherer",
          "body": "So I can't figure (yet) what break the build. I tried using git bisest, but even old revision seems to fail, so either my hypothesis is wrong, or my git biest command was wrong."
        },
        {
          "user": "mscherer",
          "body": "So it build outside of the container on my Fedora 35 system."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1868,
      "author": "sa-tyam",
      "created_at": "2022-06-13T18:45:14Z",
      "comments": [
        {
          "user": "Preshh0",
          "body": "Hi @skdbsp123 thank you so much for writing a guide for mac os installation, I've been trying to figure out how to write one, and you did this. So, I really appreciate it. Thank you!"
        },
        {
          "user": "sa-tyam",
          "body": "> Hi @skdbsp123 thank you so much for writing a guide for mac os installation, I've been trying to figure out how to write one, and you did this. So, I really appreciate it. Thank you!\r\n\r\nYou're welcome @Preshh0"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1855,
      "author": "sgoggins",
      "created_at": "2022-06-08T23:24:02Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : The key in the config is no greater or lesser than the other keys. The issue right now is that in practice it is not rotating through the available keys."
        },
        {
          "user": "ABrain7710",
          "body": "I understand they have the same number of requests, but we should use the key in the config first, because more people are likely to be using the stored keys at the same time, so we don't want to run those out first, we would rather run the one in the config first since it isn't shared."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : If there's only the one in the config, its going to generate a random number of 1, and only hit that key. Everything still works if there's only the API key in the config. In practice the ones in the table are isolated to the organization running the instance. So all the keys have the same \"value\"."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : Right now, its simply not getting to all the keys before it goes kaput. In practice."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1865,
      "author": "mscherer",
      "created_at": "2022-06-13T17:00:49Z",
      "comments": [
        {
          "user": "mscherer",
          "body": "wait, I explicitely said the PR shouldn't be merged :("
        },
        {
          "user": "numberoneg",
          "body": "woops.\n\nOn Jun 13, 2022 at 12:57:14 PM, mscherer ***@***.***> wrote:\n\n> wait, I explicitely said the PR shouldn't be merged :(\n>\n> ‚Äî\n> Reply to this email directly, view it on GitHub\n> <https://github.com/chaoss/augur/pull/1865#issuecomment-1154215113>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AZQ2E4VK7AY3MGSCTDPQIM3VO5Y7VANCNFSM5YU37T3A>\n> .\n> You are receiving this because you are subscribed to this thread.Message\n> ID: ***@***.***>\n>"
        },
        {
          "user": "mscherer",
          "body": "That happen, just a bit suprising :) \r\n\r\nHere is the final fix I found: https://github.com/chaoss/augur/pull/1870, it was green during my test. \r\n\r\nAlso, I noticed that vue-vega is not maintained since 5 years, so maybe that should be changed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1839,
      "author": "sgoggins",
      "created_at": "2022-05-10T21:19:30Z",
      "comments": [
        {
          "user": "Dhruv-Sachdev1313",
          "body": "Hey @sgoggins, Sorry I am not updated with the recent changes in Augur, but would deleting the schema affect the libyear and scorecard?"
        },
        {
          "user": "sgoggins",
          "body": "@Dhruv-Sachdev1313 : I don't think I am deleting the schema. :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1813,
      "author": "Biki-das",
      "created_at": "2022-04-24T17:51:27Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Dhruv-Sachdev1313 : Could you have a look at this? _"
        },
        {
          "user": "Biki-das",
          "body": "> I don't think it would affect the working of the dependency worker, just feels like a more pythonic way of doing stuff! So LGTM.\n> \n\nYup it's a small minor improvement!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1797,
      "author": "Preshh0",
      "created_at": "2022-04-21T15:36:53Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Preshh0 : It looks like you've committed cloned repositories here: `[workers/facade_worker/augur_facade/](https://github.com/chaoss/augur/pull/1797/files#diff-5f4378d21bfc35284b8ded339112675299ed0738e7dec1eae541b123e58eb480)` ... Those cloned repos from our test repositories should not be committed to Augur source code."
        },
        {
          "user": "Preshh0",
          "body": "On it!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1794,
      "author": "Delight362",
      "created_at": "2022-04-20T23:56:00Z",
      "comments": [
        {
          "user": "ayushtamra",
          "body": "Hello @Delight362 thanks for your contribution at chaoss.\r\nWe have a DCO(which enforces [Developer Certificate of Origin](https://developercertificate.org/)) app installed in the repository\r\nSo for passing the check, you need to sign off your commits before making a pull request.\r\nYou can refer this, [Signing-off on Commits](https://github.com/chaoss/augur/blob/main/CONTRIBUTING.md#signing-off-on-commits)"
        },
        {
          "user": "Delight362",
          "body": "> Hello @Delight362 thanks for your contribution at chaoss. We have a DCO(which enforces [Developer Certificate of Origin](https://developercertificate.org/)) app installed in the repository So for passing the check, you need to sign off your commits before making a pull request. You can refer this, [Signing-off on Commits](https://github.com/chaoss/augur/blob/main/CONTRIBUTING.md#signing-off-on-commits)\r\n\r\nOkay it's should be signing-off on commits"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1793,
      "author": "Delight362",
      "created_at": "2022-04-20T23:46:44Z",
      "comments": [
        {
          "user": "oma131",
          "body": "Hi Delight, Do sign off your pul request so it can get merged."
        },
        {
          "user": "Biki-das",
          "body": "hey @Delight362 to sign off as @oma131 suggested, go to your current working branch,  type \r\n```\r\ngit commit --amend -s -m \"Your commit message\"\r\ngit push origin \"your branch name\" -f\r\n```"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1792,
      "author": "lylynaheng",
      "created_at": "2022-04-20T18:06:46Z",
      "comments": [
        {
          "user": "ayushtamra",
          "body": "Hello @lylynaheng , thanks for contributing to chaoss.\r\nWe have a DCO([Developer Certificate of Origin](https://developercertificate.org/)) app installed in the repository\r\nSo for passing the check, you need to sign off your commits before making a pull request.\r\nYou can refer this, [Signing-off on Commits](https://github.com/chaoss/augur/blob/main/CONTRIBUTING.md#signing-off-on-commits)"
        },
        {
          "user": "Biki-das",
          "body": "hey @lylynaheng  As  @ayushtamra  suggested to sign off commits, you can do that by going to your current working branch and type the following \r\n```\r\ngit commit --amend -s -m \"Your commit message\"\r\ngit push origin \"your branch name\" -f"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1774,
      "author": "singhavs",
      "created_at": "2022-04-18T22:28:07Z",
      "comments": [
        {
          "user": "oma131",
          "body": "Hello, please add a Sign-off yo your commit so it can be merged"
        },
        {
          "user": "singhavs",
          "body": "Hey! @oma131  I made some mere changes in this document but I have no idea from where these conflicts are coming."
        },
        {
          "user": "singhavs",
          "body": "Hey!@sgoggins, Kindly review the PR. Thank You!"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1770,
      "author": "Biki-das",
      "created_at": "2022-04-18T07:35:11Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "In this worker we are importing specific components of the libraries."
        },
        {
          "user": "Biki-das",
          "body": "ok will reverse the change"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1762,
      "author": "Biki-das",
      "created_at": "2022-04-16T08:33:56Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Biki-das : This broke our docker build."
        },
        {
          "user": "Biki-das",
          "body": "> @Biki-das : This broke our docker build.\n\nHmm.. Strange, :-("
        },
        {
          "user": "Biki-das",
          "body": "@sgoggins idk if this is breaking the docker build, my last two pr also showed a docker build failure, which were just mere typo fix and documentation changes"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1747,
      "author": "Biki-das",
      "created_at": "2022-04-14T15:01:30Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Biki-das : Please remove the edits to the pull_request_worker.py file."
        },
        {
          "user": "Biki-das",
          "body": "> @Biki-das : Please remove the edits to the pull_request_worker.py file. \n\nSure,üòÉ"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1744,
      "author": "preeti-14-7",
      "created_at": "2022-04-14T08:13:24Z",
      "comments": [
        {
          "user": "preeti-14-7",
          "body": "@sgoggins \r\nplease check it and looking for your suggestions"
        },
        {
          "user": "preeti-14-7",
          "body": "Hey Can I know why u closed this? or any suggestion so i can improve the documentation"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1722,
      "author": "Priya730",
      "created_at": "2022-04-11T07:20:31Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Priya730 : Please sign your commits: https://gist.github.com/xavierfoucrier/c156027fcc6ae23bcee1204199f177da"
        },
        {
          "user": "sgoggins",
          "body": "@Priya730 : please sign your commits: https://gist.github.com/xavierfoucrier/c156027fcc6ae23bcee1204199f177da"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1718,
      "author": "rooby786",
      "created_at": "2022-04-10T11:26:25Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@rooby786 : Please sign your commits\r\nhttps://docs.github.com/en/github-ae@latest/authentication/managing-commit-signature-verification/signing-commits"
        },
        {
          "user": "rooby786",
          "body": "> @rooby786 : Please sign your commits https://docs.github.com/en/github-ae@latest/authentication/managing-commit-signature-verification/signing-commits\r\n\r\n@sgoggins : Hi. i just sign in by following the instruction that you send me above. kindly guide me do i have to pull request again ?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1704,
      "author": "mscherer",
      "created_at": "2022-04-07T17:16:59Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@mscherer : Do you know why the docker images are private? Is there a setting to change on the repo, or to the script to make it public?"
        },
        {
          "user": "mscherer",
          "body": "Yes, I think there is. I did it once, but I think that was the doc I used https://docs.github.com/en/packages/learn-github-packages/configuring-a-packages-access-control-and-visibility"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1710,
      "author": "lylynaheng",
      "created_at": "2022-04-08T02:56:51Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@lylynaheng : Please sign your commits: https://gist.github.com/xavierfoucrier/c156027fcc6ae23bcee1204199f177da"
        },
        {
          "user": "lylynaheng",
          "body": "@sgoggins I am not sure how to sign commit from GitHub Desktop. I followed the steps in the link, but it doesn't say anything about sign commit from GitHub Desktop."
        },
        {
          "user": "sgoggins",
          "body": "@lylynaheng : Try this link: https://docs.github.com/en/github-ae@latest/authentication/managing-commit-signature-verification/signing-commits"
        },
        {
          "user": "lylynaheng",
          "body": "I double check the signed document on GitHub and I believe that my commits are signed and verified. \r\n\r\n![Screen Shot 2022-04-12 at 2 06 22 PM](https://user-images.githubusercontent.com/8085196/163054672-7bbabefb-d88a-4717-8d18-14bb85f6a0b7.png)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1699,
      "author": "lylynaheng",
      "created_at": "2022-04-07T03:33:16Z",
      "comments": [
        {
          "user": "lylynaheng",
          "body": "> @lylynaheng and @sgoggins We could add relevant links to the website and augur instance\r\n\r\nI can't find the Augur instance in the CHAOSS or anywhere, so it either a work in progress or not exist yet."
        },
        {
          "user": "lylynaheng",
          "body": "> @lylynaheng there is a link missing in the last sentence of this paragraph here. most probably a link to the metrics\r\n\r\nThanks for the comment. Links are updated."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1695,
      "author": "mscherer",
      "created_at": "2022-04-05T15:20:08Z",
      "comments": [
        {
          "user": "mscherer",
          "body": "It seems that the CI fail because the build fail (a issue on npm that I am not sure to be able to debug)."
        },
        {
          "user": "mscherer",
          "body": "I fixed a bug on the naming of the container, and I ignore the frontend for now"
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : The Docker build in the test is failing. Which may mean something or it may not. \r\n````\r\nThe command '/bin/sh -c npm run build' returned a non-zero code: 1\r\n```\r\n\r\nIt looks like its being built with React? I know we previously were using NPM, setting the version to the latest of 12.22.x .."
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : Maybe I should've seen you already noticed that."
        },
        {
          "user": "sgoggins",
          "body": "OK... I think I see what is happening."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1690,
      "author": "diananova",
      "created_at": "2022-04-01T21:49:16Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "We actually do want users to update their own forks."
        },
        {
          "user": "diananova",
          "body": "But wouldn't they use `origin` remote for that? Setting the central repo as upstream would help contributors always be in sync with the latest changes."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1686,
      "author": "flyagaricdev",
      "created_at": "2022-04-01T15:26:17Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "We actually do want this to point to the users username, not `chaoss/augur`, as its supposed to point to a fork."
        },
        {
          "user": "flyagaricdev",
          "body": "Thanks for the clarification @sgoggins! I'll also consider this for new PR's."
        },
        {
          "user": "flyagaricdev",
          "body": "I've updated the pr with your correction @sgoggins :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1658,
      "author": "sgoggins",
      "created_at": "2022-03-22T12:04:04Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "This script has been run against all existing Augur instances."
        },
        {
          "user": "ABrain7710",
          "body": "The foreign key from the  pull_request_reviews table to the pull_requests table still has on delete restrict on it, which I believe needs to be on delete cascade\r\n\r\nThe foreign key from the  issue_labels table to the issues table still has on delete restrict on it, which I believe needs to be on delete cascade"
        },
        {
          "user": "sgoggins",
          "body": "> The foreign key from the pull_request_reviews table to the pull_requests table still has on delete restrict on it, which I believe needs to be on delete cascade\r\n> \r\n> The foreign key from the issue_labels table to the issues table still has on delete restrict on it, which I believe needs to be on delete cascade\r\n\r\nI made this change by having two sequential, now identical database scripts. Its a little weird, but since I upgraded all the live databases with the original, this was the best way not to cause an upgrade path mess."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1668,
      "author": "rooby786",
      "created_at": "2022-03-26T11:04:35Z",
      "comments": [
        {
          "user": "diananova",
          "body": "\"a once-over\" is correct, no need to change it."
        },
        {
          "user": "sgoggins",
          "body": "The grammar is tricky, but it is actually correct how it is. \r\n\r\nhttps://www.quickanddirtytips.com/education/grammar/a-versus-an"
        },
        {
          "user": "sgoggins",
          "body": "\"a\", not \"an\" is grammatically correct in this case."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1641,
      "author": "mscherer",
      "created_at": "2022-03-02T17:48:00Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@mscherer : tracking identities .. you are the person who is installing for San Diego that I zoomed with? Sorry. :)"
        },
        {
          "user": "mscherer",
          "body": "@sgoggins yep, that's me. Forgot my profile was private, so you can't see my orgs nor my name :/\r\n\r\nAnd yes, I finally deployed the proxy we talked about, but index.html point to server.tld/augurface/foo.js, while we serve them directly from the root directory. I can work around using configuration magic, but figured this would be easier.\r\n\r\nBut if that's supposed to be consumed by more than just our instance, I guess I need to propose another fix."
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : It would be better for Augur if we kept the `/augurface` path in the URL, simply because there's another interface served up at `/` .. Is that possible."
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : I will merge this and we can see what happens."
        },
        {
          "user": "sgoggins",
          "body": "@mscherer : This change makes me wonder if you are running `augurface` with the intention of having it be Augur's primary frontend, or if you are using it to load repos (which is what it is for, and its not quite right/perfect yet.).  The main frontend is in the `frontend` directory. \r\n\r\nThere is also another project, https://github.com/chaoss/augur_view that we are developing new frontend \"stuff\" in."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1630,
      "author": "IsaacMilarky",
      "created_at": "2022-02-22T23:37:01Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I will test that this works in high volume cases."
        },
        {
          "user": "sgoggins",
          "body": "Awesome!"
        },
        {
          "user": "sgoggins",
          "body": "I will test this."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1603,
      "author": "Dhruv-Sachdev1313",
      "created_at": "2022-01-28T08:50:50Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@Dhruv-Sachdev1313: Is this ready?"
        },
        {
          "user": "Dhruv-Sachdev1313",
          "body": "@sgoggins The code is ready. I just have to test it once. If it breaks, I will add a fix and ping you for the review on slack! üôÇ"
        },
        {
          "user": "sgoggins",
          "body": "@Dhruv-Sachdev1313 : Any chance this is complete3?"
        },
        {
          "user": "Dhruv-Sachdev1313",
          "body": "Hey @sgoggins: I got caught up with some stuff! Looking at this first thing this weekend! I will update you soon"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1610,
      "author": "ABrain7710",
      "created_at": "2022-02-03T01:52:31Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Any reason to remove the `int` cast? I have noticed sometimes python does not do type conversion the way we expect, though that's from APIs we pull from, not our own APIs. Just asking."
        },
        {
          "user": "sgoggins",
          "body": "is the none, none, none API return set what generates the \"Hey, you need a repo ID there pardner?\" message."
        },
        {
          "user": "sgoggins",
          "body": "Seems to be \"yes\" to my prior question."
        },
        {
          "user": "sgoggins",
          "body": "is this simply a convention change, or is It fixing an error. LGTM, I just want to make sure I understand the change. \r\n\r\nDoes it change the name of the existing endpoint? If so, @Ulincsys is relying on the current names and we probably need to also provide a legacy alias."
        },
        {
          "user": "sgoggins",
          "body": "Same note as above."
        },
        {
          "user": "sgoggins",
          "body": "Same question about int casting. I'm just asking to make sure I understand. My guess is you have tested it, and it is not necessary. So, then no problem."
        },
        {
          "user": "sgoggins",
          "body": "What happens if somebody provides a start date, but not an end date? Is it defaulted to \"now\" elsewhere?"
        },
        {
          "user": "ABrain7710",
          "body": "If 'repo_id' is in the request.args array is None (which means it isn't specified in the query parameters), casting it to an int would result in an error because you cannot cast None to an int. Therefore I moved the cast to after I've checked if the 'repo_id' is specified in the request.args array"
        },
        {
          "user": "ABrain7710",
          "body": "Yes, basically if the repo_id is not in the query params, then it returns None for all return variables. I could have just returned None, but I decided to still return None for the start_date and end_date too."
        },
        {
          "user": "ABrain7710",
          "body": "Yes"
        },
        {
          "user": "ABrain7710",
          "body": "This is simply a change to the method name to match the API endpoint path. It will not change the existing endpoint."
        },
        {
          "user": "ABrain7710",
          "body": "Yep, it is just a change so the method name matches the current API endpoint path"
        },
        {
          "user": "ABrain7710",
          "body": "Yes, it is casted in the return statement, after I've confirmed that it isn't a None type, because trying to cast a None type to int will return an error, and give the user a 500 server error"
        },
        {
          "user": "ABrain7710",
          "body": "If someone provides a start date but no end date, the end date defaults to now. This made me think that I should add an error check to make sure the start_date is before the end_date though."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1548,
      "author": "IsaacMilarky",
      "created_at": "2022-01-05T18:26:53Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I have seen stalling on heavily taxed machines. Are you seeing this only in the facade worker resolution or elsewhere?"
        },
        {
          "user": "IsaacMilarky",
          "body": "I haven't seen it elsewhere yet and it hasn't happened with facade when I have been testing it most recently. I think that comment might be talking about a bug that has since been squashed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1542,
      "author": "sbrennan98",
      "created_at": "2021-12-20T23:24:53Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@sbrennan98 or @ABrain7710 or @IsaacMilarky : We need to test that this will run on a dev machine for a developer who runs the frontend using `npm run serve` ... I think it does, but would like some confirmation. \r\n\r\n@Ulincsys : We would also need to update `augur_view` to hit https endpoints. \r\n\r\n@ABrain7710 : Anything that can be scripted on install would be great."
        },
        {
          "user": "ayushtamra",
          "body": "@sgoggins does this needs contribution? I saw this on the [projects top priorities list](https://github.com/chaoss/augur/projects/9#card-77193923)"
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : This is the section of the code with the merge conflict. @sbrennan98 has a useful comment when you look at the merge conflict, and I think its these conditions where the install script may need to be modified. If we could script generating a certbot certificate (I'm not sure we can, or that its worth the labor), then we may want to use config variables for HTTP or HTTPS."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1434,
      "author": "sgoggins",
      "created_at": "2021-08-18T13:04:26Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@IsaacMilarky and @ABrain7710 : I copied the worker_* shared libraries from libyear-test, which was based on main as of about a week ago. The number of differences confuses me a little."
        },
        {
          "user": "sgoggins",
          "body": "We do get emails when we query contributors though, don't we @IsaacMilarky ?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1388,
      "author": "IsaacMilarky",
      "created_at": "2021-07-27T19:13:44Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I think we need to resolve the issue with contributors first, right?"
        },
        {
          "user": "sgoggins",
          "body": "Changed the target branch before closing because GitHub gets weird about telling you that you have a closed, unmmerged PR between two branches, and I've had it do things I didn't understand."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1376,
      "author": "achalesh27022003",
      "created_at": "2021-07-25T07:57:02Z",
      "comments": [
        {
          "user": "achalesh27022003",
          "body": "Please review this PR as it is the last day now to submit the form in OSD'21. Thanks"
        },
        {
          "user": "achalesh27022003",
          "body": "@ccarterlandis @sgoggins  sir please review it. Thanks"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1360,
      "author": "sgoggins",
      "created_at": "2021-07-19T18:10:39Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "Merging updates from `master` into `dev` after careful review from @IsaacMilarky and @sgoggins . This is to keep `dev` from getting too far out of date during refactoring."
        },
        {
          "user": "sgoggins",
          "body": "NOt good."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1346,
      "author": "maxhbr",
      "created_at": "2021-07-15T13:18:22Z",
      "comments": [
        {
          "user": "IsaacMilarky",
          "body": "This has a good chance of breaking the docker container's ability to establish a local database connection. I would have to test it to be sure but I remember this being necessary."
        },
        {
          "user": "maxhbr",
          "body": "The change in the entrypoint script fixes that. That configures the db address directly in augur, so that this should be unnecessary."
        },
        {
          "user": "IsaacMilarky",
          "body": "I was under the impression that the database's domain needed to be added to the container's /etc/hosts file, not just in augur. It seems like your changes all work great though when I test it on my machine so I am proven wrong. Thanks :)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1337,
      "author": "Yogita98",
      "created_at": "2021-07-12T07:16:21Z",
      "comments": [
        {
          "user": "Yogita98",
          "body": "cc @sgoggins \r\nNot sure how to add you in the reviewers list and the merge requires atleast 2 approvals"
        },
        {
          "user": "Yogita98",
          "body": "I see that [`make dev`](https://github.com/chaoss/augur/blob/master/Makefile#L71) first stops the existing servers and turns them up again. However, for contributors running the project for the first time, it'd be nice to have a note mentioning about an alternate command if `make dev` fails. Let me know your thoughts on this."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1314,
      "author": "maxhbr",
      "created_at": "2021-07-07T13:05:56Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@maxhbr : I can merge this to a fresh copy of `test` branch so you don't have to deal with resolving conflicts in the `Vagrantfile` versions. When you're past WIP."
        },
        {
          "user": "maxhbr",
          "body": "I will resolve conflicts before merging"
        },
        {
          "user": "maxhbr",
          "body": "It is rebased and should improve the branch. But the interactive build issue is still not fixed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1325,
      "author": "maxhbr",
      "created_at": "2021-07-07T17:08:34Z",
      "comments": [
        {
          "user": "maxhbr",
          "body": "I added scripting, that allows to mount initial repo and repo_group lists into the container and they are consumed on startup. Can be tested e.g. via the following configuration in `docker-compose.yml`:\r\n```\r\n    volumes:\r\n      - ./schema/repo_group_load_sample.csv:/repo_groups.csv\r\n      - ./schema/repo_load_sample.csv:/repos.csv\r\n```"
        },
        {
          "user": "maxhbr",
          "body": "I would also propose to get rid of the `augur:database` image and instead just use:\r\n\r\n```diff\r\ndiff --git a/database-compose.yml b/database-compose.yml\r\nindex 2b5371a6..8e7917d7 100644\r\n--- a/database-compose.yml\r\n+++ b/database-compose.yml\r\n@@ -2,10 +2,13 @@\r\n version: '3'\r\n services:\r\n    database:\r\n-    image: augurlabs/augur:${AUGUR_DB_TYPE}\r\n-    build:\r\n-      context: .\r\n-      dockerfile: ./util/docker/database/Dockerfile\r\n+    image: postgres:12\r\n+    environment:\r\n+      - POSTGRES_DB=\"augur\"\r\n+      - POSTGRES_USER=\"augur\"\r\n+      - POSTGRES_PASSWORD=\"augur\"\r\n+    volumes:\r\n+      - ./schema/generate/:/docker-entrypoint-initdb.d/\r\n     restart: unless-stopped\r\n     ports:\r\n      - 5434:5432\r\ndiff --git a/util/docker/database/Dockerfile b/util/docker/database/Dockerfile\r\ndeleted file mode 100644\r\nindex c890d078..00000000\r\n--- a/util/docker/database/Dockerfile\r\n+++ /dev/null\r\n@@ -1,13 +0,0 @@\r\n-#SPDX-License-Identifier: MIT\r\n-FROM postgres:12\r\n-\r\n-LABEL maintainer=\"outdoors@a"
        },
        {
          "user": "maxhbr",
          "body": "Why is that exposed as `5434` on the host? would it be OK to switch to 5432?"
        },
        {
          "user": "sgoggins",
          "body": "I believe that is a Docker related port mapping. Since the local Postgres instances typically resolve to 5432, or 5433, the Docker container (I think) uses 5434 to avoid a conflict. However, it is possible I misunderstand. In our use case, we are running the Docker container on the same metal as the database. @maxhbr"
        },
        {
          "user": "maxhbr",
          "body": "yes, it is probably for avoiding conflicts. But it creates other conflicts by having to change config (either talk to 5432 or 5434)"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1312,
      "author": "maxhbr",
      "created_at": "2021-07-05T15:54:49Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I'm going to merge it and update a copy of our test branch. I think this may be a byproduct of some dependencies I locked down too hard.  Specifically Dask; which is changing **very** fast right now."
        },
        {
          "user": "maxhbr",
          "body": "This line currently fails with\r\n\r\n```\r\n    default: **********************************\r\n    default: Installing message_insights_worker...\r\n    default: **********************************\r\n    default: Processing /vagrant/workers/message_insights_worker\r\n    default: Requirement already satisfied: Flask-Cors==3.0.10 in /root/.virtualenvs/augur_env/lib/python3.8/site-packages (from message-insights-worker==0.0.0) (3.0.10)\r\n    default: Requirement already satisfied: Flask-Login==0.5.0 in /root/.virtualenvs/augur_env/lib/python3.8/site-packages (from message-insights-worker==0.0.0) (0.5.0)\r\n    default: Requirement already satisfied: Flask-WTF==0.14.3 in /root/.virtualenvs/augur_env/lib/python3.8/site-packages (from message-insights-worker==0.0.0) (0.14.3)\r\n    default: Requirement already satisfied: Flask==1.1.4 in /root/.virtualenvs/augur_env/lib/python3.8/site-packages (from message-insights-worker==0.0.0) (1.1.4)\r\n    default: Collecting Keras-Preprocessing==1.1.2\r\n    default:   Dow"
        },
        {
          "user": "sgoggins",
          "body": "@maxhbr: I have only occasionally used vagrant. I'm going to test on the latest available version for OSX Big Sur. Let me know if I should be testing on a different version."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1285,
      "author": "anujlamoria",
      "created_at": "2021-06-17T23:00:55Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@anujlamoria : Can you look into the merge conflicts and resolve them?"
        },
        {
          "user": "sgoggins",
          "body": "Also, follow the instructions to do DCO ... if you click details it will give you them."
        },
        {
          "user": "sgoggins",
          "body": "@anujlamoria : Can you resolve the merge conflicts. Look at the `dev` branch and your branch for those three files, and just copy the `dev` branch versions into yours. Unless those three files are edited as part of hte pypi work on purpose, in which case, give me some more info."
        },
        {
          "user": "sgoggins",
          "body": "@anujlamoria : You need to resolve the merge conflicts before I can merge the PR."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1205,
      "author": "ivanayov",
      "created_at": "2021-03-23T19:26:15Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "I'll merge into dev from dev-redirect branch locally after I test it. Unless that messes up the commit credit, but I don't think it does."
        },
        {
          "user": "ivanayov",
          "body": "@sgoggins It's ok, whatever works better for you."
        },
        {
          "user": "sgoggins",
          "body": "@ivanayov : I sent a slack message with details, but the update does not seem to put the changed URLs into a 'new' status."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1168,
      "author": "sgoggins",
      "created_at": "2021-03-09T16:32:24Z",
      "comments": [
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : Are we past needing to do that."
        },
        {
          "user": "sgoggins",
          "body": "@ABrain7710 : can this be closed."
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1087,
      "author": "sgoggins",
      "created_at": "2021-01-14T19:46:10Z",
      "comments": [
        {
          "user": "ccarterlandis",
          "body": "This fix looks good to me, but now I'm realizing that the config does not get written to the `augurface` directory when it's generated, only `augur/frontend/`. I can fix this - should both frontends use the same frontend config file, or different ones?"
        },
        {
          "user": "sgoggins",
          "body": "@ccarterlandis : Per our discussion last  night, I think keeping the frontend.config.json in one place makes it easier. This PR accomplishes that goal."
        },
        {
          "user": "sgoggins",
          "body": "@ccarterlandis : Do you know why the Docker tests are not running?"
        }
      ]
    },
    {
      "repo": "chaoss/augur",
      "number": 1078,
      "author": "sgoggins",
      "created_at": "2021-01-04T15:49:11Z",
      "comments": [
        {
          "user": "ccarterlandis",
          "body": "What does this `all_focused` key actually do? I don't see it used anywhere in the code for these workers. Also, this is a separate issue, but I don't like the name `all_focused`. It's not descriptive at all and as a new user I would have no idea what it would change. The name doesn't need to convey literally everything it does, but something like `collect_all_issues` or `complete_collection` would be far more useful IMHO."
        },
        {
          "user": "ccarterlandis",
          "body": "Is this **GitLab** merge requests, or just merge requests of any kind? Context clues tell me it's just for GitLab, so I think we need to be very specific both in the model and in the given. Merge request is of course a very common FOSS term and could create confusion if we do no use it carefully."
        },
        {
          "user": "ccarterlandis",
          "body": "`all_focused` and merge request terminology comments apply here too."
        },
        {
          "user": "ccarterlandis",
          "body": "This indentation is incorrect. The brackets appear too far too the left, and the code appears to be too far to the right."
        },
        {
          "user": "ccarterlandis",
          "body": "This indentation is also incorrect. It needs to follow the formatting of the rest of the object."
        },
        {
          "user": "ccarterlandis",
          "body": "This needs to be added to the oneshot schema install script. And probably some other stuff we forgot to add too..."
        },
        {
          "user": "ccarterlandis",
          "body": "This code is also present in PR #1049. I don't know which version is correct."
        },
        {
          "user": "ccarterlandis",
          "body": "Please fix the indentation on this line."
        },
        {
          "user": "sgoggins",
          "body": "@gabe-heim picked the name. Its for the PR and issues workers to go make sure they are getting everything done."
        },
        {
          "user": "sgoggins",
          "body": "This is *GitLab*"
        },
        {
          "user": "sgoggins",
          "body": "ok but that wouldn't prevent this from being merged. Where is the oneshot?"
        },
        {
          "user": "sgoggins",
          "body": "They are the same.  I've merged that commit in that other branch as well."
        },
        {
          "user": "ccarterlandis",
          "body": "Okay, then I think we should change the model to `gitlab_merge_requests` and the given to `gitlab_url` to be as clear as possible."
        },
        {
          "user": "ccarterlandis",
          "body": "So what happens when it's off? Does it just...not collect everything? Like just a subset of the data or? \r\nAnd does this worker need it? I assume so, since it's about PRs (well MRs) but I guess what I'm trying to get at is that because the name of this key is confusing, I can't tell if this is actually supposed to be here or not."
        },
        {
          "user": "ccarterlandis",
          "body": "I don't think is resolved, I still think this needs to be changed because it is confusing otherwise. Or at least, I haven't been convinced otherwise yet. üòâ"
        },
        {
          "user": "ccarterlandis",
          "body": "This is also unresolved, for the same reasons as above."
        },
        {
          "user": "ccarterlandis",
          "body": "Again, this is not resolved. It needs to be in the oneshot as we made that with the intention to keep it up to date with the small update scripts, otherwise we ship 2 different versions of the schema and that's not good for anyone. It's in the `schema/` folder, same as all the other schema files. It's called `20201025-Release-0.14.0.sql`"
        },
        {
          "user": "ccarterlandis",
          "body": "Please fix the formatting on this line."
        },
        {
          "user": "ccarterlandis",
          "body": "This is not resolved either. Please fix the formatting as outlined in [this comment](https://github.com/chaoss/augur/pull/1049/files?file-filters%5B%5D=.sh#r544597459) on PR #1049."
        },
        {
          "user": "sgoggins",
          "body": "You're asking questions about the basic design @gabe-heim has in place. I'm not doing anything new or special here. This is a switch to *ensure* that we get everything on the first run. Its been there for over two years."
        },
        {
          "user": "sgoggins",
          "body": "Same answer as above. Its been there over two years. Now is not the time to stop a pull request because of it. Ask @gabe-heim ."
        },
        {
          "user": "sgoggins",
          "body": "extra space corrected."
        },
        {
          "user": "sgoggins",
          "body": "fixed."
        },
        {
          "user": "ccarterlandis",
          "body": "Okay, I definitely misspoke here and caused undue confusion; for that, I am sorry. Let me be crystal clear; the naming of this flag, while not straightforward at all, is not what is causing me to request a change. As I said in my first comment: \r\n> What does this all_focused key actually do? I don't see it used anywhere in the code for these workers \r\n\r\nThe whole reason for my comment is that I couldn't figure out WHY it's here. Doing a CTRL+F search for `all_focused` on this PR shows no results other than in this config, so I have no reason to believe it needs to be included. I talked to @gabe-heim about its purpose, and he confirmed my suspicions. Apparently it was only used in a `paginate_endpoint` function to enable/disable backwards pagination. This was unreliable and has since been switched out for a new `paginate` function as part of the worker refactor, so this flag should really be deprecated as it's useless now. It's fine for now since it doesn't hurt anything, but we need to"
        },
        {
          "user": "ccarterlandis",
          "body": "This is not resolved, and I'm not going to approve this PR or resolve this conversation until it either gets changed or I am convinced that it doesn't need to be changed."
        },
        {
          "user": "ccarterlandis",
          "body": "`all_focused` flag can stay, but the merge request terminology issue is not resolved."
        },
        {
          "user": "ccarterlandis",
          "body": "You must have merged the commit with these tests into this branch, they still need to be deleted. See [this thread](https://github.com/chaoss/augur/pull/1049/files#r543664611) as to why these test **MUST** be deleted, _or they will break the build_."
        },
        {
          "user": "ccarterlandis",
          "body": "This call to `main()` should not be here, please remove it."
        },
        {
          "user": "ccarterlandis",
          "body": "Can't we add this to a `.gitkeep`?"
        },
        {
          "user": "ccarterlandis",
          "body": "The `message_insights_worker` still seems to have added some `.h5` model files. Please review those files and determine if they are necessary or not; if they are not, please remove them from version control."
        },
        {
          "user": "ccarterlandis",
          "body": "This should go in  `.gitkeep` so we don't have a random `README.md` floating around. Looks weird when viewing on GitHub and breaks our pattern of using `.gitkeep`."
        },
        {
          "user": "ccarterlandis",
          "body": "After further thought this doesn't need to block this PR, as we should do the same thing for GitHub. We can do that later. But I still think it needs to be changed."
        },
        {
          "user": "sgoggins",
          "body": "@gabe-heim : Please pull this branch and fix it, or merge your PR branch and I'll merge that here first."
        }
      ]
    }
  ]
}